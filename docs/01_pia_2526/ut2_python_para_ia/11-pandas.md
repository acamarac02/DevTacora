---
title: "Pandas"
sidebar_position: 11
description: "Introducci√≥n a Pandas, la librer√≠a esencial para manipular y analizar datos en Python"
keywords: [Python, Pandas, DataFrame, Series, an√°lisis de datos, IA, Machine Learning, datos tabulares]
---

<div class="justify-text">

Pandas es una de las **librer√≠as m√°s potentes y utilizadas** en el ecosistema cient√≠fico de Python. Su objetivo principal es facilitar el **an√°lisis, la manipulaci√≥n y la limpieza de datos**, tareas fundamentales antes de aplicar cualquier modelo de **machine learning o deep learning**.

Mientras que **NumPy** trabaja con datos **num√©ricos homog√©neos** (arrays de n√∫meros del mismo tipo), Pandas introduce estructuras **m√°s flexibles y expresivas**, capaces de manejar **datos tabulares** (como hojas de c√°lculo o bases de datos) con **etiquetas** en filas y columnas.

## Conceptos b√°sicos

### Importancia de Pandas en la IA

En proyectos de **inteligencia artificial y machine learning**, la informaci√≥n no suele llegar en forma de arrays num√©ricos limpios.
Normalmente trabajamos con **datos reales**, que provienen de fuentes heterog√©neas como ficheros CSV, hojas de c√°lculo, bases de datos o APIs, y que contienen **mezclas de n√∫meros, textos, fechas y valores faltantes**.

Ah√≠ es donde **Pandas** se convierte en una herramienta esencial: act√∫a como un **puente entre los datos crudos y los modelos de aprendizaje autom√°tico**.
Permite **cargar, limpiar, transformar y analizar** la informaci√≥n de manera eficiente, utilizando estructuras de datos optimizadas (`Series` y `DataFrame`), que facilitan el paso posterior a NumPy o a bibliotecas de IA como **scikit-learn**, **TensorFlow** o **PyTorch**.

#### üß† Ejemplo: An√°lisis de un conjunto de datos antes de entrenar un modelo

Imagina que queremos construir un modelo de IA para **predecir el precio de viviendas**.
Disponemos de un archivo CSV con miles de registros que contienen informaci√≥n como:

* Superficie del inmueble (`m2`)
* N√∫mero de habitaciones
* Barrio
* Precio de venta

Antes de entrenar cualquier modelo, necesitamos **entender y preparar** esos datos.
Con Pandas podemos hacerlo en solo unas l√≠neas:

```python
import pandas as pd

# Cargar el conjunto de datos desde un archivo CSV
datos = pd.read_csv("viviendas.csv")

# Mostrar las primeras filas
print(datos.head())

# Calcular estad√≠sticas b√°sicas de las columnas num√©ricas
print(datos.describe())

# Ver cu√°ntos valores faltan por columna
print(datos.isna().sum())
```



üìä **Salida de `head()` (primeras 5 filas):**

```
      m2  habitaciones  barrio   precio
0  120.0            3  Centro   250000
1   85.0            2  Norte    185000
2   60.0            1  Este     120000
3  150.0            4  Oeste    310000
4   90.0            2  Centro   195000
```

**Estad√≠sticas b√°sicas (`describe()`):**

```
                m2  habitaciones        precio
count     5.000000      5.000000       5.000000
mean     101.0          2.4       212000.0
std       33.17          1.14       72594.3
min       60.0           1.0       120000.0
max      150.0           4.0       310000.0
```

**Valores faltantes (`isna().sum()`):**

```
m2              0
habitaciones    0
barrio          0
precio          0
dtype: int64
```

üëâ En solo tres pasos hemos:

1. **Le√≠do** los datos directamente desde un fichero.
2. **Explorado** su estructura y estad√≠sticas.
3. **Detectado valores ausentes**, algo fundamental antes del entrenamiento.

Pandas permite realizar estas tareas de forma **r√°pida, legible y escalable**, sin necesidad de bucles o estructuras complejas.
Por eso es una **herramienta indispensable en las primeras fases del flujo de trabajo de IA**, cuando transformamos los datos reales en informaci√≥n lista para ser utilizada por modelos de machine learning.


---

### Relaci√≥n entre Pandas y NumPy

Pandas se construye **sobre NumPy**, aprovechando sus arrays para realizar c√°lculos num√©ricos de forma eficiente.

La principal diferencia es que Pandas a√±ade **etiquetas e informaci√≥n estructurada** a los datos:

* En **NumPy**, trabajas con arrays indexados por posici√≥n num√©rica (`a[0, 1]`).
* En **Pandas**, puedes usar etiquetas para acceder a los datos (`df["nombre"]`, `df.loc["fila1"]`).

Esto hace que el c√≥digo sea **m√°s legible, expresivo y cercano a c√≥mo pensamos los datos en tablas** (como en una hoja de c√°lculo o base de datos).

üëâ En resumen:

| Librer√≠a | Estructura principal | Tipo de datos | Acceso por | Ideal para |
|-----------|----------------------|----------------|-------------|-------------|
| **NumPy** | Array (`ndarray`) | Datos num√©ricos homog√©neos | √çndices num√©ricos | C√°lculos cient√≠ficos y matriciales |
| **Pandas** | DataFrame / Series | Datos heterog√©neos (num√©ricos, texto, fechas‚Ä¶) | Etiquetas (nombres de columnas o √≠ndices) | An√°lisis y manipulaci√≥n de datos tabulares |

---

### Estructuras principales de Pandas

Pandas introduce **dos estructuras de datos principales** que ampl√≠an las capacidades de NumPy:

1. `Series`: es una **columna unidimensional** con **etiquetas asociadas** (√≠ndices).  
2. `DataFrame`: es una **tabla bidimensional** (como una hoja de Excel o una tabla SQL), donde:
    * Cada **columna** es una `Series`.
    * Cada **fila** tiene su propio **√≠ndice**.
    * Las columnas pueden contener **tipos de datos diferentes** (n√∫meros, texto, booleanos‚Ä¶).

---

## Series

Una **Serie** (`pd.Series`) es la estructura m√°s simple de Pandas: un **array unidimensional con etiquetas**, que combina la eficiencia de los arrays de **NumPy** con la flexibilidad de las listas o diccionarios de Python.

Cada elemento de una Serie tiene **dos componentes**:

* un **valor** (el dato en s√≠),
* un **√≠ndice** (una etiqueta asociada al valor).

Esto permite acceder a los datos **por posici√≥n o por nombre**, algo muy √∫til cuando trabajamos con informaci√≥n tabular o registros etiquetados.

---

### Creaci√≥n de Series

Podemos crear una Serie a partir de **listas**, **arrays de NumPy** o **diccionarios de Python**.

#### A partir de una lista

```python
import pandas as pd

edades = pd.Series([18, 22, 30, 25])
print(edades)
```

Salida:

```
0    18
1    22
2    30
3    25
dtype: int64
```

üëâ Pandas crea autom√°ticamente un **√≠ndice num√©rico** empezando en `0`, igual que en las listas.

---

#### A partir de un array de NumPy

```python
import numpy as np

valores = np.array([10, 20, 30, 40])
serie = pd.Series(valores)
print(serie)
```

Salida:

```
0    10
1    20
2    30
3    40
dtype: int64
```

üìò Esto demuestra c√≥mo Pandas puede **integrar directamente datos de NumPy**, manteniendo toda su potencia num√©rica.

---

#### A partir de un diccionario

Si usamos un diccionario, las **claves se convierten en el √≠ndice** y los **valores en los datos**:

```python
precios = pd.Series({'manzana': 0.85, 'pl√°tano': 0.60, 'pera': 0.90})
print(precios)
```

Salida:

```
manzana    0.85
pl√°tano    0.60
pera       0.90
dtype: float64
```

üëâ Este formato es muy √∫til para representar datos **con etiquetas significativas**, como columnas de un dataset real.

---

#### √çndices y acceso a elementos

El √≠ndice de una Serie puede personalizarse:

```python
alumnos = pd.Series([8.5, 7.0, 9.2], index=['Ana', 'Luis', 'Marta'])
print(alumnos)
```

Salida:

```
Ana      8.5
Luis     7.0
Marta    9.2
dtype: float64
```

Podemos acceder a los elementos de dos formas:

```python
print(alumnos[0])        # Por posici√≥n
# 8.5

print(alumnos['Marta'])  # Por etiqueta
# 9.2
```

---

### Propiedades de una Serie

Las Series tienen propiedades √∫tiles para inspeccionar su contenido:

```python
print(alumnos.values)   # Valores (array de NumPy)
print(alumnos.index)    # √çndices
print(alumnos.dtype)    # Tipo de dato
print(alumnos.shape)    # Dimensi√≥n
```

Salida:

```
[8.5 7.  9.2]
Index(['Ana', 'Luis', 'Marta'], dtype='object')
float64
(3,)
```

üëâ Observa que los valores se almacenan internamente como un **array NumPy**, lo que permite realizar operaciones vectorizadas.

---

### Operaciones vectorizadas y estad√≠sticas

Podemos aplicar operaciones **directamente sobre toda la Serie**, igual que en NumPy:

```python
print(alumnos + 1)     # Suma 1 a todas las notas
print(alumnos * 2)     # Duplica cada valor
```

Salida:

```
Ana      9.5
Luis     8.0
Marta   10.2
dtype: float64
```

Y tambi√©n funciones estad√≠sticas integradas:

```python
print(alumnos.mean())   # Media
print(alumnos.max())    # M√°ximo
print(alumnos.min())    # M√≠nimo
```

Salida:

```
8.233333333333333
9.2
7.0
```

üìä En IA, estas operaciones son muy comunes para **analizar variables individuales** (por ejemplo, la edad media de los clientes o el valor promedio de un sensor).

---

### Filtrado y condiciones l√≥gicas

Podemos filtrar los valores de una Serie usando **condiciones booleanas**, igual que en NumPy:

```python
print(alumnos[alumnos > 8])
```

Salida:

```
Ana      8.5
Marta    9.2
dtype: float64
```

Tambi√©n pueden combinarse condiciones con `&` (*and*) y `|` (*or*):

```python
print(alumnos[(alumnos >= 7) & (alumnos < 9)])
```

Salida:

```
Luis    7.0
Ana     8.5
dtype: float64
```

üëâ Este tipo de filtrado se utiliza constantemente en an√°lisis de datos y preparaci√≥n de datasets, por ejemplo, para **seleccionar muestras v√°lidas o descartar valores an√≥malos** antes del entrenamiento de un modelo.

---

:::tip EJERCICIO SERIES: An√°lisis de consumo energ√©tico

Imagina que un sistema IoT ha registrado el **consumo el√©ctrico (en kWh)** de un edificio inteligente durante cinco d√≠as consecutivos.
Queremos analizar estos datos con Pandas.

1. Crea una Serie llamada `consumo` con las siguientes etiquetas y los valores generados aleatoriamente entre 27 y 40. Una posible salida ser√≠a:

    | D√≠a       | Consumo (kWh) |
    | --------- | ------------- |
    | Lunes     | 34.5          |
    | Martes    | 29.8          |
    | Mi√©rcoles | 31.2          |
    | Jueves    | 40.1          |
    | Viernes   | 37.6          |


2. Muestra:

   * El consumo medio de la semana.
   * Qu√© d√≠as superaron el consumo medio.
   * Cu√°l fue el **d√≠a de mayor consumo**.
   * Incrementa todos los valores un 10% (simulando una predicci√≥n de aumento de demanda).
:::

---

## DataFrames

Un **DataFrame** es la estructura de datos **m√°s importante y vers√°til de Pandas**.
Podemos imaginarlo como una **tabla**, similar a una hoja de c√°lculo de Excel o una tabla de base de datos:

* Cada **columna** es una **Serie** (con su propio tipo de dato).
* Cada **fila** representa una **observaci√≥n o registro**.
* Cada **celda** contiene un valor individual.

Los DataFrames permiten manejar datos **heterog√©neos** (n√∫meros, textos, fechas, booleanos‚Ä¶) de forma eficiente y estructurada.
En proyectos de IA y ciencia de datos, los DataFrames son el **punto de partida habitual** para analizar y preparar conjuntos de datos antes de alimentar a modelos de *machine learning*.

---

### Creaci√≥n de DataFrames

#### A partir de un diccionario de listas

Cada clave del diccionario se convierte en el **nombre de una columna**, y los valores (listas) en las **filas** correspondientes.

```python
import pandas as pd

datos = {
    "nombre": ["Ana", "Luis", "Marta", "Jorge"],
    "edad": [23, 21, 25, 22],
    "nota": [8.5, 7.2, 9.1, 6.8]
}

df = pd.DataFrame(datos)
print(df)
```

Salida:

```
  nombre  edad  nota
0    Ana    23   8.5
1   Luis    21   7.2
2  Marta    25   9.1
3  Jorge    22   6.8
```

üìò En IA, este formato es muy com√∫n al **importar datasets** en los que cada columna representa una caracter√≠stica (*feature*) y cada fila, una muestra.

---

#### A partir de una lista de diccionarios

Cada elemento de la lista representa una **fila del DataFrame**:

```python
personas = [
    {"nombre": "Ana", "edad": 23, "nota": 8.5},
    {"nombre": "Luis", "edad": 21, "nota": 7.2},
    {"nombre": "Marta", "edad": 25, "nota": 9.1},
]
df = pd.DataFrame(personas)
print(df)
```

---

#### A partir de un array de NumPy

Podemos combinar **NumPy** y **Pandas** f√°cilmente:

```python
import numpy as np

valores = np.array([[1, 2, 3],
                    [4, 5, 6],
                    [7, 8, 9]])

df = pd.DataFrame(valores, columns=["A", "B", "C"])
print(df)
```

Salida:

```
   A  B  C
0  1  2  3
1  4  5  6
2  7  8  9
```

üëâ Esto es muy √∫til cuando generamos datos con NumPy (por ejemplo, simulaciones o resultados de sensores) y queremos analizarlos o etiquetarlos con Pandas.

---

### Exploraci√≥n inicial

Una vez creado el DataFrame, existen m√©todos muy √∫tiles para **inspeccionar su contenido**:

```python
print(df.head())      # Primeras 5 filas
print(df.tail(2))     # √öltimas 2 filas
print(df.info())      # Informaci√≥n general
print(df.describe())  # Estad√≠sticas num√©ricas
```

**Ejemplo de salida (`df.describe()`):**

```
            edad      nota
count   4.000000  4.000000
mean   22.750000  7.900000
std     1.707825  1.031091
min    21.000000  6.800000
max    25.000000  9.100000
```

üìä Estas funciones son esenciales para **conocer la estructura y distribuci√≥n** de los datos, detectar valores extremos o confirmar tipos de variables antes de entrenar un modelo.

---

### Acceso a los datos

El procedimiento depender√° si queremos acceder a los datos por fila o por columna.

#### Acceso a columnas

Podemos acceder a una columna de la siguiente forma:

```python
print(df["nombre"])   # M√©todo m√°s com√∫n (hay otras formas)
```

Salida:

```
0      Ana
1     Luis
2    Marta
3    Jorge
Name: nombre, dtype: object
```

üëâ Cada columna es en realidad una **Serie de Pandas**.

Tambi√©n podemos obtener varias columnas a la vez pasando una lista:

```python
print(df[["nombre", "nota"]])
```

---

#### Acceso a filas

Pandas ofrece dos formas principales de acceder a filas:

* `.loc[]` ‚Üí por **etiqueta** o nombre de √≠ndice.
* `.iloc[]` ‚Üí por **posici√≥n num√©rica**.

```python
print(df.loc[2])   # Fila con etiqueta 2
print(df.iloc[0])  # Primera fila
```

Salida:

```
nombre    Marta
edad          25
nota         9.1
Name: 2, dtype: object
```

---

### Selecci√≥n condicional y filtrado m√∫ltiple

Al igual que hac√≠amos en NumPy, podemos aplicar condiciones para **filtrar registros** f√°cilmente:

```python
print(df[df["nota"] > 8])
```

Salida:

```
  nombre  edad  nota
0    Ana    23   8.5
2  Marta    25   9.1
```

Tambi√©n se pueden combinar condiciones con operadores l√≥gicos:

```python
print(df[(df["edad"] > 21) & (df["nota"] >= 8)])
```

üëâ Esto resulta muy √∫til para seleccionar subconjuntos de datos, como ‚Äúestudiantes mayores de 21 con nota destacada‚Äù.

---

### A√±adir y eliminar registros

#### A√±adir columnas

Podemos crear una nueva columna directamente:

```python
df["aprobado"] = df["nota"] >= 5
print(df)
```

Salida:

```
  nombre  edad  nota  aprobado
0    Ana    23   8.5      True
1   Luis    21   7.2      True
2  Marta    25   9.1      True
3  Jorge    22   6.8      True
```

Tambi√©n se pueden a√±adir columnas calculadas:

```python
df["nota_ajustada"] = df["nota"] * 1.05
```

---

#### Eliminar columnas o filas

Para eliminar una columna, usamos `drop()` con `axis=1`:

```python
df = df.drop("nota_ajustada", axis=1)
```

Para eliminar filas por √≠ndice:

```python
df = df.drop(3, axis=0)  # Elimina la fila con √≠ndice 3
```

üëâ Todas estas operaciones devuelven **una nueva copia del DataFrame**; si se quiere modificar el original, se a√±ade el par√°metro `inplace=True`.

---

## Modificaci√≥n y limpieza b√°sica

En la pr√°ctica, los conjuntos de datos rara vez llegan ‚Äúlimpios‚Äù.
Antes de analizar o entrenar modelos de IA, es habitual tener que **renombrar columnas**, **corregir tipos de datos**, **tratar valores nulos** o **eliminar duplicados**.

Pandas incluye m√∫ltiples herramientas para realizar estas tareas de manera sencilla y eficiente.

### Renombrar columnas

El m√©todo `rename()` permite **cambiar el nombre de una o varias columnas**.
Recibe un diccionario donde las claves son los nombres actuales y los valores los nuevos.

```python
import pandas as pd

df = pd.DataFrame({
    "nombre": ["Ana", "Luis", "Marta"],
    "edad": [23, 21, 25],
    "nota": [8.5, 7.2, 9.1]
})

df = df.rename(columns={"nota": "puntuacion"})
print(df)
```

Salida:

```
  nombre  edad  puntuacion
0    Ana    23         8.5
1   Luis    21         7.2
2  Marta    25         9.1
```

üëâ Esta operaci√≥n es muy com√∫n cuando los datasets provienen de **fuentes externas** (por ejemplo, CSVs con nombres poco descriptivos).

---

### Reemplazar valores

Para sustituir valores espec√≠ficos, utilizamos `replace()`.
Funciona tanto con valores individuales como con listas o diccionarios.

```python
df["nombre"] = df["nombre"].replace("Luis", "Luis M.")
print(df)
```

Salida:

```
  nombre  edad  puntuacion
0    Ana    23         8.5
1  Luis M.  21         7.2
2  Marta    25         9.1
```

Tambi√©n puede emplearse para **reemplazar varios valores a la vez**:

```python
df["edad"] = df["edad"].replace({21: 22, 25: 26})
```

---

### Cambiar tipos de datos

Pandas detecta autom√°ticamente los tipos de cada columna (`int`, `float`, `object`, etc.), pero a veces es necesario **convertirlos manualmente**, por ejemplo para c√°lculos num√©ricos o modelos que no aceptan texto.

Se usa el m√©todo `astype()`:

```python
df["edad"] = df["edad"].astype(float)
print(df.dtypes)
```

Salida:

```
nombre         object
edad          float64
puntuacion    float64
dtype: object
```

üìò Este paso es fundamental antes del modelado: los algoritmos de aprendizaje autom√°tico requieren tipos num√©ricos homog√©neos (por ejemplo, `float32` en TensorFlow).

---

### Detecci√≥n y tratamiento de valores nulos

Los valores ausentes o desconocidos (`NaN`) son muy frecuentes en datasets reales.
Pandas ofrece varias funciones para **identificarlos, eliminarlos o sustituirlos**.

#### Detecci√≥n de nulos

```python
import numpy as np

df.loc[1, "puntuacion"] = np.nan   # Simulamos un valor faltante
print(df)
```

```
  nombre  edad  puntuacion
0    Ana  23.0        8.5
1  Luis M. 22.0        NaN
2  Marta  26.0        9.1
```

Podemos comprobar qu√© valores son nulos:

```python
print(df.isna())       # True/False por celda
print(df.isna().sum()) # Conteo por columna
```

Salida:

```
   nombre   edad  puntuacion
0   False  False       False
1   False  False        True
2   False  False       False

nombre        0
edad          0
puntuacion    1
dtype: int64
```

---

#### Sustituir valores nulos

Para rellenar los nulos, usamos `fillna()`:

```python
df["puntuacion"] = df["puntuacion"].fillna(df["puntuacion"].mean())
print(df)
```

Salida:

```
  nombre  edad  puntuacion
0    Ana    23.0     8.5
1  Luis M.  22.0     8.8
2  Marta    26.0     9.1
```

üëâ En este caso, se ha sustituido el valor faltante por la **media de la columna**, una t√©cnica de imputaci√≥n com√∫n en preprocesamiento. M√°s adelante estudiaremos las diferentes t√©cnicas que existen y cual aplicar seg√∫n el caso.

---

#### Eliminar filas o columnas con nulos

Si queremos **eliminar registros incompletos**, usamos `dropna()`:

```python
df = df.dropna()
```

O bien eliminar columnas con valores ausentes:

```python
df = df.dropna(axis=1)
```

---

### Duplicados

Otra fuente habitual de problemas son los **registros duplicados**, especialmente en datasets recopilados de distintas fuentes.

Podemos detectarlos con `duplicated()`:

```python
print(df.duplicated())
```

Y eliminarlos con `drop_duplicates()`:

```python
df = df.drop_duplicates()
```

Si solo queremos considerar algunas columnas para definir duplicados:

```python
df = df.drop_duplicates(subset=["nombre"])
```

---

### Resumen r√°pido

| Funci√≥n                              | Descripci√≥n                           | Ejemplo                        | Resultado            |
| ------------------------------------ | ------------------------------------- | ------------------------------ | -------------------- |
| `rename()`                           | Cambiar nombres de columnas o √≠ndices | `df.rename(columns={"a":"A"})` | Columna renombrada   |
| `replace()`                          | Sustituir valores                     | `df["col"].replace(0, np.nan)` | Valores reemplazados |
| `astype()`                           | Cambiar tipo de datos                 | `df["edad"].astype(float)`     | Tipo actualizado     |
| `isna()` / `fillna()`                | Detectar / rellenar valores nulos     | `df.fillna(0)`                 | Nulos sustituidos    |
| `dropna()`                           | Eliminar filas o columnas con nulos   | `df.dropna(axis=0)`            | Datos limpios        |
| `duplicated()` / `drop_duplicates()` | Detectar / eliminar duplicados        | `df.drop_duplicates()`         | Sin repeticiones     |


üìò **En resumen:**
Estas operaciones forman parte de la **fase b√°sica de limpieza de datos**, imprescindible antes de cualquier an√°lisis o entrenamiento.
Dominar estas funciones permite **preparar los datasets de manera r√°pida y fiable**, garantizando que los modelos de IA trabajen con datos consistentes y sin errores.

---

## Operaciones y funciones √∫tiles

Una vez que los datos est√°n limpios y organizados en un **DataFrame**, Pandas permite realizar **operaciones matem√°ticas, estad√≠sticas y transformaciones** de forma r√°pida y vectorizada, sin necesidad de bucles.

Estas funciones son esenciales en la **fase de an√°lisis exploratorio de datos (EDA)**, donde se busca obtener informaci√≥n general antes de aplicar t√©cnicas de modelado o aprendizaje autom√°tico.


### Operaciones aritm√©ticas y estad√≠sticas

Pandas hereda de NumPy la capacidad de aplicar operaciones **elemento a elemento** sobre columnas num√©ricas.

```python
import pandas as pd

df = pd.DataFrame({
    "temperatura": [20, 22, 25, 23, 21],
    "humedad": [65, 70, 60, 72, 68]
})
```

#### Operaciones aritm√©ticas

```python
print(df["temperatura"] + 1)    # Aumentar en 1 grado
print(df["humedad"] / 100)      # Convertir a proporci√≥n
```

Salida:

```
0    21
1    23
2    26
3    24
4    22
Name: temperatura, dtype: int64
```

üëâ Estas operaciones se aplican **a toda la columna** (vectorizaci√≥n), lo que las hace muy r√°pidas incluso con miles de registros.

---

#### Operaciones estad√≠sticas b√°sicas

Pandas incluye numerosas funciones estad√≠sticas integradas:

```python
print("Media temperatura:", df["temperatura"].mean())
print("M√°ximo humedad:", df["humedad"].max())
print("Desviaci√≥n est√°ndar:", df["temperatura"].std())
print("Suma total humedad:", df["humedad"].sum())
```

Salida:

```
Media temperatura: 22.2
M√°ximo humedad: 72
Desviaci√≥n est√°ndar: 1.92
Suma total humedad: 335
```

üìò En IA, estas m√©tricas ayudan a **resumir y entender la distribuci√≥n** de los datos antes del entrenamiento (por ejemplo, detectar valores extremos o sesgos en las variables).

---

### Aplicaci√≥n de funciones con `map()`

Adem√°s de las operaciones b√°sicas, Pandas permite aplicar **funciones personalizadas** sobre una columna. Por ejemplo, podemos convertir temperaturas de ¬∞C a ¬∞F o pasar textos a min√∫sculas.


```python
df["temperatura_F"] = df["temperatura"].map(lambda x: x * 1.8 + 32)
print(df)
```

Salida:

```
   temperatura  humedad  temperatura_F
0           20       65           68.0
1           22       70           71.6
2           25       60           77.0
3           23       72           73.4
4           21       68           69.8
```

---

### Agrupaciones simples (`groupby()`)

Una de las herramientas **m√°s potentes** de Pandas es `groupby()`.
Permite **dividir un DataFrame en grupos** seg√∫n una o varias columnas categ√≥ricas (por ejemplo, *tienda*, *ciudad* o *producto*), para luego **calcular estad√≠sticas o res√∫menes** sobre cada grupo.

En otras palabras, `groupby()` en Pandas equivale a la operaci√≥n `GROUP BY` en **SQL**.


#### Concepto b√°sico

El flujo l√≥gico de un `groupby()` puede entenderse como tres pasos:

1. **Dividir (split):** agrupar el DataFrame seg√∫n una o varias columnas.
2. **Aplicar (apply):** ejecutar una operaci√≥n sobre cada grupo (por ejemplo, `mean()`, `sum()`, `count()`‚Ä¶).
3. **Combinar (combine):** juntar los resultados en una nueva estructura.

üîπ Sintaxis general:

```python
df.groupby("columna_agrupar")["columna_numerica_calculo"].funci√≥n()
```

Ejemplo:

```python
ventas.groupby("tienda")["ventas"].mean()
```

---

#### Ejemplo pr√°ctico

Supongamos el siguiente DataFrame con informaci√≥n de ventas por tienda y ciudad:

```python
import pandas as pd

ventas = pd.DataFrame({
    "tienda": ["A", "B", "A", "B", "A", "C"],
    "ventas": [200, 300, 250, 400, 150, 350],
    "ciudad": ["Madrid", "Madrid", "Sevilla", "Sevilla", "Sevilla", "Madrid"]
})
print(ventas)
```

Salida:

```
  tienda  ventas   ciudad
0      A     200   Madrid
1      B     300   Madrid
2      A     250  Sevilla
3      B     400  Sevilla
4      A     150  Sevilla
5      C     350   Madrid
```

#### Agrupar por una columna

Si queremos conocer la **media de ventas por tienda**, podemos agrupar por el nombre de la tienda:

```python
media_ventas = ventas.groupby("tienda")["ventas"].mean()
print(media_ventas)
```

Salida:

```
tienda
A    200.0
B    350.0
C    350.0
Name: ventas, dtype: float64
```

üìò Cada grupo se identifica por el valor de la columna `tienda`.
La funci√≥n `mean()` calcula la media dentro de cada grupo.

---

#### Otras funciones comunes con `groupby()`

Adem√°s de `mean()`, se pueden aplicar muchas funciones estad√≠sticas:

| Funci√≥n           | Descripci√≥n           |
| ----------------- | --------------------- |
| `sum()`           | Suma total del grupo  |
| `mean()`          | Media aritm√©tica      |
| `count()`         | N√∫mero de elementos   |
| `min()` / `max()` | Valor m√≠nimo / m√°ximo |
| `median()`        | Mediana               |
| `std()`           | Desviaci√≥n est√°ndar   |

Ejemplo:

```python
ventas.groupby("tienda")["ventas"].sum()
```

Salida:

```
tienda
A    600
B    700
C    350
Name: ventas, dtype: int64
```

üëâ Esto indica las **ventas totales** por tienda, combinando los registros repetidos.

---

#### Agrupar por m√°s de una columna

Tambi√©n podemos agrupar por **dos o m√°s columnas** para obtener combinaciones √∫nicas, igual que en SQL:

```python
ventas_ciudad = ventas.groupby(["ciudad", "tienda"])["ventas"].sum()
print(ventas_ciudad)
```

Salida:

```
ciudad   tienda
Madrid   A    200
         B    300
         C    350
Sevilla  A    400
         B    400
Name: ventas, dtype: int64
```

üîπ El resultado tiene un **√≠ndice jer√°rquico** (*MultiIndex*), donde primero se agrupa por ciudad y luego por tienda.
Esto es muy √∫til para comparar resultados entre regiones o categor√≠as.

---

#### Obtener varias estad√≠sticas a la vez

Tambi√©n podemos obtener **m√∫ltiples estad√≠sticas simult√°neamente** usando `.agg()` (de *aggregate*):

```python
resumen = ventas.groupby("tienda")["ventas"].agg(["mean", "sum", "count"])
print(resumen)
```

Salida:

```
         mean  sum  count
tienda
A        200   600      3
B        350   700      2
C        350   350      1
```

üëâ `agg()` permite aplicar varias funciones a la vez, generando un resumen completo por grupo.

---

### Ordenaci√≥n de datos (`sort_values()`, `sort_index()`)

#### Ordenar por valores

```python
print(ventas.sort_values(by="ventas", ascending=False))
```

Salida:

```
  tienda  ventas   ciudad
3      B     400  Sevilla
1      B     300   Madrid
2      A     250  Sevilla
0      A     200   Madrid
4      A     150  Sevilla
```

#### Ordenar por √≠ndice

```python
print(ventas.sort_index())
```

üëâ Esto ordena las filas seg√∫n su **√≠ndice num√©rico o etiqueta**, √∫til tras concatenaciones o reindexaciones.

---

## Carga y guardado de datos

Una de las principales ventajas de Pandas es su capacidad para **leer y escribir datos en m√∫ltiples formatos**.
En ciencia de datos y aprendizaje autom√°tico, los conjuntos de datos suelen almacenarse en **archivos CSV o Excel**, por lo que dominar estas operaciones es esencial para poder **importar, explorar y preparar la informaci√≥n** antes del an√°lisis.


### Lectura de archivos CSV (`read_csv()`)

El formato **CSV (Comma-Separated Values)** es el m√°s habitual para almacenar datos tabulares.
Cada fila representa un registro y las columnas se separan por comas, punto y coma u otros delimitadores.

Pandas permite leer f√°cilmente este tipo de ficheros con la funci√≥n `pd.read_csv()`. Puedes descargar el fichero de ejemplo [aqu√≠](./0-datasets/ventas.csv).


```python
import pandas as pd

# Cargar un archivo CSV
df = pd.read_csv("ventas.csv")

# Mostrar las primeras filas
print(df.head())
```

Salida (ejemplo):

```
   id  tienda   ciudad  ventas
0   1       A   Madrid     200
1   2       B   Madrid     300
2   3       A  Sevilla     250
3   4       B  Sevilla     400
4   5       A  Sevilla     150
```

üëâ Por defecto, `read_csv()` interpreta que las columnas est√°n separadas por comas, que la primera fila contiene los encabezados y que se usar√° un √≠ndice num√©rico.

---

### Par√°metros importantes de `read_csv()`

Pandas permite adaptar la lectura del fichero con numerosos argumentos.
A continuaci√≥n se muestran los m√°s usados:

| Par√°metro   | Descripci√≥n                                                      | Ejemplo                       |
| ----------- | ---------------------------------------------------------------- | ----------------------------- |
| `sep`       | Delimitador del archivo. Puede ser `","`, `";"`, `"\t"`‚Ä¶         | `sep=";"`                     |
| `header`    | Fila que contiene los nombres de las columnas (por defecto `0`). | `header=0`                    |
| `index_col` | Columna a usar como √≠ndice del DataFrame.                        | `index_col="id"`              |
| `usecols`   | Lista de columnas a cargar (para ahorrar memoria).               | `usecols=["tienda","ventas"]` |
| `encoding`  | Codificaci√≥n del archivo (`utf-8`, `latin-1`, etc.).             | `encoding="utf-8"`            |

Ejemplo pr√°ctico con varios par√°metros:

```python
df = pd.read_csv(
    "ventas.csv",
    sep=";",
    index_col="id",
    usecols=["id", "tienda", "ventas"],
    encoding="utf-8"
)
print(df.head())
```

---

### Exploraci√≥n r√°pida tras la carga

Una vez cargado el dataset, conviene **inspeccionar su contenido y estructura**:

```python
print(df.shape)     # N√∫mero de filas y columnas
print(df.columns)   # Nombres de columnas
print(df.info())    # Tipos de datos y valores nulos
print(df.describe())# Estad√≠sticas num√©ricas
```

üìò Estas comprobaciones son el primer paso del flujo de trabajo en IA: garantizan que el dataset se ha le√≠do correctamente y que los tipos de datos son adecuados.

---

### Escritura de DataFrames (`to_csv()`)

Cuando terminamos de limpiar o transformar un DataFrame, podemos **guardar los resultados** nuevamente en un archivo CSV.

```python
# Guardar el DataFrame en un nuevo archivo
df.to_csv("ventas_limpias.csv", index=False)
```

üìò El par√°metro `index=False` evita guardar el √≠ndice como una columna adicional en el archivo.
Esto es √∫til cuando el √≠ndice no tiene significado en el dataset.

Tambi√©n podemos personalizar el formato de salida:

```python
df.to_csv("ventas_utf8.csv", sep=";", encoding="utf-8")
```

---

### Lectura y escritura en Excel

Adem√°s de CSV, Pandas permite trabajar directamente con archivos **Excel** (`.xlsx`, `.xls`).
Esto es muy com√∫n en entornos empresariales o cuando los datos provienen de hojas de c√°lculo.

#### Leer un archivo Excel

```python
df_excel = pd.read_excel("ventas.xlsx", sheet_name="Hoja1")
print(df_excel.head())
```

#### Guardar un DataFrame a Excel

```python
df.to_excel("resultado.xlsx", index=False, sheet_name="Resumen")
```

üìò Estos m√©todos requieren tener instalado un motor adicional como `openpyxl` (ya incluido en la mayor√≠a de entornos cient√≠ficos de Python).

</div>