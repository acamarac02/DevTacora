---
title: "Ideas generales"
sidebar_position: 0
toc_max_heading_level: 5
description: "Introducci√≥n a los problemas de regresi√≥n en Machine Learning. Qu√© es la regresi√≥n, en qu√© se diferencia de la clasificaci√≥n, principales m√©tricas de evaluaci√≥n y visi√≥n general de los modelos de regresi√≥n."
keywords: [Regresi√≥n, Machine Learning, modelos de regresi√≥n, m√©tricas, MSE, MAE, R2, supervisado]
---

Un **problema de regresi√≥n** es un tipo de problema de **aprendizaje supervisado** en el que el objetivo es **predecir un valor num√©rico continuo**.

En estos problemas:
- El dataset contiene **features** (variables de entrada).
- Existe una variable objetivo (**target**) **num√©rica**.
- El modelo aprende una relaci√≥n entre las features y el target.

## Ejemplos de problemas de regresi√≥n
- Predecir el **precio de una vivienda**
- Estimar la **temperatura** de ma√±ana
- Calcular el **consumo el√©ctrico**
- Predecir la **nota final** de un estudiante

---

## Diferencias entre regresi√≥n y clasificaci√≥n

Aunque ambos son problemas de aprendizaje supervisado, existen diferencias clave:

| Caracter√≠stica | Regresi√≥n | Clasificaci√≥n |
|----------------|----------|---------------|
| Tipo de salida | Num√©rica continua | Categor√≠a o clase |
| Ejemplo de target | 1250.75 | "spam", "no spam" |
| M√©tricas comunes | MSE, MAE, R¬≤ | Accuracy, Precision, Recall |
| Visualizaci√≥n | Rectas, curvas | Regiones de decisi√≥n |

üëâ La **principal diferencia** est√° en el **tipo de variable objetivo**.

---

## Modelos de regresi√≥n

En regresi√≥n, el objetivo es predecir un **valor num√©rico continuo**.
Algunos modelos lo hacen ajustando una **funci√≥n global** (como una recta o un plano),
mientras que otros realizan predicciones locales basadas en los datos m√°s cercanos,
como ocurre en k-NN.

![Simple vs Multiple](../../0-img/simple_vs_multiple.png)

| Modelo | Tipo | Lineal | Param√©trico | Interpretabilidad |
|------|------|--------|-------------|------------------|
| Regresi√≥n Lineal | Base | S√≠ | S√≠ | Alta |
| Regresi√≥n Polin√≥mica | Extensi√≥n | No | S√≠ | Media |
| k-NN Regresi√≥n | Basado en instancias | No | No | Baja |
| √Årbol de Decisi√≥n | Basado en reglas | No | No | Media |
| Random Forest | Ensemble | No | No | Baja |
| Ridge | Lineal regularizado | S√≠ | S√≠ | Media |
| Lasso | Lineal regularizado | S√≠ | S√≠ | Media |

:::info ¬øQu√© significan estas caracter√≠sticas?
En la tabla se utilizan los siguientes conceptos:

- **Lineal**: indica si el modelo asume una relaci√≥n lineal entre las variables de entrada y la variable objetivo.  
  Un modelo lineal puede representarse mediante una combinaci√≥n lineal de las features.

- **Param√©trico**: indica si el modelo aprende un n√∫mero fijo de par√°metros (como coeficientes).  
  Los modelos param√©tricos asumen una forma concreta del modelo y no dependen directamente del n√∫mero de datos.

- **Interpretabilidad**: hace referencia a lo f√°cil que es entender c√≥mo el modelo realiza sus predicciones.  
  Modelos simples y lineales suelen ser m√°s interpretables, mientras que modelos m√°s complejos suelen ofrecer mayor rendimiento pero menor explicaci√≥n.
:::


Una vez ajustado el modelo, necesitamos medir qu√© tan bien se adapta a los datos.
Para ello se utilizan distintas m√©tricas de evaluaci√≥n.


---

## M√©tricas de evaluaci√≥n en regresi√≥n

Para evaluar modelos de regresi√≥n se utilizan m√©tricas que miden **el error entre el valor real y el valor predicho**.

### Mean Squared Error (MSE)

El **Mean Squared Error (MSE)** es una de las m√©tricas m√°s utilizadas en problemas de regresi√≥n. Mide el **promedio del cuadrado de la diferencia entre los valores reales y los valores predichos por el modelo**.

En otras palabras, cuantifica **cu√°nto se equivoca el modelo al predecir**, dando **m√°s peso a los errores grandes**.

Si tenemos un conjunto de $ n $ observaciones:

* $ y_i $: valor real
* $ \hat{y}_i $: valor predicho por el modelo

El MSE se define como:

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

:::tip
Cuanto **menor** sea el MSE, **mejor** es el modelo,  
porque indica que, en promedio, las predicciones del modelo est√°n m√°s
cerca de los valores reales y que los errores grandes son menos frecuentes.
:::

Ejemplo de c√°lculo del MSE con un dataset de prueba:

![C√°lculo MSE](../../0-img/calculo-mse.png)


Si el modelo comete errores grandes en pocas observaciones, el MSE **aumenta mucho**.

---

#### Relaci√≥n con el entrenamiento del modelo

En muchos modelos de regresi√≥n, el entrenamiento del modelo consiste en
encontrar los **par√°metros internos** (por ejemplo, los **coeficientes**) que
minimizan una **funci√≥n de coste**, siendo el MSE una de las m√°s utilizadas.

En este contexto, el MSE:
- Se utiliza como funci√≥n de coste durante el entrenamiento
- Gu√≠a el ajuste de los par√°metros del modelo

Adem√°s, el MSE tambi√©n puede utilizarse como m√©trica de evaluaci√≥n en
procesos de selecci√≥n de hiperpar√°metros, como GridSearch, donde se emplea
para comparar distintos modelos entrenados.

:::info ¬øQu√© es la funci√≥n de coste?
La **funci√≥n de coste** es una funci√≥n matem√°tica que mide el **error del modelo**, comparando los valores reales con los valores predichos.

Durante el entrenamiento, el objetivo del algoritmo es **minimizar la funci√≥n de coste**, ajustando los par√°metros del modelo.  
En problemas de regresi√≥n, una de las funciones de coste m√°s utilizadas es el **Mean Squared Error (MSE)**.
:::

---

### Mean Absolute Error (MAE)

El **Mean Absolute Error (MAE)** mide el **promedio del valor absoluto de la diferencia entre los valores reales y los valores predichos por el modelo**.

A diferencia del MSE, el MAE **no eleva el error al cuadrado**, por lo que **todos los errores contribuyen de forma proporcional** al resultado final.

Si tenemos un conjunto de $ n $ observaciones:

* $ y_i $: valor real
* $ \hat{y}_i $: valor predicho por el modelo

El MAE se define como:

$$
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} \lvert y_i - \hat{y}_i \rvert
$$

:::tip
Cuanto **menor** sea el MAE, **mejor** es el modelo, porque indica que, de media, el error de las predicciones es menor y el modelo se equivoca menos en las mismas unidades que la variable objetivo.
:::

El MAE indica, de media, **cu√°ntas unidades se equivoca el modelo en sus predicciones**.

Por ejemplo:

* Un MAE de **5** en un problema de predicci√≥n de precios significa que,
  de media, el modelo se equivoca **5 unidades monetarias**.

Esto hace que el MAE sea una m√©trica **muy f√°cil de interpretar**, ya que se
expresa en las **mismas unidades que la variable objetivo**.

---

### Coeficiente de determinaci√≥n (R¬≤)

El **coeficiente de determinaci√≥n (R¬≤)** es una m√©trica utilizada en regresi√≥n que indica **qu√© proporci√≥n de la variabilidad de la variable objetivo es explicada por el modelo**.

A diferencia del MSE o el MAE, el R¬≤ **no mide el error directamente**, sino **la calidad del ajuste global del modelo**.

El R¬≤ compara el modelo entrenado con un modelo muy simple que **siempre predice la media del target**.

* Si el modelo explica bien los datos, el R¬≤ ser√° alto.
* Si el modelo no mejora esa predicci√≥n b√°sica, el R¬≤ ser√° bajo o incluso negativo.

Los valores posibles del R¬≤ son:

* **R¬≤ = 1**
  El modelo explica el 100 % de la variabilidad del target (ajuste perfecto).

* **R¬≤ = 0**
  El modelo no mejora respecto a predecir siempre la media del target.

* **R¬≤ < 0**
  El modelo es peor que predecir la media, lo que indica un ajuste muy deficiente.

Por ejemplo:

* Un **R¬≤ = 0.80** significa que el modelo explica el **80 % de la variabilidad**
  de la variable objetivo.
* El **20 % restante** se debe a factores no capturados por el modelo.


:::info ¬øQu√© es el concepto de variabilidad?

La **variabilidad** de una variable es **cu√°nto cambian sus valores** dentro del dataset.


Imagina dos datasets con la misma media:

* Dataset A

    ```text
    10, 10, 10, 10, 10
    ```

    * Media = 10
    * Variabilidad = **muy baja** (todos los valores son iguales)

* Dataset B

    ```text
    2, 8, 10, 15, 25
    ```

    * Media ‚âà 12
    * Variabilidad = **alta** (los valores est√°n muy dispersos)

üëâ Ambos tienen media similar, pero **no se comportan igual**.

En regresi√≥n, la variabilidad del target indica:

* Cu√°nto **var√≠an los valores reales**
* Qu√© tan dif√≠cil es el problema
* Cu√°nto margen tiene el modelo para ‚Äúexplicar‚Äù los datos

Si el target casi no cambia, **no hay mucho que explicar**.
Si cambia mucho, el modelo debe capturar **patrones m√°s complejos**.

El R¬≤ responde a esta pregunta:

> ¬øCu√°nta de esa variabilidad total consigue explicar el modelo?

* **R¬≤ = 0**
  El modelo no explica nada m√°s que la media.

* **R¬≤ = 0.7**
  El modelo explica el **70 % de la variabilidad** del target.

* **R¬≤ = 1**
  El modelo explica toda la variabilidad.


Piensa en las notas de una clase:

* Si todos sacan un 7 ‚Üí poca variabilidad
* Si hay notas entre 2 y 10 ‚Üí mucha variabilidad

Un buen modelo ser√≠a aquel que **explica por qu√© unos sacan m√°s y otros menos**.
:::

---

### Comparaci√≥n entre MSE, MAE y R¬≤

| M√©trica | Qu√© mide | Penalizaci√≥n de errores grandes | Sensible a outliers | Interpretabilidad | Uso habitual |
|--------|---------|----------------------------------|---------------------|------------------|--------------|
| **MSE** | Error medio al cuadrado | Alta | Alta | Media | Funci√≥n de coste y entrenamiento |
| **MAE** | Error medio absoluto | Baja | Media | Alta | Evaluaci√≥n e interpretaci√≥n |
| **R¬≤** | Variabilidad explicada | No aplica | Baja | Alta | Comparaci√≥n de modelos |
