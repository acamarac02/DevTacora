---
title: "Primer modelo de ML: Titanic"
sidebar_position: 2
description: "Primer ejemplo pr√°ctico de aprendizaje autom√°tico utilizando el dataset del Titanic y el algoritmo KNN. Compararemos un flujo b√°sico y otro completo siguiendo las fases del ciclo de ML."
keywords: [Machine Learning, Titanic, KNN, clasificaci√≥n, scikit-learn, Python, preprocesamiento, EDA]
---

<div class="justify-text">

En este primer ejemplo pr√°ctico vamos a **construir un modelo de clasificaci√≥n** que prediga **si un pasajero del Titanic sobrevivi√≥ o no** utilizando el algoritmo **K-Nearest Neighbors (KNN)**.

Nuestro objetivo no es a√∫n obtener la m√°xima precisi√≥n, sino **comprender la estructura completa de un proyecto de ML** y **visualizar la diferencia** entre:

1. Un modelo b√°sico sin apenas preparaci√≥n (sin EDA ni preprocesamiento).  
2. Un modelo completo siguiendo correctamente el **flujo de trabajo de ML**.


## Material disponible

A continuaci√≥n puedes descargar los dos notebooks que utilizaremos:

| Notebook | Descripci√≥n | Enlace |
|-----------|--------------|--------|
| **TitanicBasico.ipynb** | Versi√≥n m√≠nima: se carga el dataset y se entrena un modelo KNN sin preprocesamiento ni an√°lisis previo. | [Descargar cuaderno](./0-datasets/TitanicSencillo.ipynb) |
| **TitanicCompleto.ipynb** | Implementa el flujo completo: EDA, limpieza de datos, imputaci√≥n de nulos, codificaci√≥n de variables, escalado y entrenamiento del modelo KNN. | [Descargar cuaderno](./0-datasets/TitanicCompleto.ipynb) |

üìÇ **Dataset:** [`titanic.csv`](./0-datasets/titanic.csv)

---

## Contexto del problema

El **conjunto de datos del Titanic** es un cl√°sico en aprendizaje autom√°tico. Cada fila representa un pasajero e incluye informaci√≥n como:

| Columna | Descripci√≥n |
|----------|--------------|
| `Survived` | Variable objetivo (1 = sobrevivi√≥, 0 = no sobrevivi√≥) |
| `Pclass` | Clase del billete (1¬™, 2¬™ o 3¬™) |
| `Sex` | Sexo del pasajero |
| `Age` | Edad |
| `SibSp` | N√∫mero de hermanos/esposos a bordo |
| `Parch` | N√∫mero de padres/hijos a bordo |
| `Fare` | Tarifa pagada |
| `Embarked` | Puerto de embarque (C = Cherbourg, Q = Queenstown, S = Southampton) |

> üìö **Fuente del dataset:** [Titanic ‚Äì Kaggle (Brendan45774)](https://www.kaggle.com/datasets/brendan45774/test-file)

---

## Qu√© hace KNN

El algoritmo [**K-Nearest Neighbors (KNN)**](https://www.geeksforgeeks.org/machine-learning/k-nearest-neighbours/) clasifica una muestra nueva compar√°ndola con sus **K vecinos m√°s cercanos** en el espacio de caracter√≠sticas.

- Si la mayor√≠a de los vecinos pertenecen a la clase ‚Äú1‚Äù (sobrevive), el nuevo ejemplo se clasifica como 1.  
- Si la mayor√≠a pertenecen a ‚Äú0‚Äù (no sobrevive), el resultado ser√° 0.  

üí° Es un m√©todo **basado en distancias**, por lo que **requiere escalar correctamente los datos num√©ricos**.  
En el *notebook completo*, esto se hace con `StandardScaler`, mientras que en el *notebook b√°sico* **no se escala nada**, afectando la precisi√≥n del modelo.


---

## Titanic B√°sico vs Titanic Completo

| Aspecto | TitanicBasico | TitanicCompleto |
|----------|----------------|----------------|
| Exploraci√≥n de datos (EDA) | ‚ùå No se realiza | ‚úÖ An√°lisis de nulos, correlaciones y tipos |
| Preprocesamiento | ‚ùå No se imputan ni codifican variables | ‚úÖ Limpieza, imputaci√≥n y codificaci√≥n adecuadas |
| Escalado | ‚ùå No se normalizan los datos | ‚úÖ Se aplica `StandardScaler` |
| Resultados | üîª Menor precisi√≥n, posibles errores | üü¢ Mejor rendimiento y generalizaci√≥n |
| Aprendizaje pedag√≥gico | Sirve para **entender errores comunes** | Muestra **c√≥mo se hace correctamente** |

### Resumen de resultados

Las m√©tricas de evaluaci√≥n nos permiten determinar las diferencias entre ambos modelos:

| Modelo | Accuracy aproximada | Observaciones |
|---------|---------------------|----------------|
| TitanicBasico | ~0.65 | Datos sin limpiar ni escalar ‚Üí modelo inestable |
| TitanicCompleto | ~0.81 | Datos bien preprocesados ‚Üí modelo m√°s preciso y robusto |

---

## Conclusi√≥n

> La **calidad del preprocesamiento** es tan importante como el propio algoritmo.

Un modelo simple (como KNN) puede ofrecer **resultados excelentes** si seguimos un **flujo de trabajo profesional**, mientras que un modelo mal preparado puede fracasar incluso con buenos algoritmos.

---

## Actividad pr√°ctica: EDA con el dataset Heart Disease

Tu reto consiste en **repetir el mismo proceso que has realizado con el Titanic**, pero aplic√°ndolo al dataset [`heart_disease.csv`](./0-datasets/heart_disease.csv). Puedes obtener m√°s informaci√≥n de este dataset [aqu√≠](https://www.kaggle.com/datasets/redwankarimsony/heart-disease-data).

:::info Objetivos de la tarea

Explorar y visualizar los datos para comprender las variables y sus relaciones. Conc√©ntrate especialmente en la fase de **An√°lisis Exploratorio de Datos (EDA)**.

üîç **Qu√© debes hacer:**
- Carga el dataset y revisa su estructura (`.info()`, `.describe()`, valores nulos, tipos de datos‚Ä¶).  
- Genera **gr√°ficas** que te ayuden a interpretar los patrones:
  - Histogramas o `countplot` para distribuciones.  
  - Boxplots para detectar outliers.  
  - Mapas de calor (`heatmap`) para correlaciones.  
  - Scatterplots o pairplots para relaciones entre variables.
- Describe en tus conclusiones **qu√© relaciones interesantes** has encontrado entre las variables y el target (`heart_disease` = 1 si hay enfermedad, 0 si no).
- Indica qu√© features s√≠ utilizar√≠as para entrenar tu modelo, cu√°les no y por qu√©.

üß† **Opcional (para quien quiera ir m√°s all√°):**

Si te animas, intenta aplicar tambi√©n:
- Preprocesamiento (imputaci√≥n, escalado, codificaci√≥n si fuera necesario).  
- Entrenamiento de un modelo simple (por ejemplo, KNN o Logistic Regression).  
- Evaluaci√≥n b√°sica del modelo (accuracy o matriz de confusi√≥n).

> En esta actividad no se trata de obtener la mayor precisi√≥n, sino de **entender los datos y visualizar patrones**.

:::

</div>