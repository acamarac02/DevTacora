---
title: "Conceptos te√≥ricos y primera red neuronal"
sidebar_position: 1
description: "Fundamentos de c√≥mo funciona una red neuronal por dentro: perceptr√≥n, neurona artificial, pesos, sesgo, funci√≥n de p√©rdida y learning rate."
keywords: [perceptr√≥n, neurona artificial, pesos, bias, funci√≥n de p√©rdida, learning rate, tensores, red neuronal]
---

En este apartado vamos a entender c√≥mo funciona una red neuronal por dentro.  
No vamos a usar todav√≠a matem√°ticas complejas, pero s√≠ vamos a abrir la ‚Äúcaja negra‚Äù.

Nuestro objetivo es que entiendas:

- Qu√© calcula realmente una neurona
- Qu√© son los pesos y el sesgo
- C√≥mo se mide el error
- Qu√© significa entrenar un modelo
- Qu√© papel juega el *learning rate*

Usaremos como ejemplo una red muy sencilla que aprende a convertir grados **Celsius a Fahrenheit**.

:::info V√≠deo recomendado

Si quieres reforzar lo explicado en este apartado, este v√≠deo explica de forma muy clara y visual las bases de las redes neuronales y c√≥mo aprende una primera red sencilla:

https://www.youtube.com/watch?v=iX_on3VxZzk

Es especialmente √∫til para entender el ejemplo de Celsius a Fahrenheit y visualizar c√≥mo se ajustan los pesos durante el entrenamiento.
:::


---

## ¬øQu√© significa entrenar una red neuronal?

Entrenar una red neuronal significa **ajustar sus par√°metros internos para que haga buenas predicciones**.

Para poder hacer esto necesitamos datos etiquetados, es decir, ejemplos en los que conocemos tanto la entrada como la respuesta correcta. A este tipo de enfoque se le llama **aprendizaje supervisado**, porque el modelo aprende comparando sus predicciones con un valor real que act√∫a como referencia.

El proceso general es siempre el mismo:

1. Introducimos un dato o conjuntos de datos (entrada).
2. La red calcula una predicci√≥n.
3. Comparamos la predicci√≥n con el valor real.
4. Medimos el error.
5. Ajustamos los par√°metros internos.
6. Repetimos muchas veces.

En el ejemplo que veremos en Colab:

- Entrada ‚Üí grados Celsius  
- Salida esperada ‚Üí grados Fahrenheit  

La red intentar√° aprender la relaci√≥n correcta entre ambas.

---

## El perceptr√≥n: la neurona m√°s simple

Un perceptr√≥n es la forma m√°s simple de red neuronal: una √∫nica neurona conectada a las entradas, sin capas ocultas. Es el bloque b√°sico sobre el que se construyen las redes neuronales profundas.

Su funcionamiento es muy sencillo:

- Recibe uno o varios valores de entrada.
- Cada entrada tiene un peso asociado.
- Calcula una suma ponderada.
- Produce una salida.

![Gr√°fico EDA](../0-img/perceptron.png)

Matem√°ticamente, el c√°lculo b√°sico es:

$$
salida = \sum_{i=1}^{n} x_i w_i + sesgo
$$

Si solo tenemos una entrada (como Celsius), el modelo es simplemente:

$
F = (C √ó w) + b
$

Donde:
- `w` es el peso
- `b` es el sesgo (bias)

Curiosamente, la f√≥rmula real de conversi√≥n es:

$
F = 1.8C + 32
$

Eso significa que la red deber√° aprender:
- Peso (`w`) ‚âà 1.8  
- Sesgo (`b`) ‚âà 32  

:::warning Limitaci√≥n importante

El perceptr√≥n solo puede resolver **problemas lineales**.

Esto significa que √∫nicamente puede aprender relaciones que puedan representarse mediante una recta (o un hiperplano en dimensiones mayores). En nuestro ejemplo de Celsius ‚Üí Fahrenheit esto funciona perfectamente, porque la relaci√≥n entre ambas variables es lineal.

Sin embargo, si el problema requiere una frontera de decisi√≥n curva o una relaci√≥n no lineal m√°s compleja, un √∫nico perceptr√≥n no ser√° suficiente. Para resolver esos casos necesitaremos redes con varias capas, capaces de modelar relaciones m√°s sofisticadas.
:::

---

### La neurona artificial

Una neurona artificial moderna sigue la misma idea que el perceptr√≥n, pero se usa como bloque de construcci√≥n de redes m√°s grandes.

Cada neurona:

1. Recibe entradas.
2. Multiplica cada entrada por su peso.
3. Suma los resultados.
4. A√±ade un sesgo.
5. Produce una salida.

En redes m√°s complejas se a√±ade una **funci√≥n de activaci√≥n**, pero en nuestro ejemplo de Celsius ‚Üí Fahrenheit estamos ante un problema lineal, por lo que basta con una relaci√≥n lineal simple.

Lo importante aqu√≠ es entender que:

üëâ Una neurona no ‚Äúentiende‚Äù los datos.  
üëâ Solo hace operaciones matem√°ticas simples.

---

### Pesos y sesgo

Los **pesos** determinan cu√°nto influye cada entrada en el resultado final.

* Si un peso es grande, esa entrada tiene mucha influencia.  
* Si es peque√±o, tiene poca.

El **sesgo (bias)** permite desplazar la funci√≥n.  
Sin √©l, la recta siempre pasar√≠a por el origen.

![Gr√°fico EDA](../0-img/grafica-lineal.png)

En nuestro ejemplo:

- El peso ajusta la pendiente.
- El sesgo ajusta el desplazamiento vertical.

Y lo m√°s importante:

üëâ Los pesos y el sesgo son lo que la red aprende durante el entrenamiento.

:::info Relaci√≥n con la regresi√≥n lineal

Como ya has trabajado con regresi√≥n lineal, notar√°s que esto es exactamente la misma estructura matem√°tica:

$$
y = mx + b
$$

En regresi√≥n lineal:
- `m` es la pendiente.
- `b` es la ordenada en el origen.

En una neurona:
- El peso (`w`) cumple el papel de la pendiente.
- El sesgo (`b`) cumple el papel del t√©rmino independiente.

De hecho, un perceptr√≥n sin funci√≥n de activaci√≥n no lineal es, en esencia, un modelo de regresi√≥n lineal expresado en forma de neurona artificial.
:::

---

## De una neurona a una red

Una red neuronal no es m√°s que muchas neuronas conectadas entre s√≠ y organizadas en capas:

- Capa de entrada
- Capas ocultas
- Capa de salida

La informaci√≥n fluye desde la entrada hasta la salida. A este proceso se le llama **forward pass**.

En nuestro primer ejemplo solo usamos:

- Una entrada
- Una neurona
- Una salida

Pero el mecanismo interno es el mismo que en redes m√°s profundas.

---

## Funci√≥n de p√©rdida (loss function)

Para que la red pueda mejorar, necesita saber qu√© tan mal lo est√° haciendo. Ah√≠ entra la **funci√≥n de p√©rdida (loss function)**.

La funci√≥n de p√©rdida mide la diferencia entre:

- El valor real
- El valor predicho

En problemas de **regresi√≥n**, como Celsius ‚Üí Fahrenheit, es com√∫n usar el **error cuadr√°tico medio (MSE)**. Esta funci√≥n penaliza m√°s los errores grandes y permite medir qu√© tan lejos est√°n nuestras predicciones de los valores reales.

En problemas de **clasificaci√≥n**, las funciones de p√©rdida m√°s habituales son **Binary Cross-Entropy** (para clasificaci√≥n binaria) y **Categorical Cross-Entropy** (para m√∫ltiples clases). Estas funciones no miden simplemente una distancia num√©rica, sino qu√© tan buena es la probabilidad que el modelo asigna a la clase correcta.

Por ello, el resultado de la funci√≥n de p√©rdida depender√° de: 

* Si la predicci√≥n est√° muy lejos del valor real ‚Üí p√©rdida alta.  
* Si est√° cerca ‚Üí p√©rdida baja.

El objetivo del entrenamiento es **minimizar la funci√≥n de p√©rdida**.

Ahora bien, ¬ødebe llegar a cero?

- En algunos problemas simples (como nuestro ejemplo lineal), podr√≠a acercarse mucho a 0.
- En problemas reales, especialmente con datos complejos, lo normal es que nunca llegue exactamente a 0.

De hecho, una p√©rdida exactamente 0 en datos de entrenamiento puede ser una se√±al de que el modelo est√° memorizando los datos en lugar de aprender patrones generales. Por eso, m√°s adelante veremos la importancia de evaluar tambi√©n el rendimiento en datos que el modelo no ha visto (test).

En la pr√°ctica, el modelo se entrena con un conjunto de datos (train) y se eval√∫a con otro distinto (test) para comprobar que generaliza correctamente.

En resumen, la red intenta encontrar los valores de los pesos y el sesgo que hagan que la p√©rdida sea lo m√°s peque√±a posible.

---

## √âpocas (Epochs)

Una red neuronal no aprende con una sola pasada por los datos.

El entrenamiento consiste en repetir el proceso completo varias veces. Cada vez que el modelo recorre todo el conjunto de datos una vez, decimos que ha completado una **√©poca (epoch)**.

En cada √©poca:

1. La red hace predicciones.
2. Se calcula la p√©rdida.
3. Se ajustan los pesos y el sesgo.

Al principio la p√©rdida suele ser alta.  
A medida que avanzan las √©pocas, el modelo deber√≠a ir reduciendo esa p√©rdida progresivamente.

Elegir el n√∫mero de √©pocas es importante:

- Muy pocas ‚Üí el modelo no aprende lo suficiente.
- Demasiadas ‚Üí puede empezar a memorizar los datos (sobreajuste).

En nuestro ejemplo de Celsius ‚Üí Fahrenheit, veremos c√≥mo tras varias √©pocas el modelo ajusta sus par√°metros hasta aproximarse a la f√≥rmula correcta.

---

## Learning rate

El **learning rate (tasa de aprendizaje)** controla cu√°nto se ajustan los pesos en cada √©poca.

Si es:

- üî∫ Muy grande ‚Üí el modelo puede volverse inestable y no converger.
- üîª Muy peque√±o ‚Üí el entrenamiento ser√° muy lento.

Es como bajar una monta√±a:

- Pasos demasiado grandes ‚Üí puedes tropezar y caerte.
- Pasos demasiado peque√±os ‚Üí tardas mucho en llegar.

Elegir bien el learning rate es clave para que el modelo aprenda correctamente.

:::info ¬øC√≥mo se ajustan realmente los pesos?

El ajuste de los pesos no ocurre ‚Äúm√°gicamente‚Äù. Intervienen dos elementos clave:

1. **Backpropagation**: calcula cu√°nto ha contribuido cada peso al error cometido. Es decir, determina en qu√© direcci√≥n deber√≠an modificarse los pesos para reducir la p√©rdida.
2. **Optimizador** (como el descenso por gradiente o Adam): utiliza esa informaci√≥n para actualizar los pesos y el sesgo.

Aqu√≠ es donde entra el **learning rate**: controla el tama√±o del paso que da el optimizador en cada actualizaci√≥n.

- Si el learning rate es grande ‚Üí los pesos cambian mucho en cada paso.
- Si es peque√±o ‚Üí los cambios son m√°s suaves y controlados.

En resumen:
Backpropagation calcula *c√≥mo* deben cambiar los pesos, el optimizador decide *actualizarlos*, y el learning rate determina *cu√°nto* se modifican en cada paso.

En el siguiente apartado veremos este proceso con m√°s detalle.
:::


---

## El ciclo de entrenamiento

Podemos resumir todo el proceso as√≠:

1. La red recibe una entrada.
2. Calcula una predicci√≥n.
3. Se calcula la p√©rdida.
4. Se ajustan pesos y sesgo.
5. Se repite muchas veces.

Tras suficientes iteraciones, el modelo encuentra valores de peso y sesgo que minimizan el error.

En nuestro ejemplo, idealmente terminar√° cerca de:

```

peso ‚âà 1.8
sesgo ‚âà 32

```

---

## Ejemplo pr√°ctico: Celsius ‚Üí Fahrenheit

En el Colab implementaremos una red neuronal muy simple (un perceptr√≥n) con:

- Una entrada
- Una neurona
- Un peso
- Un sesgo

El modelo comenzar√° con valores aleatorios, por lo que al principio sus predicciones ser√°n incorrectas. A medida que avancen las √©pocas, ir√° ajustando el peso y el sesgo para reducir la p√©rdida y aproximarse a la relaci√≥n real entre Celsius y Fahrenheit.

Sin que le proporcionemos expl√≠citamente la ecuaci√≥n, la red terminar√° encontrando valores cercanos a:

$$
F = 1.8C + 32
$$

Eso es entrenar una red neuronal: ajustar par√°metros internos hasta minimizar el error.

M√°s adelante probaremos tambi√©n una red ligeramente m√°s compleja, con una capa oculta. Resolver√° el mismo problema, pero con una estructura m√°s potente. Sin embargo, al aumentar el n√∫mero de pesos y sesgos, la soluci√≥n deja de ser tan f√°cilmente interpretable como una simple ecuaci√≥n lineal.

üëâ **Puedes abrir el cuaderno aqu√≠:**
[Colab: Primera red neuronal](../0-colab/primera_red_neuronal.ipynb)

---

## Actividad de seguimiento

Piensa en **otro problema que tenga una relaci√≥n lineal** entre la entrada y la salida.

Una vez elegido el problema:

1. Define un peque√±o conjunto de datos de ejemplo (entrada y salida esperada).
2. Crea una red neuronal sencilla (un perceptr√≥n).
3. Entrena el modelo.
4. Comprueba qu√© peso y sesgo ha aprendido.
5. Verifica si se aproxima a la f√≥rmula real.
6. Prueba con una arquitectura m√°s compleja.

Ve jugando con los hiperpar√°metros para conseguir los mejores resultados.

