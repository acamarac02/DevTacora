---
title: "Funciones de activaci√≥n y Backpropagation"
sidebar_position: 2
description: "C√≥mo una red neuronal introduce no linealidad y c√≥mo aprende realmente mediante descenso por gradiente y backpropagation."
keywords: [funci√≥n de activaci√≥n, ReLU, sigmoid, tanh, softmax, gradiente, descenso por gradiente, backpropagation, vanishing gradient]
---

En el apartado anterior entendimos:

- Qu√© calcula una neurona
- Qu√© son los pesos y el sesgo
- C√≥mo se mide el error
- Qu√© es el learning rate

Ahora vamos a responder dos preguntas fundamentales:

1. ¬øC√≥mo puede una red neuronal modelar relaciones complejas?
2. ¬øC√≥mo sabe la red qu√© pesos debe modificar para aprender?

Este tema se divide en dos grandes bloques:

- üîµ **Funciones de activaci√≥n** ‚Üí permiten romper la linealidad.
- üî¥ **Backpropagation y descenso por gradiente** ‚Üí explican c√≥mo aprende la red.

---

# üîµ BLOQUE 1 ‚Äî Funciones de activaci√≥n

## El problema de la linealidad

Recordemos la f√≥rmula b√°sica de una neurona:

$$
z = \sum x_i w_i + b
$$

Si apilamos muchas neuronas pero todas hacen solo esta operaci√≥n lineal, el resultado final sigue siendo una funci√≥n lineal.

üëâ La composici√≥n de funciones lineales sigue siendo lineal.

Eso significa que, sin algo m√°s, una red con muchas capas ser√≠a equivalente a una simple regresi√≥n lineal.

Necesitamos introducir **no linealidad**.

---

## ¬øQu√© es una funci√≥n de activaci√≥n?

Una funci√≥n de activaci√≥n se aplica despu√©s de la suma ponderada:

$$
z = \sum x_i w_i + b
$$
$$
a = f(z)
$$

Su objetivo es:

- Introducir no linealidad
- Permitir que la red modele patrones complejos
- Hacer que m√∫ltiples capas tengan sentido matem√°tico

Sin funciones de activaci√≥n, no existir√≠a el deep learning tal como lo conocemos.

---

## Sigmoid

La funci√≥n sigmoid transforma cualquier n√∫mero real en un valor entre 0 y 1.

\[
\sigma(x) = \frac{1}{1 + e^{-x}}
\]

- Rango: (0, 1)
- Se puede interpretar como probabilidad
- Fue muy utilizada en las primeras redes neuronales

Problema:

En valores muy grandes o muy peque√±os, su derivada se aproxima a 0.  
Esto provoca el **vanishing gradient** en redes profundas.

---

## Tanh

La funci√≥n tangente hiperb√≥lica es similar a sigmoid pero centrada en 0.

- Rango: (-1, 1)
- Centrada en cero
- Suele comportarse mejor que sigmoid

Aun as√≠, tambi√©n puede sufrir problemas de gradiente en redes profundas.

---

## ReLU

ReLU (Rectified Linear Unit) es actualmente la activaci√≥n m√°s utilizada en deep learning.

\[
ReLU(x) = \max(0, x)
\]

Ventajas:

- Muy simple computacionalmente
- Derivada sencilla
- Reduce el problema del vanishing gradient

Problema:

- Puede producir el fen√≥meno conocido como **dying ReLU** si una neurona queda siempre en valores negativos.

Aun as√≠, es el est√°ndar en capas ocultas.

---

## Softmax (en capa de salida)

En problemas de clasificaci√≥n multiclase se usa softmax en la capa final.

Convierte un conjunto de valores en probabilidades cuya suma es 1.

Se usa junto con la funci√≥n de p√©rdida **Categorical Cross-Entropy**.

---

## Idea clave del bloque

Las funciones de activaci√≥n permiten que una red neuronal deje de ser un simple modelo lineal y pueda representar relaciones complejas.

Sin activaciones no hay profundidad real.

---

# üî¥ BLOQUE 2 ‚Äî Backpropagation y Descenso por Gradiente

Ya sabemos representar cosas complejas.

Ahora necesitamos entender c√≥mo aprende la red.

---

## Recordatorio: queremos minimizar la p√©rdida

Durante el entrenamiento:

1. La red hace una predicci√≥n.
2. Calculamos la p√©rdida.
3. Ajustamos los pesos.

Pero surge una pregunta clave:

üëâ ¬øC√≥mo sabe la red cu√°nto debe modificar cada peso?

---

## Intuici√≥n del gradiente

Imagina que la funci√≥n de p√©rdida es una monta√±a.

- Cada punto representa una combinaci√≥n de pesos.
- La altura representa el error.
- Queremos bajar hasta el m√≠nimo.

El **gradiente** indica la direcci√≥n de mayor subida.

Si queremos minimizar la p√©rdida, debemos movernos en la direcci√≥n contraria al gradiente.

Esto es el **descenso por gradiente**.

---

## ¬øQu√© es una derivada?

La derivada mide cu√°nto cambia una funci√≥n si modificamos ligeramente una variable.

En nuestro caso:

- ¬øCu√°nto cambia la p√©rdida si modifico un peso?
- ¬øEse cambio aumenta o reduce el error?

La derivada nos da esa informaci√≥n.

---

## ¬øQu√© es backpropagation?

Backpropagation es el algoritmo que permite calcular de forma eficiente todas las derivadas necesarias en una red neuronal.

Se basa en la **regla de la cadena**.

En lugar de calcular derivadas de forma aislada, el error se propaga desde la salida hacia atr√°s.

Proceso conceptual:

1. Forward pass ‚Üí calcular predicci√≥n.
2. Calcular la p√©rdida.
3. Calcular el gradiente en la salida.
4. Propagar el error hacia atr√°s.
5. Actualizar pesos.

---

## Regla de la cadena (idea intuitiva)

En una red profunda:

- Un peso de una capa inicial afecta indirectamente a la salida.
- La p√©rdida depende de m√∫ltiples operaciones encadenadas.

La regla de la cadena permite descomponer esa dependencia en peque√±os pasos.

Por eso el error puede propagarse hacia atr√°s capa por capa.

---

## Ciclo completo de aprendizaje

Podemos resumir todo el proceso as√≠:

```

Entrada
‚Üì
Pesos + Sesgo
‚Üì
Activaci√≥n
‚Üì
Salida
‚Üì
C√°lculo de p√©rdida
‚Üì
Gradiente
‚Üì
Backpropagation
‚Üì
Actualizaci√≥n de pesos
‚Üì
Repetir

```

Ese ciclo se repite durante muchas √©pocas hasta minimizar la p√©rdida.

---

## Vanishing y Exploding Gradient

En redes profundas pueden aparecer dos problemas:

### Vanishing gradient
El gradiente se vuelve muy peque√±o al propagarse hacia atr√°s.  
Las primeras capas apenas aprenden.

Es com√∫n con sigmoid y tanh.

### Exploding gradient
El gradiente se vuelve demasiado grande.  
Los pesos se actualizan de forma inestable.

ReLU ayuda a mitigar el problema del gradiente que se desvanece.

---

# Conexi√≥n final

Ahora ya entiendes:

- C√≥mo una red puede representar funciones complejas (activaciones).
- C√≥mo ajusta sus par√°metros para minimizar el error (backpropagation).
- Por qu√© el learning rate es importante.
- Por qu√© la elecci√≥n de la activaci√≥n influye en el aprendizaje.

A partir de aqu√≠, cuando entrenemos redes m√°s profundas, ya no ser√°n una caja negra.

Sabremos qu√© est√° ocurriendo internamente.

---

:::info V√≠deo recomendado

Para reforzar visualmente la explicaci√≥n de backpropagation, te recomiendo ver el siguiente v√≠deo:

https://www.youtube.com/watch?v=_0wdproot34&t=2s

Explica de forma extremadamente clara c√≥mo se propaga el error en una red neuronal y c√≥mo se aplican las derivadas mediante la regla de la cadena.
:::
```






Contenido te√≥rico:
* Funciones activaci√≥n
* Backpropagation

Seguir v√≠deo: https://www.youtube.com/watch?v=_0wdproot34&t=2s

Jugar con Tensorflow playgroung