---
title: "Redes Densas para Clasificaci贸n"
sidebar_position: 2
description: "C贸mo utilizar redes neuronales densas (MLP) para predecir clases o categor铆as. Diferencias entre clasificaci贸n binaria y multiclase."
keywords: [clasificaci贸n, redes densas, MLP, Titanic, Iris, accuracy, crossentropy, softmax, sigmoid]
---

En el apartado anterior vimos c贸mo utilizar una Red Neuronal Densa (MLP) para resolver problemas de regresi贸n (predecir un n煤mero continuo).

**La arquitectura base y el proceso de entrenamiento son casi id茅nticos** para problemas de clasificaci贸n. Seguimos necesitando:
* una capa de entrada acorde a nuestras *features*
* capas ocultas con funci贸n de activaci贸n ReLU
* un bucle de entrenamiento por *batches* validado 茅poca a 茅poca.

Sin embargo, cuando el objetivo cambia de "predecir un n煤mero" a "predecir una categor铆a" (por ejemplo, si un email es spam o no, o de qu茅 especie es una planta), necesitamos ajustar la fase final de nuestra red.

En este apartado vamos a centrarnos exclusivamente en **qu茅 cambia** cuando pasamos a la clasificaci贸n.

---

## Recordatorio: Los Dos Grandes Tipos de Clasificaci贸n

En Machine Learning, los problemas de clasificaci贸n se dividen principalmente en dos grupos, y la configuraci贸n de nuestra red depender谩 de ante cu谩l estemos:

1.  **Clasificaci贸n Binaria:** Solo hay dos resultados posibles.
    *   *Ejemplo:* 驴Sobrevivir谩 este pasajero del Titanic? (S铆 / No).
    *   *Ejemplo:* 驴Es este tumor maligno? (Maligno / Benigno).
2.  **Clasificaci贸n Multiclase:** Hay tres o m谩s resultados posibles, y son excluyentes entre s铆.
    *   *Ejemplo:* 驴De qu茅 especie es esta flor Iris? (Setosa / Versicolor / Virginica).
    *   *Ejemplo:* 驴Qu茅 n煤mero aparece en esta imagen? (0, 1, 2, 3, 4, 5, 6, 7, 8 o 9).

---

## Arquitectura para Clasificaci贸n: La Capa de Salida

Mientras que las capas ocultas siguen usando ReLU (o tanh, puedes ir probando diferentes funciones de activaci贸n) y se dimensionan seg煤n la complejidad del problema, la capa de salida cambia dr谩sticamente respecto a la regresi贸n.

### A. Para Clasificaci贸n Binaria

En clasificaci贸n binaria, queremos que la red nos devuelva la **probabilidad** de que el ejemplo pertenezca a la clase positiva (clase 1).

*   **N煤mero de neuronas:** **1** (nos basta un n煤mero para expresar una probabilidad, ej: 0.85 significa 85% de probabilidad de ser clase 1).
*   **Funci贸n de Activaci贸n:** **`sigmoid`**.
    *   La funci贸n *Sigmoide* "aplasta" cualquier n煤mero real de entrada y lo transforma en un valor exactamente entre 0 y 1.

```python
# Capa de salida para Clasificaci贸n Binaria
layers.Dense(1, activation='sigmoid')
```

![Gr谩fica](../0-img/fa-sigmoid.png)

### B. Para Clasificaci贸n Multiclase

En clasificaci贸n multiclase, queremos que la red nos devuelva un vector con las probabilidades de pertenecer a *cada una* de las clases posibles.

*   **N煤mero de neuronas:** **N** (tantas neuronas como clases posibles haya en el target). Si predecimos 3 especies de flores, necesitamos 3 neuronas.
*   **Funci贸n de Activaci贸n:** **`softmax`**.
    *   La funci贸n *Softmax* toma las salidas de las N neuronas y las transforma en probabilidades (entre 0 y 1) de forma que **la suma de todas ellas sea exactamente 1.0 (100%)**.
    *   La clase predicha ser谩 la que obtenga la probabilidad m谩s alta.

```python
# Capa de salida para Clasificaci贸n Multiclase (ej: 3 clases)
layers.Dense(3, activation='softmax')
```

![Gr谩fica](../0-img/softmax.png)

---

## Configuraci贸n del Entrenamiento

Dado que ya no predecimos n煤meros continuos, m茅tricas como el MSE (Error Cuadr谩tico Medio) no tienen sentido. Necesitamos nuevas formas de medir el error (Loss) y el 茅xito (Metrics).

### Cambios en la Funci贸n de P茅rdida (Loss)

*   **Para Clasificaci贸n Binaria:** Usamos **`binary_crossentropy`**.
    *   Mide lo lejos que est谩 la probabilidad predicha (ej. 0.9) del valor real (que siempre es 0 o 1). 
    * Penaliza fuertemente a la red si predice con mucha confianza la clase equivocada.
*   **Para Clasificaci贸n Multiclase:** Usamos **`categorical_crossentropy`** o **`sparse_categorical_crossentropy`**.
    *   La elecci贸n entre una y otra depende exclusivamente de c贸mo hayamos preprocesado nuestra variable objetivo (Target Y), como veremos en la siguiente secci贸n.

### Nuevas M茅tricas

*   **`accuracy` (Exactitud):** Es la m茅trica est谩ndar. Nos dice qu茅 porcentaje de predicciones fueron correctas. Si de 100 predice bien 85, el *accuracy* es del 85%.

```python
# 1. Compilar modelo Binario
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 2. Compilar modelo Multiclase
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
```

---

## Preprocesamiento: El Tratamiento del Target

En regresi贸n, la variable objetivo ya era un n煤mero (ej. d贸lares). En clasificaci贸n, suele venir como texto ('sobrevive', 'muere' o 'setosa', 'virginica'). Las redes neuronales **solo entienden n煤meros**, as铆 que hay que transformarlo.

### A. Target para Clasificaci贸n Binaria

Debemos convertir las dos clases en `0` y `1`. Suele bastar con un simple mapeo o un `LabelEncoder`.

### B. Target para Clasificaci贸n Multiclase

Aqu铆 tenemos dos opciones para codificar la variable objetivo, y esta decisi贸n dictar谩 qu茅 "*loss function*" debemos usar:

1.  **Label Encoding (Targets como enteros):** Convertimos las clases en n煤meros enteros (Ej: Setosa=0, Versicolor=1, Virginica=2).
    *   Si preprocesamos as铆, en `compile` debemos usar la loss: **`sparse_categorical_crossentropy`**.
2.  **One-Hot Encoding (Targets como vectores booleanos):** Convertimos la columna del target en N columnas con ceros y un uno. (Ej: Setosa = [1, 0, 0], Versicolor = [0, 1, 0]).
    *   Si preprocesamos as铆, en `compile` debemos usar la loss: **`categorical_crossentropy`** (sin el *sparse*).

:::tip 驴Qu茅 codificaci贸n elegimos?
Ambas aproximaciones entrenan igual de bien, pero **hoy en d铆a se prefiere usar enteros (`LabelEncoder`)** porque ahorra memoria RAM.
:::

---

## Evaluaci贸n de Modelos: M谩s all谩 del Accuracy

Aunque el `accuracy` es la m茅trica principal para Keras, en el mundo real a menudo es enga帽osa. 

Imagina un test m茅dico para detectar una enfermedad muy rara que solo tiene 1 de cada 100 personas. Si un modelo simplemente predice "Nadie est谩 enfermo" (predice clase 0 siempre), su `accuracy` ser谩 del 99%. Parece un modelo excelente, pero en realidad es in煤til: no detecta ning煤n enfermo.

Por eso, una vez entrenado el modelo, utilizamos herramientas cl谩sicas de Machine Learning para evaluarlo correctamente.

### La Matriz de Confusi贸n

La matriz de confusi贸n nos permite ver exactamente en qu茅 se equivoca nuestro modelo, desglosando los errores en:

*   **Verdaderos Positivos (TP):** Predijo 1 y era 1.
*   **Verdaderos Negativos (TN):** Predijo 0 y era 0.
*   **Falsos Positivos (FP):** Predijo 1 pero era 0 (Error Tipo I). *Ej: Le dices a alguien sano que est谩 enfermo.*
*   **Falsos Negativos (FN):** Predijo 0 pero era 1 (Error Tipo II). *Ej: Le dices a un enfermo que est谩 sano.*

Dependiendo del problema de negocio, nos interesar谩 minimizar m谩s los FP o los FN.

---

## En qu茅 fijarnos en Tensorboard

En problemas de clasificaci贸n, Tensorboard nos ofrece gr谩ficas clave para evaluar c贸mo est谩 aprendiendo nuestro modelo durante el entrenamiento. Al igual que vimos en regresi贸n, **la vista recomendada es la pesta帽a "Time Series"** (o "Scalars" en su defecto) para monitorizar la evoluci贸n a lo largo de las 茅pocas.

Es fundamental monitorizar tanto el conjunto de entrenamiento (`train`) como el de validaci贸n (`validation`) para detectar posibles problemas durante el aprendizaje.

Las dos gr谩ficas principales a las que debemos prestar atenci贸n son:

### 1. Gr谩fica de `epoch_accuracy` (Exactitud)

*   **驴Qu茅 informaci贸n aporta?:** Muestra el porcentaje de predicciones correctas que realiza el modelo en cada 茅poca. 
*   **驴Qu茅 debemos buscar?:** 
    *   Queremos que la curva suba r谩pidamente en las primeras 茅pocas y luego se estabilice en un valor alto.
    *   La l铆nea de validaci贸n debe mantenerse siempre cerca de la l铆nea de entrenamiento.
    *   **Peligro de Overfitting:** Si el `accuracy` de entrenamiento sigue subiendo hacia el 100% pero el `accuracy` de validaci贸n se estanca o incluso empieza a bajar, el modelo est谩 memorizando los datos de entrenamiento y perdiendo su capacidad para generalizar en datos nuevos.

### 2. Gr谩fica de `epoch_loss` (P茅rdida)

*   **驴Qu茅 informaci贸n aporta?:** Muestra el valor de la funci贸n de p茅rdida (`binary_crossentropy` o `categorical_crossentropy`). Representa la magnitud de los errores cometidos. Valores m谩s bajos indican un mejor ajuste a los datos.
*   **驴Qu茅 debemos buscar?:**
    *   Al igual que en regresi贸n, ambas curvas (entrenamiento y validaci贸n) deben descender progresivamente a medida que avanzan las 茅pocas.
    *   **Peligro de Overfitting:** Este es el indicador m谩s claro. Si la p茅rdida de entrenamiento sigue bajando pero la curva de p茅rdida de validaci贸n llega a un m铆nimo y luego **comienza a subir**, el modelo ha empezado a sobreajustarse. Ese punto m铆nimo es el ideal para detener el entrenamiento y recuperar los pesos, lo cual logramos f谩cilmente aplicando *Early Stopping*.

---

## Demostraciones Pr谩cticas

A continuaci贸n tienes dos cuadernos de Colab listos para ejecutarse donde se aplican estos conceptos:

### Caso Pr谩ctico 1: Clasificaci贸n Binaria (Titanic)
El dataset del Titanic es el ejemplo cl谩sico de clasificaci贸n binaria. A partir de la edad, sexo y tipo de billete, intentamos predecir si un pasajero **sobrevivi贸 (1) o no (0)**.
En esta demo ver谩s:
*   Preprocesamiento para clases binarias.
*   Construcci贸n de la red con salida `sigmoid`.
*   Uso de `binary_crossentropy` y `accuracy`.
*   Dibujado de la Matriz de Confusi贸n.

 **[Ver cuaderno Titanic en Colab](../0-colab/titanic_binaria_redes_densas.ipynb)**   

### Caso Pr谩ctico 2: Clasificaci贸n Multiclase (Iris Species)
El dataset Iris consiste en predecir de qu茅 **especie (Setosa, Versicolor o Virginica)** es una flor midiendo la longitud y anchura de sus p茅talos.
En esta demo ver谩s:
*   Preprocesamiento del target con `LabelEncoder` (clases 0, 1, 2).
*   Construcci贸n de la red con 3 neuronas de salida y activaci贸n `softmax`.
*   Uso de `sparse_categorical_crossentropy`.

 **[Ver cuaderno Iris en Colab](../0-colab/iris_multiclase_redes_densas.ipynb)**

---

## Actividad de seguimiento

Para poner en pr谩ctica los conocimientos de clasificaci贸n binaria, utiliza el dataset de **Empleados (Attrition)** que utilizamos en unidades anteriores.

 **[CSV empleados](../0-colab/employee.csv)**

El objetivo es entrenar una Red Neuronal Densa que prediga si un empleado **abandonar谩 la empresa o no** (`Attrition` = Yes o No).

1.  **Carga y Preprocesamiento:** Carga el dataset, trata los valores nulos (si los hay), codifica las variables categ贸ricas (como *Department* o *JobRole*) y estandariza las variables num茅ricas. Esto ya lo deber铆as tener hecho. No olvides recodificar la variable objetivo (Attrition) a 0 y 1 (si no lo est谩 ya).
2.  **Entrenamiento Controlado:** Divide tu dataset en entrenamiento y test. Define varias arquitecturas de redes neuronales apropiadas. Entrena tu modelo utilizando **TensorBoard** y monitoriza el progreso.
3.  **Evaluaci贸n Realista:** Una vez finalizado el entrenamiento, muestra las gr谩ficas de p茅rdida (loss) desde TensorBoard. A continuaci贸n, eval煤a el modelo utilizando el conjunto de Test. Adem谩s del *accuracy*, dibuja la **Matriz de Confusi贸n** y determina cu谩l es la arquitectura que obtiene mejores resultados para tu dataset.