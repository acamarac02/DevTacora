---
title: "Redes Densas para Regresi√≥n"
sidebar_position: 1
description: "C√≥mo utilizar redes neuronales densas (MLP) para predecir valores continuos. Arquitectura, funciones de activaci√≥n y m√©tricas clave."
keywords: [regresi√≥n, redes densas, MLP, California Housing, MSE, MAE, ReLU, TensorBoard]
---

En las unidades anteriores hemos visto c√≥mo funciona una neurona individual y c√≥mo se entrena mediante el descenso de gradiente. Pero una sola neurona (perceptr√≥n) tiene una limitaci√≥n fundamental: solo puede aprender relaciones lineales.

Para resolver problemas complejos, necesitamos conectar muchas neuronas en capas, formando lo que se conoce como **Red Neuronal Densa** o **Perceptr√≥n Multicapa (MLP)**.

En este apartado vamos a ver c√≥mo configurar estas redes para resolver problemas de **regresi√≥n**, es decir, cuando queremos predecir un valor num√©rico continuo (como el precio de una casa, la temperatura de ma√±ana o la demanda de electricidad).

---

## ¬øQu√© es una Red Neuronal Densa?

Una red densa (*Fully Connected Layer* o *Dense Layer*) es aquella en la que **cada neurona de una capa est√° conectada con todas las neuronas de la capa siguiente**.

Es la arquitectura m√°s b√°sica y fundamental del Deep Learning. Su potencia reside en que, al apilar varias capas con funciones de activaci√≥n no lineales (como ReLU), la red puede aprender a aproximar cualquier funci√≥n matem√°tica compleja, no solo l√≠neas rectas.

![Gr√°fico EDA](../0-img/nn-architecture.png)

---

##  Arquitectura para Regresi√≥n

Cuando dise√±amos una red para un problema de regresi√≥n, la arquitectura suele seguir un patr√≥n est√°ndar:

### A. Capa de Entrada (Input)
El n√∫mero de neuronas de entrada debe coincidir con el n√∫mero de **caracter√≠sticas (features)** de nuestros datos.
* Si nuestro dataset tiene 8 columnas de datos (como en California Housing), la capa de entrada tendr√° 8 neuronas.

### B. Capas Ocultas (Hidden Layers)
Aqu√≠ es donde ocurre la "magia".
* **N√∫mero de capas y neuronas**: Depende de la complejidad del problema. Para problemas sencillos, 1 o 2 capas con 32-64 neuronas suelen funcionar bien.
* **Funci√≥n de Activaci√≥n**: El est√°ndar hoy en d√≠a es **ReLU** (*Rectified Linear Unit*). Es eficiente y funciona muy bien para permitir que la red aprenda relaciones no lineales.

### C. Capa de Salida (Output)
Esta es la parte cr√≠tica que diferencia a la regresi√≥n de la clasificaci√≥n.
* **N√∫mero de neuronas**: **1** (porque queremos predecir un √∫nico valor num√©rico).
* **Funci√≥n de Activaci√≥n**: **Ninguna (Lineal)**.
    * No usamos Sigmoid o Tanh porque estas comprimen la salida a rangos limitados ([0,1] o [-1,1]).
    * Queremos que la red pueda predecir cualquier valor real (por ejemplo, un precio de 500.000\$ o una temperatura de -15¬∫C), por lo que dejamos que la neurona devuelva el valor tal cual lo calcula la suma ponderada: $y = \sum (w_i x_i) + b$.

---

## Configuraci√≥n del Entrenamiento

Para entrenar una red de regresi√≥n, necesitamos configurar el compilador del modelo con los siguientes elementos:

### Funci√≥n de P√©rdida (Loss Function)
Es la m√©trica que el optimizador intentar√° minimizar. Las m√°s comunes en regresi√≥n son:

* **MSE (Mean Squared Error)**: Calcula el promedio de los errores al cuadrado. Penaliza mucho los errores grandes (outliers). Es la m√°s habitual en regresi√≥n.
* **MAE (Mean Absolute Error)**: Calcula el promedio del valor absoluto de los errores. Es menos sensible a outliers que el MSE.

### Optimizador
Como vimos en la teor√≠a, el algoritmo que ajusta los pesos. El est√°ndar de facto para empezar es **Adam**, ya que gestiona autom√°ticamente el *learning rate* de forma adaptativa.

### M√©tricas
Son valores que *nosotros* leemos para entender qu√© tan bien funciona el modelo (aunque no se usan directamente para optimizar).
* **MAE** es muy interpretable: nos dice, de media, cu√°nto nos estamos equivocando en las unidades originales (por ejemplo, "nos equivocamos en 20.000$ de media").
* **RMSE** (Ra√≠z del error cuadr√°tico medio): Muy usada tambi√©n para tener una medida de error en las mismas unidades que la variable objetivo.

---

## Caso de Estudio: California Housing

Para poner en pr√°ctica estos conceptos, en la siguiente demo utilizaremos el famoso dataset **California Housing**.

### El Problema
El objetivo es predecir el **precio medio de las viviendas** en un distrito de California, bas√°ndonos en datos del censo de 1990.

Las caracter√≠sticas (features) incluyen:
* Ingreso medio en el bloque (MedInc)
* Antig√ºedad media de las casas (HouseAge)
* N√∫mero medio de habitaciones (AveRooms)
* Latitud y Longitud
* Poblaci√≥n, etc.

### La Importancia de la Estandarizaci√≥n
A diferencia de los modelos basados en √°rboles (como Random Forest o XGBoost), las redes neuronales son **muy sensibles a la escala de los datos**.

Si una variable tiene valores entre 0-1 (como una proporci√≥n) y otra tiene valores entre 1.000-100.000 (como ingresos), la red tendr√° dificultades para converger, ya que los pesos asociados a la variable grande tendr√°n que ser muy peque√±os y el gradiente ser√° inestable.

:::important Regla de Oro
En Deep Learning, **siempre** debemos estandarizar o normalizar los datos de entrada para que tengan una escala similar (por ejemplo, media 0 y desviaci√≥n est√°ndar 1).
:::

---

## An√°lisis de Experimentos: TensorBoard

Cuando entrenamos redes neuronales, a menudo probamos muchas configuraciones distintas:
* ¬øMejor con 1 capa oculta o con 3?
* ¬øMejor con 32 neuronas o con 128?
* ¬øMejor con *learning rate* 0.01 o 0.001?

Llevar la cuenta de todo esto no es f√°cil. Aqu√≠ entra en juego **TensorBoard**.

### ¬øQu√© es TensorBoard?
Es una herramienta de visualizaci√≥n incliuda en TensorFlow que nos permite monitorizar el entrenamiento en tiempo real.

Nos permite ver:
1. **Curvas de P√©rdida**: Ver si el modelo est√° aprendiendo o si ha dejado de mejorar.
2. **Comparar Modelos**: Superponer las gr√°ficas de distintos entrenamientos para ver cu√°l converge m√°s r√°pido o consigue menor error.
3. **Detectar Overfitting**: Si vemos que la p√©rdida en entrenamiento baja pero en validaci√≥n sube, sabremos exactamente en qu√© √©poca empez√≥ el sobreajuste.

En la demo pr√°ctica aprenderemos a instrumentar nuestro c√≥digo para enviar estos datos a TensorBoard y analizarlos visualmente.

---


## Evitando el memorismo: Early Stopping

Cuando entrenamos una red neuronal, corremos el riesgo de que aprenda "demasiado bien" los datos de entrenamiento, hasta el punto de memorizar el ruido en lugar del patr√≥n general. A esto se le llama **Overfitting** (sobreajuste).

### ¬øC√≥mo detectarlo?
Lo veremos claramente en las gr√°ficas de p√©rdida (Loss) que nos muestra TensorBoard o el historial de entrenamiento:

*   La p√©rdida en **Train** sigue bajando indefinidamente.
*   La p√©rdida en **Validation** deja de bajar y empieza a subir.

Ese punto de inflexi√≥n es donde el modelo empieza a memorizar.

### La soluci√≥n m√°s sencilla: Early Stopping
En lugar de intentar adivinar cu√°ntas √©pocas necesita el modelo (¬ø100? ¬ø200? ¬ø500?), usamos una t√©cnica llamada **Early Stopping** (parada temprana).

Funciona as√≠:
1.  Monitorizamos la p√©rdida de validaci√≥n en cada √©poca.
2.  Si la p√©rdida de validaci√≥n no mejora durante un n√∫mero determinado de √©pocas (paciencia), **paramos el entrenamiento autom√°ticamente**.
3.  Restauramos los pesos del modelo al punto donde consigui√≥ el mejor resultado.

Es una forma muy eficaz y sencilla de evitar el sobreajuste sin complicar la arquitectura del modelo.

---

## Siguientes Pasos

Ahora que conocemos la teor√≠a de las redes densas para regresi√≥n, ¬°vamos a construir una!

üëâ **[Demo: Regresi√≥n con California Housing y TensorBoard](../0-colab/regresion_california.ipynb)**
*(Nota: El enlace a la demo se activar√° cuando la creemos en los siguientes pasos)*