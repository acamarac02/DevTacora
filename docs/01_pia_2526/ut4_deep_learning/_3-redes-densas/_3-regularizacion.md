---
title: "Regularizaci√≥n y Overfitting"
sidebar_position: 3
description: "T√©cnicas fundamentales para combatir el sobreajuste en redes neuronales: Early Stopping, Dropout, L2 y Batch Normalization."
keywords: [regularizaci√≥n, overfitting, sobreajuste, early stopping, dropout, batch normalization, keras, tensorflow]
---

En los apartados anteriores hemos visto c√≥mo dise√±ar arquitecturas tanto para problemas de regresi√≥n como de clasificaci√≥n. Al monitorizar el entrenamiento con TensorBoard, es muy probable que te hayas topado con un fen√≥meno recurrente: el **Overfitting** (sobreajuste).

Las redes neuronales densas son modelos con una capacidad de aprendizaje masiva (a menudo tienen miles o cientos de miles de par√°metros). Si las dejamos entrenar el tiempo suficiente sin control, tender√°n a "memorizar" los datos de entrenamiento exactos en lugar de aprender los patrones generales que subyacen en ellos.

![Gr√°fico EDA](../0-img/overfitting-tensorboard.png)

En este apartado veremos c√≥mo utilizar t√©cnicas de **Regularizaci√≥n**, cuyo objetivo principal es restringir, penalizar o aplicar "ruido" a la red para forzarla a generalizar mejor en datos que nunca ha visto.

---

## El Diagn√≥stico del Overfitting

Sabemos que nuestra arquitectura sufre de overfitting cuando observamos una divergencia clara en el panel "Time Series" de TensorBoard:

*   La p√©rdida en el conjunto de entrenamiento (`loss`) sigue bajando acerc√°ndose a cero.
*   La p√©rdida en el conjunto de validaci√≥n (`val_loss`) llega a un punto m√≠nimo, se estanca o, lo que es peor, **empieza a subir**.

![Gr√°fico EDA](../0-img/tensorboard-loss.png)

En el momento en que la curva de validaci√≥n empieza a empeorar, cada nueva √©poca de entrenamiento est√° perjudicando activamente al modelo final. Nuestro objetivo con las siguientes t√©cnicas es "cerrar la brecha" (gap) entre estas dos curvas.

---

## Parada Temprana (Early Stopping)

Es la t√©cnica de regularizaci√≥n m√°s recomendada, sencilla y efectiva. Si sabemos matem√°ticamente que el modelo empezar√° a empeorar a partir de cierta √©poca, ¬øpor qu√© no pedimos a Keras que detenga el entrenamiento exactamente en ese punto?

El **Early Stopping** monitoriza una m√©trica (normalmente `val_loss`) e interrumpe el bucle de entrenamiento autom√°ticamente si dicha m√©trica deja de mejorar despu√©s de un n√∫mero determinado de √©pocas de "paciencia".

### Implementaci√≥n en Keras
Se implementa como un objeto *Callback* (igual que vimos con TensorBoard), que luego le pasamos al m√©todo `.fit()` en forma de lista:

```python
from tensorflow.keras import callbacks

early_stopping = callbacks.EarlyStopping(
    monitor='val_loss', # M√©trica que queremos vigilar
    patience=10,        # Cu√°ntas √©pocas esperar sin mejora antes de detenerse
    restore_best_weights=True # ¬°Cr√≠tico! Nos quedamos con los pesos del punto √≥ptimo
)

# A√±adimos el callback a la lista junto al callback de TensorBoard (si lo tenemos)
model.fit(
    X_train, y_train,
    epochs=500, # Podemos establecer un l√≠mite enorme; el Early Stopping lo parar√° antes
    validation_data=(X_valid, y_valid),
    callbacks=[early_stopping, tensorboard_callback]
)
```

:::tip La importancia cr√≠tica de `restore_best_weights`
Imagina que en la √©poca 40 el modelo alcanz√≥ su mejor (m√≠nimo) valor de `val_loss`. Como hemos configurado una paciencia de 10 √©pocas, el entrenamiento continuar√°, pero al no mejorar, se detendr√° en la √©poca 50. 
Si **NO** activamos `restore_best_weights=True`, el modelo final en memoria almacenar√° los pesos de la √©poca 50 (donde ya hab√≠a empezado a empeorar fuertemente). Al ponerlo a `True`, consideramos esa "paciencia" como una simple ventana de exploraci√≥n, y Keras "rebobina" y recupera autom√°ticamente los pesos de la √©poca 40 por nosotros. ¬°Nunca lo olvides!
:::

---

## Dropout (Deserci√≥n)

El **Dropout** es posiblemente la innovaci√≥n en regularizaci√≥n m√°s popular y replicada del Deep Learning moderno. Su funcionamiento conceptual es sorprendentemente simple pero incre√≠blemente efectivo: consiste en **"apagar" u omitir aleatoriamente un porcentaje de las neuronas** durante cada paso de actualizaci√≥n (*batch*) del entrenamiento.

Al desconectar neuronas al azar, la red se da cuenta de que no puede depender de manera absoluta en ninguna conexi√≥n espec√≠fica o caracter√≠stica individual, ya que podr√≠an fallar o desaparecer en cualquier momento. Esto obliga a la red a "distribuir" el conocimiento, forzando a que las neuronas vecinas aprendan representaciones redundantes y robustas.

### Implementaci√≥n en Keras
En lugar de configurarlo al compilar, el Dropout se a√±ade directamente como una capa intermedia m√°s dentro de nuestra arquitectura `Sequential`. Esta capa especial afecta exclusivamente a las salidas de la capa inmediatamente anterior:

```python
from tensorflow.keras import layers

model = tf.keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=[n_features]),
    
    # Apagamos el 30% de las neuronas de la capa anterior aleatoriamente
    layers.Dropout(0.3), 
    
    layers.Dense(64, activation='relu'),
    
    # Podemos aplicar varios Dropouts en la red (suelen ponerse despu√©s de las Dense)
    layers.Dropout(0.2),
    
    layers.Dense(1, activation='sigmoid') # Capa de salida (estas NUNCA llevan Dropout)
])
```

:::important El Dropout solo act√∫a en Fase de Entrenamiento
Keras gestiona internamente el ciclo de vida del modelo de forma inteligente. Reconoce que el Dropout solo debe actuar activamente introduciendo ese ruido durante el ajuste de pesos (`.fit()`). 
Cuando pasamos a la fase de evaluaci√≥n del modelo (`.evaluate()`) o lanzamos predicciones reales (`.predict()`), **el Dropout se desactiva de manera transparente y autom√°tica**. Otorga a la red su 100% de fuerza conjunta y ajusta la escala matem√°tica interna de sus salidas para compensar la reaparici√≥n sorpresiva de esas neuronas que faltaban.
:::

---

## Regularizaci√≥n de Pesos (L1 y L2)

A diferencia del Dropout, que altera las rutas computacionales din√°micamente, L1 y L2 son penalizaciones directas incluidas en la Funci√≥n de P√©rdida final que se intenta optimizar. A√±aden un castigo matem√°tico proporcional a la magnitud (*tama√±o*) de los pesos de nuestra red.

*   **L1 (Lasso):** Castiga la suma "absoluta" de los pesos, con un efecto colateral caracter√≠stico: fuerza la dispersi√≥n, obligando activamente a que muchos de los pesos terminen siendo puramente o matem√°ticamente **cero**. Es id√≥neo si sospechamos con antelaci√≥n que disponemos de un volumen muy alto de par√°metros sin ninguna aportaci√≥n de valor predictivo.
*   **L2 (Ridge):** Castiga la suma de los valores de los pesos en su forma cuadr√°tica. En este caso no suele reducir valores de peso a cero, pero desincentiva brutalmente que exista cualquier peso en particular con un tama√±o desorbitado y empuja, como objetivo, a obtener arquitecturas densas en las que todos los pesos est√©n repartidos equitativamente y cercanos a la franja del 0.

### Implementaci√≥n en Keras
Se inyecta como un flag o par√°metro de configuraci√≥n expl√≠cito dentro de la propia declaraci√≥n de la capa de neuronas subyacente que queremos regularizar:

```python
from tensorflow.keras import regularizers

model = tf.keras.Sequential([
    # Penalizamos que los par√°metros asuman un peso inmensamente grande aplicando L2
    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
    layers.Dense(1)
])
```

---

## Batch Normalization (Normalizaci√≥n por Lotes)

:::note Diferencias fundamentales en terminolog√≠a
Es imprescindible recordar que la capa especial de *Batch Normalization* no tiene absolutamente nada en com√∫n con configurar en Keras nuestro tama√±o de lote en el `.fit()` (`batch_size=32`).
:::

Tal y como aprendimos durante la exploraci√≥n de modelos tradicionales de ML de la necesidad casi obligatoria del preprocesamiento y estandarizaci√≥n a nuestros datos iniciales pre-capa de entrada, el **Batch Normalization** tiene exactamente la misma labor. De forma sencilla, act√∫a como un "StandardScaler" intercalado que estandariza forzosamente para que devuelva medias 0 y desviaciones t√≠picas 1 a **las salidas intermedias** ocultas entre las capas.

La ventaja competitiva de su incorporaci√≥n se centra de facto en acelerar desproporcionadamente tiempos de aprendizaje (m√°s convergencia y curvas menos vibrantes en modelos masivos muy extendidos hacia el fondo de las capas). Secundariamente arrastra en este proceso un sutil componente colateral y aleatorio que restringe levemente al modelo aportando cierto porcentaje extra de resiliencia final que sirve tambi√©n y amortigua un min√∫sculo porcentaje del overfitting general.

### Implementaci√≥n en Keras
Difiere tradicionalmente seg√∫n las modas de la √©poca. Para redes fully-connected se recomienda intercalarla o anteceder a la fase posterior, o incluso en mitad de separaciones (interrumpiendo separadamente un activation call).

```python
model = tf.keras.Sequential([
    layers.Dense(64, activation='relu'),
    layers.BatchNormalization(), # Escala en l√≠nea pura este lote espec√≠fico 
    layers.Dense(32, activation='relu'),
    layers.Dense(1)
])
```

---

## Metodolog√≠a de Trabajo

A la hora de enfrentarnos a un nuevo problema de Deep Learning, la tentaci√≥n de crear desde el primer momento una red gigantesca repleta de capas de Dropout y Batch Normalization es enorme. Sin embargo, en la pr√°ctica profesional se sigue una metodolog√≠a iterativa y estructurada. El flujo de trabajo habitual se resume en los siguientes pasos:

1. **Construir un modelo base simple (Baseline):**
   Comienza con una arquitectura muy sencilla, sin regularizaci√≥n. Tu √∫nico objetivo inicial es lograr que el modelo "aprenda" algo, es decir, que la p√©rdida en entrenamiento (`loss`) empiece a disminuir y sus m√©tricas superen el rendimiento de hacer predicciones aleatorias.

2. **Forzar el Overfitting (Escalar la capacidad):**
   Para poder regularizar una red, primero debes asegurarte de que tiene la capacidad suficiente para asimilar toda la complejidad de los datos (y de sobra). Si tu modelo base no sufre de *overfitting*, ampl√≠a la arquitectura (a√±ade m√°s capas o m√°s neuronas por capa). Debes llegar a ese punto en el que TensorBoard te muestre de manera evidente que el modelo est√° memorizando: el `loss` de entrenamiento cae hacia cero, mientras que el `val_loss` se estanca o asciende.

3. **Aplicar Regularizaci√≥n para "domar" el modelo:**
   Una vez que dispones de un modelo musculoso que claramente est√° sobreajustando, es el momento de aplicar las t√©cnicas descritas en este apartado para cerrarle el paso a la memorizaci√≥n en crudo y obligarlo a generalizar:
   * **Reduce su tama√±o:** La regularizaci√≥n m√°s elemental es simplemente podar capas o neuronas si la ampliaci√≥n del paso 2 fue desmesurada.
   * **Introduce Early Stopping:** A√±√°delo siempre como medida de seguridad, aunque sea con una "paciencia" holgada.
   * **Introduce Dropout:** A√±√°delo gradualmente (ej. tasas del 20% al 30%) a continuaci√≥n de las capas densas m√°s voluminosas.
   * **Suma Batch Normalization:** Si aprecias mucha inestabilidad o picos abruptos en las curvas durante el entrenamiento.

4. **Iterar y refinar (Tuning):**
   Aqu√≠ entra el ciclo de validaci√≥n emp√≠rica. Analiza las gr√°ficas en TensorBoard de cada prueba, ajusta la severidad de tus capas de Dropout o prueba alternativas como regularizadores de peso (L2) si es imperativo. El estado √≥ptimo se alcanza cuando las curvas de entrenamiento y validaci√≥n logran descender de la mano manteni√©ndose lo m√°s cerca la una de la otra antes de que el Early Stopping decida intervenir.

:::tip En resumen
La filosof√≠a de trabajo se condensa en tres fases:   
**1.** Haz un modelo m√≠nimo que sea capaz de aprender algo.   
**2.** Hazlo tan grande que acabe memorizando (y sobreajustando).   
**3.** Som√©telo a regularizaci√≥n matem√°tica para forzarlo a generalizar.  
:::


## Caso Pr√°ctico

En este caso pr√°ctico, vamos a consolidar lo aprendido trabajando nuevamente sobre el conjunto de datos de viviendas. Nuestro objetivo ser√° construir primero una red demasiado compleja para forzar de manera deliberada el sobreajuste (*overfitting*). A continuaci√≥n, aplicaremos la metodolog√≠a de trabajo introduciendo progresivamente **Early Stopping** y **Dropout** para observar emp√≠ricamente en TensorBoard c√≥mo logramos controlar esas curvas de validaci√≥n.

Puedes acceder al notebook con el c√≥digo completo desde este enlace:

üëâ [Google Colab: regularizacion_california_housing_redes_densas](../0-colab/regularizacion_california_housing_redes_densas.ipynb)

---

## Actividad de Seguimiento

Es tu turno de aplicar esta misma metodolog√≠a de regularizaci√≥n a los ejercicios que ya resolviste en los dos apartados anteriores. Tu misi√≥n es recuperar esos notebooks y tratar de mejorar el rendimiento y la generalizaci√≥n de tus modelos:

1. **Problema de Regresi√≥n (Bike Sharing Dataset):**
   * Recupera tu notebook de la primera pr√°ctica.
   * Modifica la arquitectura para forzar un claro *overfitting* observable en TensorBoard.
   * Aplica **Early Stopping** y comb√≠nalo con capas de **Dropout** para acotar el problema. 
   * Compara los resultados: ¬øHas conseguido un error (RMSE o MAE) en validaci√≥n/test mejor que en tus primeros intentos sin regularizar?

2. **Problema de Clasificaci√≥n (Employees Dataset):**
   * Abre tu notebook de la pr√°ctica de clasificaci√≥n (predicci√≥n de abandono o *attrition*).
   * Aplica la estrategia de escalado y posterior regularizaci√≥n.
   * Aprovecha para experimentar tambi√©n con **Batch Normalization** dentro de la arquitectura.
   * Analiza c√≥mo impacta esta regularizaci√≥n en tu matriz de confusi√≥n final y en las m√©tricas de clasificaci√≥n sobre los datos de test.

