<!doctype html>
<html lang="es" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-pia_2526/ut3_ml/aprendizaje-supervisado/regresion/knn_regresion" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">KNN Regresi√≥n | DevTacora</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://acamarac02.github.io/DevTacora/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://acamarac02.github.io/DevTacora/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/knn_regresion"><meta data-rh="true" property="og:locale" content="es"><meta data-rh="true" name="docusaurus_locale" content="es"><meta data-rh="true" name="docsearch:language" content="es"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="KNN Regresi√≥n | DevTacora"><meta data-rh="true" name="description" content="Introducci√≥n a KNN Regression en Machine Learning. Funcionamiento del algoritmo, diferencias con KNN clasificaci√≥n, hiperpar√°metros principales, importancia del escalado, m√©tricas de evaluaci√≥n y ejemplos pr√°cticos con scikit-learn."><meta data-rh="true" property="og:description" content="Introducci√≥n a KNN Regression en Machine Learning. Funcionamiento del algoritmo, diferencias con KNN clasificaci√≥n, hiperpar√°metros principales, importancia del escalado, m√©tricas de evaluaci√≥n y ejemplos pr√°cticos con scikit-learn."><meta data-rh="true" name="keywords" content="KNN,KNN Regression,Regresi√≥n KNN,Machine Learning,vecinos m√°s cercanos,distancia,scikit-learn"><link data-rh="true" rel="icon" href="/DevTacora/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/knn_regresion"><link data-rh="true" rel="alternate" href="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/knn_regresion" hreflang="es"><link data-rh="true" rel="alternate" href="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/knn_regresion" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"UT3. Machine Learning","item":"https://acamarac02.github.io/DevTacora/docs/category/ut3-machine-learning"},{"@type":"ListItem","position":2,"name":"Aprendizaje supervisado","item":"https://acamarac02.github.io/DevTacora/docs/category/aprendizaje-supervisado"},{"@type":"ListItem","position":3,"name":"Regresi√≥n","item":"https://acamarac02.github.io/DevTacora/docs/category/regresi√≥n"},{"@type":"ListItem","position":4,"name":"KNN Regresi√≥n","item":"https://acamarac02.github.io/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/knn_regresion"}]}</script><link rel="alternate" type="application/rss+xml" href="/DevTacora/blog/rss.xml" title="DevTacora RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/DevTacora/blog/atom.xml" title="DevTacora Atom Feed">




<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7WCKN9ZY1F"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-7WCKN9ZY1F",{anonymize_ip:!0})</script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/DevTacora/assets/css/styles.71ba2beb.css">
<script src="/DevTacora/assets/js/runtime~main.c54df848.js" defer="defer"></script>
<script src="/DevTacora/assets/js/main.a26401bd.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Saltar al contenido principal"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Saltar al contenido principal</a></div><nav aria-label="Principal" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alternar barra lateral" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/DevTacora/"><div class="navbar__logo"><img src="/DevTacora/img/devtacora_logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/DevTacora/img/devtacora_logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">DevTacora</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/DevTacora/docs/pia_2526/">PIA</a><a class="navbar__item navbar__link" href="/DevTacora/docs/pmdm_2526/">PMDM</a><a class="navbar__item navbar__link" href="/DevTacora/docs/category/ut5-persistencia-de-datos">PMDM 24-25</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/DevTacora/docs/licencia">Licencia</a><a href="https://www.linkedin.com/in/aliciacamcas" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Cambiar entre modo oscuro y claro (actualmente system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Volver al principio" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Barra lateral de Documentos" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/DevTacora/docs/pia_2526/">Presentaci√≥n</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/DevTacora/docs/category/ut1-introducci√≥n-a-la-ia">UT1. Introducci√≥n a la IA</a><button aria-label="Ampliar la categor√≠a &#x27;UT1. Introducci√≥n a la IA&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/DevTacora/docs/category/ut2-python-para-la-ia">UT2. Python para la IA</a><button aria-label="Ampliar la categor√≠a &#x27;UT2. Python para la IA&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/DevTacora/docs/category/ut3-machine-learning">UT3. Machine Learning</a><button aria-label="Colapsar categor√≠a &#x27;UT3. Machine Learning&#x27; de la barra lateral" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/introduccion">Introducci√≥n</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/primer-modelo">Primer modelo de ML: Titanic</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/eda">Exploratory Data Analysis (EDA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/preprocesamiento">Preprocesamiento de Datos</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/DevTacora/docs/category/aprendizaje-supervisado">Aprendizaje supervisado</a><button aria-label="Colapsar categor√≠a &#x27;Aprendizaje supervisado&#x27; de la barra lateral" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/tips-generales">Tips generales</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/DevTacora/docs/category/clasificaci√≥n">Clasificaci√≥n</a><button aria-label="Ampliar la categor√≠a &#x27;Clasificaci√≥n&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/DevTacora/docs/category/regresi√≥n">Regresi√≥n</a><button aria-label="Colapsar categor√≠a &#x27;Regresi√≥n&#x27; de la barra lateral" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/intro_regresion">Ideas generales</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/regresion_lineal">Regresi√≥n Lineal</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/knn_regresion">KNN Regresi√≥n</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/arbol_decision_regresion">Decision Trees Regresi√≥n</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/random_forest_regresion">Random Forest Regresi√≥n</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/regresion_ridge_lasso">Ridge y Lasso Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/gradient_boosting">Gradient Boosting Regresi√≥n</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/svr">Support Vector Regression (SVR)</a></li></ul></li></ul></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Rastro de navegaci√≥n"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="P√°gina de Inicio" class="breadcrumbs__link" href="/DevTacora/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/DevTacora/docs/category/ut3-machine-learning"><span>UT3. Machine Learning</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/DevTacora/docs/category/aprendizaje-supervisado"><span>Aprendizaje supervisado</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/DevTacora/docs/category/regresi√≥n"><span>Regresi√≥n</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">KNN Regresi√≥n</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">En esta p√°gina</button></div><div class="theme-doc-markdown markdown"><header><h1>KNN Regresi√≥n</h1></header><p>La <strong>KNN Regresi√≥n (K-Nearest Neighbors Regression)</strong> es un algoritmo de Machine Learning utilizado para <strong>predecir valores num√©ricos</strong> bas√°ndose en la informaci√≥n de los datos m√°s cercanos.</p>
<p>A diferencia de la Regresi√≥n Lineal, <strong>KNN no aprende una f√≥rmula matem√°tica</strong>, sino que realiza las predicciones <strong>directamente a partir de los datos de entrenamiento</strong>.</p>
<p>Por su simplicidad conceptual, KNN Regresi√≥n suele utilizarse como:</p>
<ul>
<li>Primer <strong>modelo no lineal</strong></li>
<li>Modelo de comparaci√≥n frente a regresi√≥n lineal</li>
<li>Algoritmo introductorio para entender modelos basados en distancia</li>
</ul>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Lectura recomendada</div><div class="admonitionContent_BuS1"><p>Para reforzar la comprensi√≥n de las diferencias entre <strong>Regresi√≥n Lineal</strong> y <strong>KNN</strong>, se recomienda la siguiente lectura:</p><p>üëâ <strong>KNN vs Linear Regression: How to Choose the Right ML Algorithm</strong><br>
<a href="https://medium.com/@skytoinds/knn-vs-linear-regression-how-to-choose-the-right-ml-algorithm-4f6bf01a4202" target="_blank" rel="noopener noreferrer">https://medium.com/@skytoinds/knn-vs-linear-regression-how-to-choose-the-right-ml-algorithm-4f6bf01a4202</a></p><p>El art√≠culo compara ambos modelos desde un punto de vista conceptual, destacando aspectos como la forma de la funci√≥n de predicci√≥n, la flexibilidad del modelo y el papel de los datos en cada enfoque.</p></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="idea-principal-del-algoritmo">Idea principal del algoritmo<a href="#idea-principal-del-algoritmo" class="hash-link" aria-label="Enlace directo al Idea principal del algoritmo" title="Enlace directo al Idea principal del algoritmo">‚Äã</a></h2>
<p>La idea de KNN Regresi√≥n es muy intuitiva:</p>
<blockquote>
<p>‚ÄúSi varios puntos cercanos tienen valores parecidos, un nuevo punto deber√≠a tener un valor similar.‚Äù</p>
</blockquote>
<p>Para predecir un nuevo valor:</p>
<ol>
<li>Se buscan los <strong>k puntos m√°s cercanos</strong></li>
<li>Se calcula la <strong>media</strong> de sus valores objetivo</li>
<li>Esa media es la predicci√≥n final</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Gr√°fico EDA" src="/DevTacora/assets/images/knn-regressor-7dd3e7bf7c5b723bd500722666e2964f.png" width="547" height="413" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="funcionamiento-del-modelo">Funcionamiento del modelo<a href="#funcionamiento-del-modelo" class="hash-link" aria-label="Enlace directo al Funcionamiento del modelo" title="Enlace directo al Funcionamiento del modelo">‚Äã</a></h2>
<p>El funcionamiento interno de KNN Regresi√≥n sigue siempre los mismos pasos:</p>
<ol>
<li>Elegir el valor de <strong>k</strong></li>
<li>Calcular la <strong>distancia</strong> entre el punto nuevo y todos los puntos del dataset</li>
<li>Seleccionar los <strong>k vecinos m√°s cercanos</strong></li>
<li>Calcular la <strong>media</strong> (o media ponderada) de sus valores objetivo</li>
</ol>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Nuevo punto ‚Üí buscar vecinos ‚Üí promediar valores ‚Üí predicci√≥n</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="c√°lculo-de-la-distancia">C√°lculo de la distancia<a href="#c√°lculo-de-la-distancia" class="hash-link" aria-label="Enlace directo al C√°lculo de la distancia" title="Enlace directo al C√°lculo de la distancia">‚Äã</a></h3>
<p>Para decidir qu√© puntos son ‚Äúcercanos‚Äù, KNN utiliza una <strong>m√©trica de distancia</strong>.
La m√°s habitual es la <strong>distancia eucl√≠dea</strong>, aunque existen otras como Manhattan.</p>
<p>La distancia se calcula teniendo en cuenta <strong>todas las variables de entrada</strong>, por lo que:</p>
<ul>
<li>Las variables deben estar en la <strong>misma escala</strong></li>
<li>Variables con valores grandes pueden dominar la distancia</li>
</ul>
<p>Por este motivo, el <strong>escalado de los datos es obligatorio</strong> en KNN.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="entrenamiento-vs-predicci√≥n">Entrenamiento vs predicci√≥n<a href="#entrenamiento-vs-predicci√≥n" class="hash-link" aria-label="Enlace directo al Entrenamiento vs predicci√≥n" title="Enlace directo al Entrenamiento vs predicci√≥n">‚Äã</a></h3>
<p>KNN Regresi√≥n es un algoritmo basado en instancias:</p>
<ul>
<li>Durante el <strong>entrenamiento</strong>, el modelo <strong>no aprende par√°metros</strong></li>
<li>Simplemente <strong>almacena el dataset de entrenamiento</strong></li>
<li>El trabajo computacional ocurre en la <strong>fase de predicci√≥n</strong></li>
</ul>
<p>Cada vez que se realiza una predicci√≥n, el modelo debe:</p>
<ul>
<li>Calcular distancias a todos los puntos</li>
<li>Buscar los vecinos m√°s cercanos</li>
<li>Calcular la predicci√≥n final</li>
</ul>
<p>Esto explica por qu√© KNN es muy barato de entrenar pero costoso en tiempo y memoria al predecir</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="interpretaci√≥n-geom√©trica">Interpretaci√≥n geom√©trica<a href="#interpretaci√≥n-geom√©trica" class="hash-link" aria-label="Enlace directo al Interpretaci√≥n geom√©trica" title="Enlace directo al Interpretaci√≥n geom√©trica">‚Äã</a></h3>
<p>KNN Regresi√≥n <strong>no ajusta una recta ni un plano</strong>.
La predicci√≥n depende √∫nicamente de la <strong>regi√≥n local</strong> del espacio de datos donde cae el nuevo punto.</p>
<p>Esto lo convierte en un modelo:</p>
<ul>
<li>Flexible</li>
<li>No lineal</li>
<li>Muy dependiente de la distribuci√≥n de los datos</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Gr√°fico EDA" src="/DevTacora/assets/images/knn-regressor-2-0a79bcaa81c382969d57dc0ea5869991.png" width="780" height="551" class="img_ev3q"></p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Modelos param√©tricos vs no param√©tricos</div><div class="admonitionContent_BuS1"><p>En Machine Learning, los modelos de regresi√≥n pueden clasificarse, de forma general, en <strong>modelos param√©tricos</strong> y <strong>modelos no param√©tricos</strong>.</p><p>Esta distinci√≥n no tiene que ver con si el modelo es simple o complejo, sino con <strong>c√≥mo representa la relaci√≥n entre las variables de entrada y la variable objetivo</strong>.</p><hr><h4 class="anchor anchorWithStickyNavbar_LWe7" id="modelos-param√©tricos">Modelos param√©tricos<a href="#modelos-param√©tricos" class="hash-link" aria-label="Enlace directo al Modelos param√©tricos" title="Enlace directo al Modelos param√©tricos">‚Äã</a></h4><p>Los <strong>modelos param√©tricos</strong> asumen de antemano una <strong>forma concreta</strong> para la funci√≥n de predicci√≥n.
Esa funci√≥n se describe mediante un <strong>n√∫mero fijo de par√°metros</strong>, independientemente de cu√°ntos datos tengamos.</p><p>La <strong>Regresi√≥n Lineal</strong> es un ejemplo claro de modelo param√©trico:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><msub><mi>w</mi><mn>0</mn></msub><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mo>‚ãØ</mo><mo>+</mo><msub><mi>w</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\hat{y} = w_0 + w_1x_1 + \dots + w_nx_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="minner">‚ãØ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span><p>El modelo siempre tiene la misma estructura (una combinaci√≥n lineal de las variables).
Durante el entrenamiento, <strong>solo se ajustan los valores de los coeficientes</strong>.</p><p>Aunque aumente la cantidad de datos, <strong>la forma del modelo no cambia</strong>, √∫nicamente cambian sus par√°metros.</p><hr><h4 class="anchor anchorWithStickyNavbar_LWe7" id="modelos-no-param√©tricos">Modelos no param√©tricos<a href="#modelos-no-param√©tricos" class="hash-link" aria-label="Enlace directo al Modelos no param√©tricos" title="Enlace directo al Modelos no param√©tricos">‚Äã</a></h4><p>Los <strong>modelos no param√©tricos</strong> no asumen una forma concreta para la funci√≥n de predicci√≥n.
En su lugar, permiten que la <strong>estructura del modelo dependa directamente de los datos</strong>.</p><p><strong>KNN Regresi√≥n</strong> es un modelo no param√©trico:</p><ul>
<li>No aprende coeficientes</li>
<li>No ajusta una funci√≥n expl√≠cita</li>
<li>Utiliza directamente los datos de entrenamiento para realizar las predicciones</li>
</ul><p>La forma de la funci√≥n de predicci√≥n depende de:</p><ul>
<li>la distribuci√≥n de los datos</li>
<li>el valor de <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mclose">)</span></span></span></span></li>
<li>la m√©trica de distancia utilizada</li>
</ul><p><img decoding="async" loading="lazy" alt="Gr√°fico EDA" src="/DevTacora/assets/images/lr-vs-knn-1f4426618b1426ce14dab4dbced5249b.png" width="1232" height="502" class="img_ev3q"></p></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="uso-de-knn-regresi√≥n">Uso de KNN Regresi√≥n<a href="#uso-de-knn-regresi√≥n" class="hash-link" aria-label="Enlace directo al Uso de KNN Regresi√≥n" title="Enlace directo al Uso de KNN Regresi√≥n">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cu√°ndo-s√≠-usarlo">Cu√°ndo S√ç usarlo<a href="#cu√°ndo-s√≠-usarlo" class="hash-link" aria-label="Enlace directo al Cu√°ndo S√ç usarlo" title="Enlace directo al Cu√°ndo S√ç usarlo">‚Äã</a></h3>
<p>KNN Regresi√≥n puede funcionar bien cuando:</p>
<ul>
<li>La relaci√≥n entre variables es <strong>no lineal</strong></li>
<li>El dataset no es excesivamente grande</li>
<li>Los datos est√°n bien distribuidos</li>
<li>Se dispone de un buen preprocesamiento</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cu√°ndo-no-funciona-bien">Cu√°ndo NO funciona bien<a href="#cu√°ndo-no-funciona-bien" class="hash-link" aria-label="Enlace directo al Cu√°ndo NO funciona bien" title="Enlace directo al Cu√°ndo NO funciona bien">‚Äã</a></h3>
<p>KNN Regresi√≥n suele rendir mal cuando:</p>
<ul>
<li>El dataset es muy grande (coste computacional)</li>
<li>Hay mucho ruido</li>
<li>Existen muchos outliers</li>
<li>El n√∫mero de variables es elevado (curse of dimensionality)</li>
</ul>
<p>En la pr√°ctica:</p>
<blockquote>
<p>KNN es un buen modelo de referencia, pero rara vez es el mejor modelo final.</p>
</blockquote>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="importancia-del-preprocesamiento">Importancia del preprocesamiento<a href="#importancia-del-preprocesamiento" class="hash-link" aria-label="Enlace directo al Importancia del preprocesamiento" title="Enlace directo al Importancia del preprocesamiento">‚Äã</a></h2>
<p>En KNN Regresi√≥n, el preprocesamiento <strong>es obligatorio</strong>.</p>
<table><thead><tr><th>Aspecto</th><th>¬øEs necesario?</th><th>Explicaci√≥n</th></tr></thead><tbody><tr><td>Tratamiento de nulos</td><td>‚úî S√≠</td><td>No admite valores nulos</td></tr><tr><td>Escalado</td><td>‚úî Obligatorio</td><td>La distancia depende de la escala</td></tr><tr><td>Outliers</td><td>‚úî Muy importante</td><td>Pueden dominar la predicci√≥n</td></tr><tr><td>Selecci√≥n de variables</td><td>‚úî Recomendado</td><td>Reduce ruido y dimensionalidad</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Escalado obligatorio</div><div class="admonitionContent_BuS1"><p>Si las variables no est√°n en la misma escala, <strong>la distancia no tiene sentido</strong> y el modelo producir√° predicciones err√≥neas.</p></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="principales-hiperpar√°metros">Principales hiperpar√°metros<a href="#principales-hiperpar√°metros" class="hash-link" aria-label="Enlace directo al Principales hiperpar√°metros" title="Enlace directo al Principales hiperpar√°metros">‚Äã</a></h2>
<p>KNN Regresi√≥n depende fuertemente de sus hiperpar√°metros, ya que estos determinan <strong>c√≥mo se definen los vecinos y c√≥mo se calcula la predicci√≥n</strong>.</p>
<p>Por este motivo, es habitual <strong>buscar autom√°ticamente la mejor combinaci√≥n de hiperpar√°metros</strong> utilizando <strong>validaci√≥n cruzada</strong>, del mismo modo que ya se ha hecho en los algoritmos de clasificaci√≥n.</p>
<p>En la pr√°ctica, esto se realiza mediante herramientas como <strong>GridSearchCV</strong>, que permiten evaluar distintas combinaciones y seleccionar la que ofrece mejor rendimiento medio.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="n√∫mero-de-vecinos-n_neighbors">N√∫mero de vecinos (<code>n_neighbors</code>)<a href="#n√∫mero-de-vecinos-n_neighbors" class="hash-link" aria-label="Enlace directo al n√∫mero-de-vecinos-n_neighbors" title="Enlace directo al n√∫mero-de-vecinos-n_neighbors">‚Äã</a></h3>
<ul>
<li><strong>k peque√±o</strong> ‚Üí modelo muy sensible al ruido (overfitting)</li>
<li><strong>k grande</strong> ‚Üí modelo muy suavizado (underfitting)</li>
</ul>
<p>No existe un valor universal de (k).
El valor √≥ptimo debe ajustarse mediante <strong>validaci√≥n cruzada</strong>, evaluando el rendimiento del modelo en distintos subconjuntos de datos.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pesos-weights">Pesos (<code>weights</code>)<a href="#pesos-weights" class="hash-link" aria-label="Enlace directo al pesos-weights" title="Enlace directo al pesos-weights">‚Äã</a></h3>
<ul>
<li><code>uniform</code> ‚Üí todos los vecinos pesan igual</li>
<li><code>distance</code> ‚Üí los vecinos m√°s cercanos tienen mayor influencia en la predicci√≥n</li>
</ul>
<p>En muchos casos, <code>weights=&quot;distance&quot;</code> mejora el rendimiento, especialmente cuando los datos no est√°n uniformemente distribuidos.</p>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ajuste-de-hiperpar√°metros">Ajuste de hiperpar√°metros<a href="#ajuste-de-hiperpar√°metros" class="hash-link" aria-label="Enlace directo al Ajuste de hiperpar√°metros" title="Enlace directo al Ajuste de hiperpar√°metros">‚Äã</a></h3>
<p>Al igual que en clasificaci√≥n, en problemas de regresi√≥n es posible combinar <strong>KNN Regresi√≥n</strong>, <strong>validaci√≥n cruzada</strong> y <strong>GridSearchCV</strong> para:</p>
<ul>
<li>Probar distintos valores de <code>n_neighbors</code></li>
<li>Comparar diferentes esquemas de pesos</li>
<li>Seleccionar autom√°ticamente la mejor configuraci√≥n</li>
</ul>
<p>Esto permite obtener un modelo m√°s robusto y reducir el riesgo de <strong>overfitting</strong> o <strong>underfitting</strong>.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="m√©tricas-de-evaluaci√≥n">M√©tricas de evaluaci√≥n<a href="#m√©tricas-de-evaluaci√≥n" class="hash-link" aria-label="Enlace directo al M√©tricas de evaluaci√≥n" title="Enlace directo al M√©tricas de evaluaci√≥n">‚Äã</a></h2>
<p>En KNN Regresi√≥n se utilizan las mismas m√©tricas que en otros modelos de regresi√≥n:</p>
<ul>
<li><strong>MAE</strong> (Mean Absolute Error)</li>
<li><strong>MSE</strong> (Mean Squared Error)</li>
<li><strong>R¬≤</strong> (Coeficiente de determinaci√≥n)</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="flujo-recomendado-en-un-problema-de-knn-regresi√≥n">Flujo recomendado en un problema de KNN Regresi√≥n<a href="#flujo-recomendado-en-un-problema-de-knn-regresi√≥n" class="hash-link" aria-label="Enlace directo al Flujo recomendado en un problema de KNN Regresi√≥n" title="Enlace directo al Flujo recomendado en un problema de KNN Regresi√≥n">‚Äã</a></h2>
<table><thead><tr><th>Paso</th><th>Qu√© se hace</th><th>Por qu√© es importante</th></tr></thead><tbody><tr><td>1. EDA</td><td>Analizar escalas y outliers</td><td>KNN es sensible a ambos</td></tr><tr><td>2. Preprocesamiento</td><td>Limpieza y escalado</td><td>Hace v√°lida la distancia</td></tr><tr><td>3. Entrenamiento</td><td>Ajustar hiperpar√°metros</td><td>Controla el sesgo</td></tr><tr><td>4. Evaluaci√≥n</td><td>MAE, MSE, R¬≤ + An√°lisis gr√°fico del rendimiento</td><td>Medir rendimiento</td></tr><tr><td>5. Comparaci√≥n</td><td>Comparar con otros modelos</td><td>Determina qu√© modelo se adapta mejor a nuestro dataset</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ejemplo-knn-regresi√≥n">Ejemplo KNN Regresi√≥n<a href="#ejemplo-knn-regresi√≥n" class="hash-link" aria-label="Enlace directo al Ejemplo KNN Regresi√≥n" title="Enlace directo al Ejemplo KNN Regresi√≥n">‚Äã</a></h2>
<p>Para ver c√≥mo funciona un <strong>KNN Regression</strong> en la pr√°ctica, puedes ejecutar este ejemplo utilizando el dataset <strong>California Housing</strong>.</p>
<p>üëâ <strong>Puedes abrir el cuaderno aqu√≠:</strong>
<a href="/DevTacora/assets/files/ejemplo_knn_regresion-69b4e4d64b0cf8bd868c95a0f19c3c38.ipynb" target="_blank">Colab: KNN Regression con California Housing</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="actividad-de-seguimiento-bike-sharing-dataset">Actividad de seguimiento: Bike Sharing Dataset<a href="#actividad-de-seguimiento-bike-sharing-dataset" class="hash-link" aria-label="Enlace directo al Actividad de seguimiento: Bike Sharing Dataset" title="Enlace directo al Actividad de seguimiento: Bike Sharing Dataset">‚Äã</a></h2>
<p>Utiliza el <strong>Bike Sharing Dataset</strong> y compara:</p>
<ul>
<li>Regresi√≥n Lineal</li>
<li>KNN Regresi√≥n</li>
</ul>
<p>Recuerda que debes realizar:</p>
<ul>
<li>Entrenamiento con GridSearch</li>
<li>An√°lisis mejores hiperpar√°metros</li>
<li>M√©tricas de evaluaci√≥n</li>
<li>Gr√°fica de an√°lisis de resultados (Valores reales vs predichos; Residuos)</li>
</ul>
<p><strong>Usa el mismo Colab que la entrega anterior</strong>.</p>
<p><strong>Entrega:</strong> Notebook (Colab) con conclusiones razonadas.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="P√°gina del documento"><a class="pagination-nav__link pagination-nav__link--prev" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/regresion_lineal"><div class="pagination-nav__sublabel">Anterior</div><div class="pagination-nav__label">Regresi√≥n Lineal</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/arbol_decision_regresion"><div class="pagination-nav__sublabel">Siguiente</div><div class="pagination-nav__label">Decision Trees Regresi√≥n</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#idea-principal-del-algoritmo" class="table-of-contents__link toc-highlight">Idea principal del algoritmo</a></li><li><a href="#funcionamiento-del-modelo" class="table-of-contents__link toc-highlight">Funcionamiento del modelo</a><ul><li><a href="#c√°lculo-de-la-distancia" class="table-of-contents__link toc-highlight">C√°lculo de la distancia</a></li><li><a href="#entrenamiento-vs-predicci√≥n" class="table-of-contents__link toc-highlight">Entrenamiento vs predicci√≥n</a></li><li><a href="#interpretaci√≥n-geom√©trica" class="table-of-contents__link toc-highlight">Interpretaci√≥n geom√©trica</a><ul><li><a href="#modelos-param√©tricos" class="table-of-contents__link toc-highlight">Modelos param√©tricos</a></li><li><a href="#modelos-no-param√©tricos" class="table-of-contents__link toc-highlight">Modelos no param√©tricos</a></li></ul></li></ul></li><li><a href="#uso-de-knn-regresi√≥n" class="table-of-contents__link toc-highlight">Uso de KNN Regresi√≥n</a><ul><li><a href="#cu√°ndo-s√≠-usarlo" class="table-of-contents__link toc-highlight">Cu√°ndo S√ç usarlo</a></li><li><a href="#cu√°ndo-no-funciona-bien" class="table-of-contents__link toc-highlight">Cu√°ndo NO funciona bien</a></li></ul></li><li><a href="#importancia-del-preprocesamiento" class="table-of-contents__link toc-highlight">Importancia del preprocesamiento</a></li><li><a href="#principales-hiperpar√°metros" class="table-of-contents__link toc-highlight">Principales hiperpar√°metros</a><ul><li><a href="#n√∫mero-de-vecinos-n_neighbors" class="table-of-contents__link toc-highlight">N√∫mero de vecinos (<code>n_neighbors</code>)</a></li><li><a href="#pesos-weights" class="table-of-contents__link toc-highlight">Pesos (<code>weights</code>)</a></li><li><a href="#ajuste-de-hiperpar√°metros" class="table-of-contents__link toc-highlight">Ajuste de hiperpar√°metros</a></li></ul></li><li><a href="#m√©tricas-de-evaluaci√≥n" class="table-of-contents__link toc-highlight">M√©tricas de evaluaci√≥n</a></li><li><a href="#flujo-recomendado-en-un-problema-de-knn-regresi√≥n" class="table-of-contents__link toc-highlight">Flujo recomendado en un problema de KNN Regresi√≥n</a></li><li><a href="#ejemplo-knn-regresi√≥n" class="table-of-contents__link toc-highlight">Ejemplo KNN Regresi√≥n</a></li><li><a href="#actividad-de-seguimiento-bike-sharing-dataset" class="table-of-contents__link toc-highlight">Actividad de seguimiento: Bike Sharing Dataset</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">
        <section classname="bg-white border-t border-gray-100">
      <div classname="max-w-4xl mx-auto px-6 py-16 text-center">
        <h3 classname="text-2xl font-bold text-gray-900 mb-4">
          Construyendo conocimiento, l√≠nea por l√≠nea
        </h3>
        <p classname="text-gray-600 leading-relaxed">
          ¬© 2026 Alicia C√°mara Casares - Contenido bajo licencia 
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer" classname="text-blue-600 hover:text-blue-700 underline">
                CC BY-NC-SA 4.0
              </a>.
        </p>
      </div>
    </section>
      </div></div></div></footer></div>
</body>
</html>