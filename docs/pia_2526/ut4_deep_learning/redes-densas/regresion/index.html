<!doctype html>
<html lang="es" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-pia_2526/ut4_deep_learning/redes-densas/regresion" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Redes Densas para Regresión | DevTacora</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://acamarac02.github.io/DevTacora/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://acamarac02.github.io/DevTacora/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut4_deep_learning/redes-densas/regresion"><meta data-rh="true" property="og:locale" content="es"><meta data-rh="true" name="docusaurus_locale" content="es"><meta data-rh="true" name="docsearch:language" content="es"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Redes Densas para Regresión | DevTacora"><meta data-rh="true" name="description" content="Cómo utilizar redes neuronales densas (MLP) para predecir valores continuos. Arquitectura, funciones de activación y métricas clave."><meta data-rh="true" property="og:description" content="Cómo utilizar redes neuronales densas (MLP) para predecir valores continuos. Arquitectura, funciones de activación y métricas clave."><meta data-rh="true" name="keywords" content="regresión,redes densas,MLP,California Housing,MSE,MAE,ReLU,TensorBoard"><link data-rh="true" rel="icon" href="/DevTacora/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut4_deep_learning/redes-densas/regresion"><link data-rh="true" rel="alternate" href="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut4_deep_learning/redes-densas/regresion" hreflang="es"><link data-rh="true" rel="alternate" href="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut4_deep_learning/redes-densas/regresion" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"UT4. Deep Learning","item":"https://acamarac02.github.io/DevTacora/docs/category/ut4-deep-learning"},{"@type":"ListItem","position":2,"name":"Redes Densas","item":"https://acamarac02.github.io/DevTacora/docs/category/redes-densas"},{"@type":"ListItem","position":3,"name":"Redes Densas para Regresión","item":"https://acamarac02.github.io/DevTacora/docs/pia_2526/ut4_deep_learning/redes-densas/regresion"}]}</script><link rel="alternate" type="application/rss+xml" href="/DevTacora/blog/rss.xml" title="DevTacora RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/DevTacora/blog/atom.xml" title="DevTacora Atom Feed">




<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7WCKN9ZY1F"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-7WCKN9ZY1F",{anonymize_ip:!0})</script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/DevTacora/assets/css/styles.71ba2beb.css">
<script src="/DevTacora/assets/js/runtime~main.9639b348.js" defer="defer"></script>
<script src="/DevTacora/assets/js/main.444011df.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Saltar al contenido principal"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Saltar al contenido principal</a></div><nav aria-label="Principal" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alternar barra lateral" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/DevTacora/"><div class="navbar__logo"><img src="/DevTacora/img/devtacora_logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/DevTacora/img/devtacora_logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">DevTacora</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/DevTacora/docs/pia_2526/">PIA</a><a class="navbar__item navbar__link" href="/DevTacora/docs/pmdm_2526/">PMDM</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/DevTacora/docs/licencia">Licencia</a><a href="https://www.linkedin.com/in/aliciacamcas" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Cambiar entre modo oscuro y claro (actualmente system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Volver al principio" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Barra lateral de Documentos" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/DevTacora/docs/pia_2526/">Presentación</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/DevTacora/docs/category/ut1-introducción-a-la-ia">UT1. Introducción a la IA</a><button aria-label="Ampliar la categoría &#x27;UT1. Introducción a la IA&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/DevTacora/docs/category/ut2-python-para-la-ia">UT2. Python para la IA</a><button aria-label="Ampliar la categoría &#x27;UT2. Python para la IA&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/DevTacora/docs/category/ut3-machine-learning">UT3. Machine Learning</a><button aria-label="Ampliar la categoría &#x27;UT3. Machine Learning&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/DevTacora/docs/category/ut4-deep-learning">UT4. Deep Learning</a><button aria-label="Colapsar categoría &#x27;UT4. Deep Learning&#x27; de la barra lateral" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut4_deep_learning/introduccion">Introducción</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/DevTacora/docs/category/fundamentos">Fundamentos</a><button aria-label="Ampliar la categoría &#x27;Fundamentos&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/DevTacora/docs/category/redes-densas">Redes Densas</a><button aria-label="Colapsar categoría &#x27;Redes Densas&#x27; de la barra lateral" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/DevTacora/docs/pia_2526/ut4_deep_learning/redes-densas/regresion">Redes Densas para Regresión</a></li></ul></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Rastro de navegación"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Página de Inicio" class="breadcrumbs__link" href="/DevTacora/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/DevTacora/docs/category/ut4-deep-learning"><span>UT4. Deep Learning</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/DevTacora/docs/category/redes-densas"><span>Redes Densas</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Redes Densas para Regresión</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">En esta página</button></div><div class="theme-doc-markdown markdown"><header><h1>Redes Densas para Regresión</h1></header><p>En los apartados anteriores hemos visto cómo funciona una neurona individual y cómo se entrena mediante el descenso de gradiente. Pero una sola neurona (perceptrón) tiene una limitación fundamental: solo puede aprender relaciones lineales.</p>
<p>Para resolver problemas complejos, necesitamos conectar muchas neuronas en capas, formando lo que se conoce como <strong>Red Neuronal Densa</strong> o <strong>Perceptrón Multicapa (MLP)</strong>.</p>
<p>En este apartado vamos a ver cómo configurar estas redes para resolver problemas de <strong>regresión</strong>, es decir, cuando queremos predecir un valor numérico continuo (como el precio de una casa, la temperatura de mañana o la demanda de electricidad).</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="qué-es-una-red-neuronal-densa">¿Qué es una Red Neuronal Densa?<a href="#qué-es-una-red-neuronal-densa" class="hash-link" aria-label="Enlace directo al ¿Qué es una Red Neuronal Densa?" title="Enlace directo al ¿Qué es una Red Neuronal Densa?">​</a></h2>
<p>Una red densa (<em>Fully Connected Layer</em> o <em>Dense Layer</em>) es aquella en la que <strong>cada neurona de una capa está conectada con todas las neuronas de la capa siguiente</strong>.</p>
<p>Es la arquitectura más básica y fundamental del Deep Learning. Su potencia reside en que, al apilar varias capas con funciones de activación no lineales (como ReLU), la red puede aprender a aproximar cualquier función matemática compleja, no solo líneas rectas.</p>
<p><img decoding="async" loading="lazy" alt="Gráfico EDA" src="/DevTacora/assets/images/nn-architecture-21fb3cf4325a32be9dace5c67fada707.png" width="800" height="504" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="arquitectura-para-regresión">Arquitectura para Regresión<a href="#arquitectura-para-regresión" class="hash-link" aria-label="Enlace directo al Arquitectura para Regresión" title="Enlace directo al Arquitectura para Regresión">​</a></h2>
<p>Cuando diseñamos una red para un problema de regresión, la arquitectura suele seguir un patrón estándar:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="a-capa-de-entrada-input">A. Capa de Entrada (Input)<a href="#a-capa-de-entrada-input" class="hash-link" aria-label="Enlace directo al A. Capa de Entrada (Input)" title="Enlace directo al A. Capa de Entrada (Input)">​</a></h3>
<p>El número de neuronas de entrada debe coincidir con el número de <strong>características (features)</strong> de nuestros datos.</p>
<ul>
<li>Si nuestro dataset tiene 8 columnas de datos (como en California Housing), la capa de entrada tendrá 8 neuronas.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="b-capas-ocultas-hidden-layers">B. Capas Ocultas (Hidden Layers)<a href="#b-capas-ocultas-hidden-layers" class="hash-link" aria-label="Enlace directo al B. Capas Ocultas (Hidden Layers)" title="Enlace directo al B. Capas Ocultas (Hidden Layers)">​</a></h3>
<p>Aquí es donde ocurre la &quot;magia&quot;.</p>
<ul>
<li><strong>Número de capas y neuronas</strong>: Depende de la complejidad del problema. Para problemas sencillos, 1 o 2 capas con 32-64 neuronas suelen funcionar bien.</li>
<li><strong>Función de Activación</strong>: El estándar hoy en día es <strong>ReLU</strong>.</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>¿Cuál es la mejor arquitectura?</div><div class="admonitionContent_BuS1"><p>No existe una fórmula mágica. La clave en Deep Learning es la <strong>experimentación</strong>. Probaremos diferentes combinaciones (más capas, menos neuronas, etc.) y nos quedaremos con aquella que:</p><ol>
<li><strong>Mejor generalice</strong>: La que consiga el menor error en el conjunto de <strong>Validación</strong> (no en el de entrenamiento).</li>
<li><strong>Sea más simple</strong>: Siguiendo el principio de la <em>Navaja de Ockham</em>, si dos arquitecturas dan resultados similares, siempre elegiremos la más sencilla para evitar el sobreajuste y ahorrar cómputo.</li>
</ol></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="c-capa-de-salida-output">C. Capa de Salida (Output)<a href="#c-capa-de-salida-output" class="hash-link" aria-label="Enlace directo al C. Capa de Salida (Output)" title="Enlace directo al C. Capa de Salida (Output)">​</a></h3>
<p>Esta es la parte crítica que diferencia a la regresión de la clasificación.</p>
<ul>
<li><strong>Número de neuronas</strong>: <strong>1</strong> (porque queremos predecir un único valor numérico).</li>
<li><strong>Función de Activación</strong>: <strong>Ninguna (Lineal)</strong>.<!-- -->
<ul>
<li>No usamos Sigmoid o Tanh porque estas comprimen la salida a rangos limitados ([0,1] o [-1,1]).</li>
<li>Queremos que la red pueda predecir cualquier valor real (por ejemplo, un precio de 500.000$ o una temperatura de -15ºC), por lo que dejamos que la neurona devuelva el valor tal cual lo calcula la suma ponderada: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mo>∑</mo><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">y = \sum (w_i x_i) + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span>.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="implementación-básica-en-keras">Implementación básica en Keras<a href="#implementación-básica-en-keras" class="hash-link" aria-label="Enlace directo al Implementación básica en Keras" title="Enlace directo al Implementación básica en Keras">​</a></h3>
<p>Traducir esta arquitectura a código con TensorFlow y Keras es muy directo. Aquí tienes un ejemplo de cómo se configuraría la arquitectura:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> tensorflow </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> tf</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> tensorflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">keras </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> layers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 1. Definir la arquitectura</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> tf</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">keras</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Sequential</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Capa oculta 1: 64 neuronas, activación ReLU</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    layers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Dense</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">64</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> activation</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;relu&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> input_shape</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">n_features</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Capa oculta 2: 32 neuronas, activación ReLU</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    layers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Dense</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">32</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> activation</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;relu&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Capa de salida: 1 neurona, sin activación (lineal)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    layers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Dense</span><span class="token punctuation" style="color:#393A34">(</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="configuración-del-entrenamiento">Configuración del Entrenamiento<a href="#configuración-del-entrenamiento" class="hash-link" aria-label="Enlace directo al Configuración del Entrenamiento" title="Enlace directo al Configuración del Entrenamiento">​</a></h2>
<p>Para entrenar una red de regresión, necesitamos configurar el compilador del modelo con los siguientes elementos:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="función-de-pérdida-loss-function">Función de Pérdida (Loss Function)<a href="#función-de-pérdida-loss-function" class="hash-link" aria-label="Enlace directo al Función de Pérdida (Loss Function)" title="Enlace directo al Función de Pérdida (Loss Function)">​</a></h3>
<p>Es la métrica que el optimizador intentará minimizar. Las más comunes en regresión son:</p>
<ul>
<li><strong>MSE (Mean Squared Error)</strong>: Calcula el promedio de los errores al cuadrado. Penaliza mucho los errores grandes (outliers). Es la más habitual en regresión.</li>
<li><strong>MAE (Mean Absolute Error)</strong>: Calcula el promedio del valor absoluto de los errores. Es menos sensible a outliers que el MSE.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="optimizador">Optimizador<a href="#optimizador" class="hash-link" aria-label="Enlace directo al Optimizador" title="Enlace directo al Optimizador">​</a></h3>
<p>Como vimos en la teoría, el algoritmo que ajusta los pesos. El estándar de facto para empezar es <strong>Adam</strong>, ya que gestiona automáticamente el <em>learning rate</em> de forma adaptativa.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="métricas">Métricas<a href="#métricas" class="hash-link" aria-label="Enlace directo al Métricas" title="Enlace directo al Métricas">​</a></h3>
<p>Son valores que <em>nosotros</em> leemos para entender qué tan bien funciona el modelo (aunque no se usan directamente para optimizar).</p>
<ul>
<li><strong>MAE</strong> es muy interpretable: nos dice, de media, cuánto nos estamos equivocando en las unidades originales (por ejemplo, &quot;nos equivocamos en 20.000$ de media&quot;).</li>
<li><strong>RMSE</strong> (Raíz del error cuadrático medio): Muy usada también para tener una medida de error en las mismas unidades que la variable objetivo.</li>
<li><strong>R² (R-cuadrado)</strong>: Indica qué porcentaje de la variación de los datos es capaz de explicar nuestro modelo. Un R² de 0.8 significa que el modelo explica el 80% de la variabilidad. Es la métrica ideal para saber si el modelo es &quot;bueno&quot; en términos generales.</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="implementación-básica-en-keras-1">Implementación básica en Keras<a href="#implementación-básica-en-keras-1" class="hash-link" aria-label="Enlace directo al Implementación básica en Keras" title="Enlace directo al Implementación básica en Keras">​</a></h3>
<p>Traducir esta arquitectura a código con TensorFlow y Keras es muy directo. Aquí tienes un ejemplo de cómo se compila un modelo:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># 2. Compilar el modelo</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">compile</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    optimizer</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;adam&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    loss</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;mse&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    metrics</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;mae&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Diferencia entre Loss y Metrics</div><div class="admonitionContent_BuS1"><ul>
<li><strong>Loss (Pérdida)</strong>: Es para la <strong>Red Neuronal</strong>. Es la función que el optimizador intenta minimizar para ajustar los pesos.</li>
<li><strong>Metrics (Métricas)</strong>: Es para el <strong>Humano</strong>. Son valores que Keras nos muestra durante el entrenamiento para que podamos entender cómo de bueno es el modelo en unidades comprensibles (como el MAE en dólares), pero la red no las usa para aprender.</li>
</ul></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="el-proceso-de-entrenamiento-batches-y-validación">El Proceso de Entrenamiento: Batches y Validación<a href="#el-proceso-de-entrenamiento-batches-y-validación" class="hash-link" aria-label="Enlace directo al El Proceso de Entrenamiento: Batches y Validación" title="Enlace directo al El Proceso de Entrenamiento: Batches y Validación">​</a></h2>
<p>Para que el modelo aprenda correctamente, no basta con pasarle los datos; hay que definir <em>cómo</em> los va a procesar.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="qué-es-el-batch-size">¿Qué es el Batch Size?<a href="#qué-es-el-batch-size" class="hash-link" aria-label="Enlace directo al ¿Qué es el Batch Size?" title="Enlace directo al ¿Qué es el Batch Size?">​</a></h3>
<p>No le pasamos todos los datos a la red a la vez (sería demasiado pesado para la memoria), ni tampoco uno por uno (sería muy lento). Los agrupamos en <strong>batches</strong> (lotes).</p>
<ul>
<li><strong>Batch Size</strong>: El número de ejemplos que procesa la red antes de actualizar los pesos. Un valor común es 32 o 64.</li>
<li><em>Nota: No confundir con &quot;Batch Normalization&quot;, que es una técnica de regularización que veremos más adelante.</em></li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="el-conjunto-de-validación-validation-split">El Conjunto de Validación (Validation Split)<a href="#el-conjunto-de-validación-validation-split" class="hash-link" aria-label="Enlace directo al El Conjunto de Validación (Validation Split)" title="Enlace directo al El Conjunto de Validación (Validation Split)">​</a></h3>
<p>Durante el entrenamiento, es vital saber cómo se comporta el modelo con datos que <strong>no está usando para aprender</strong>.
Reservamos una pequeña parte de los datos (por ejemplo, el 20%) para validación. El modelo:</p>
<ol>
<li>Aprende con el conjunto de <strong>Entrenamiento</strong>.</li>
<li>Al final de cada época, se evalúa con el conjunto de <strong>Validación</strong>.</li>
</ol>
<p>Esto nos permite detectar el sobreajuste en tiempo real: si el error de entrenamiento baja pero el de validación sube, el modelo está empezando a memorizar.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Entrenar usando batches y conjunto de validación</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">history </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    X_train</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_train</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    epochs</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">100</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    batch_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">32</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    validation_data</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">X_valid</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_valid</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    verbose</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Train, Validation y Test</div><div class="admonitionContent_BuS1"><p>Para entrenar un modelo correctamente, solemos dividir nuestros datos en tres bloques:</p><ol>
<li><strong>Entrenamiento (<code>X_train</code>, <code>y_train</code>)</strong>: Son los &quot;apuntes&quot; que la red estudia para ajustar sus pesos.</li>
<li><strong>Validación (<code>X_valid</code>, <code>y_valid</code>)</strong>: Es un &quot;simulacro de examen&quot; que se hace al final de cada época. Sirve para ver si el modelo está aprendiendo a generalizar o solo está memorizando. <strong>La red no usa estos datos para ajustar pesos.</strong></li>
<li><strong>Test (<code>X_test</code>, <code>y_test</code>)</strong>: Es el &quot;examen final&quot; que solo se hace una vez hemos terminado de entrenar y ajustar todo, para saber el rendimiento real del modelo con datos que nunca ha visto.</li>
</ol><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_selection </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> train_test_split</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Dividimos para obtener el conjunto de Test (20%)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">X_temp</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> X_test</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_temp</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_test </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> train_test_split</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">X</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> test_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Del resto (80%), sacamos el conjunto de Validación (ej: 25% de 80% = 20% del total)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">X_train</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> X_valid</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_train</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_valid </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> train_test_split</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">X_temp</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_temp</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> test_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.25</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="caso-de-estudio-california-housing">Caso de Estudio: California Housing<a href="#caso-de-estudio-california-housing" class="hash-link" aria-label="Enlace directo al Caso de Estudio: California Housing" title="Enlace directo al Caso de Estudio: California Housing">​</a></h2>
<p>Para poner en práctica estos conceptos, en la siguiente demo utilizaremos el famoso dataset <strong>California Housing</strong>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="el-problema">El Problema<a href="#el-problema" class="hash-link" aria-label="Enlace directo al El Problema" title="Enlace directo al El Problema">​</a></h3>
<p>El objetivo es predecir el <strong>precio medio de las viviendas</strong> en un distrito de California, basándonos en datos del censo de 1990.</p>
<p>Las características (features) incluyen:</p>
<ul>
<li>Ingreso medio en el bloque (MedInc)</li>
<li>Antigüedad media de las casas (HouseAge)</li>
<li>Número medio de habitaciones (AveRooms)</li>
<li>Latitud y Longitud</li>
<li>Población, etc.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="eda-y-preprocesamiento">EDA y preprocesamiento<a href="#eda-y-preprocesamiento" class="hash-link" aria-label="Enlace directo al EDA y preprocesamiento" title="Enlace directo al EDA y preprocesamiento">​</a></h3>
<p>Antes de pasar los datos a una red neuronal, debemos aplicar todo lo aprendido en las unidades anteriores sobre <strong>Análisis Exploratorio de Datos (EDA)</strong> y <strong>Preprocesamiento</strong>.</p>
<p>A menudo se piensa que el Deep Learning es &quot;mágico&quot; y que puede procesar cualquier cosa, pero nada más lejos de la realidad:</p>
<ul>
<li><strong>No admiten valores nulos</strong>: Una red neuronal no puede operar con <code>NaN</code>. Debemos imputar o eliminar esos valores previamente.</li>
<li><strong>Solo entienden números</strong>: Todo el texto (variables categóricas) debe ser codificado (One-Hot Encoding, Label Encoding, etc.) antes de entrar en la red.</li>
<li><strong>Sensibilidad a Outliers</strong>: Al basarse en el descenso de gradiente, los valores extremos pueden desestabilizar el entrenamiento y hacer que los pesos &quot;exploten&quot;.</li>
</ul>
<p>En resumen: una red neuronal solo será tan buena como la calidad de los datos que le entregues.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="la-importancia-de-la-estandarización">La Importancia de la Estandarización<a href="#la-importancia-de-la-estandarización" class="hash-link" aria-label="Enlace directo al La Importancia de la Estandarización" title="Enlace directo al La Importancia de la Estandarización">​</a></h3>
<p>A diferencia de los modelos basados en árboles (como Random Forest o XGBoost), las redes neuronales son <strong>muy sensibles a la escala de los datos</strong>.</p>
<p>Si una variable tiene valores entre 0-1 (como una proporción) y otra tiene valores entre 1.000-100.000 (como ingresos), la red tendrá dificultades para converger, ya que los pesos asociados a la variable grande tendrán que ser muy pequeños y el gradiente será inestable.</p>
<div class="theme-admonition theme-admonition-important admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Regla de Oro</div><div class="admonitionContent_BuS1"><p>En Deep Learning, <strong>siempre</strong> debemos estandarizar o normalizar los datos de entrada para que tengan una escala similar (por ejemplo, media 0 y desviación estándar 1).</p><p><strong>¿Y la variable objetivo (Target)?</strong>
En problemas de regresión donde el valor a predecir es muy grande (como el precio de una casa: 500.000$), a veces también es recomendable escalarlo. Si no lo hacemos, el modelo podría tardar mucho en converger porque los errores iniciales serían gigantescos.</p></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="análisis-de-experimentos-tensorboard">Análisis de Experimentos: TensorBoard<a href="#análisis-de-experimentos-tensorboard" class="hash-link" aria-label="Enlace directo al Análisis de Experimentos: TensorBoard" title="Enlace directo al Análisis de Experimentos: TensorBoard">​</a></h2>
<p>Cuando entrenamos redes neuronales, a menudo probamos muchas configuraciones distintas:</p>
<ul>
<li>¿Mejor con 1 capa oculta o con 3?</li>
<li>¿Mejor con 32 neuronas o con 128?</li>
<li>¿Mejor con <em>learning rate</em> 0.01 o 0.001?</li>
</ul>
<p>Llevar la cuenta de todo esto no es fácil. Aquí entra en juego TensorBoard.</p>
<p><strong>TensorBoard</strong> es una herramienta de visualización incliuda en TensorFlow que nos permite monitorizar el entrenamiento en tiempo real.</p>
<p>Nos permite ver:</p>
<ol>
<li><strong>Curvas de Pérdida</strong>: Ver si el modelo está aprendiendo o si ha dejado de mejorar.</li>
<li><strong>Comparar Modelos</strong>: Superponer las gráficas de distintos entrenamientos para ver cuál converge más rápido o consigue menor error.</li>
<li><strong>Detectar Overfitting</strong>: Si vemos que la pérdida en entrenamiento baja pero en validación sube, sabremos exactamente en qué época empezó el sobreajuste.</li>
</ol>
<p>En la demo práctica aprenderemos a instrumentar nuestro código para enviar estos datos a TensorBoard y analizarlos visualmente:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> datetime</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 1. Definir dónde se guardarán los logs (historial del entrenamiento)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Usamos la fecha y hora para que cada entrenamiento tenga su propia carpeta</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">log_dir </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;logs/fit/&quot;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> datetime</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">datetime</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">now</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">strftime</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;%Y%m%d-%H%M%S&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 2. Crear el callback de TensorBoard</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tensorboard_callback </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> tf</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">keras</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">callbacks</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">TensorBoard</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">log_dir</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">log_dir</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> histogram_freq</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 3. Entrenar el modelo pasando el callback en una lista</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    X_train</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_train</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    epochs</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">100</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    validation_data</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">X_valid</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> y_valid</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    callbacks</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">tensorboard_callback</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># 4. Mostrar el panel de TensorBoard directamente en el cuaderno</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">%</span><span class="token plain">load_ext tensorboard</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">%</span><span class="token plain">tensorboard </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">-</span><span class="token plain">logdir logs</span><span class="token operator" style="color:#393A34">/</span><span class="token plain">fit</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="en-qué-fijarnos-en-tensorboard">¿En qué fijarnos en TensorBoard?<a href="#en-qué-fijarnos-en-tensorboard" class="hash-link" aria-label="Enlace directo al ¿En qué fijarnos en TensorBoard?" title="Enlace directo al ¿En qué fijarnos en TensorBoard?">​</a></h3>
<p>Una vez que se abre el panel, puedes elegir entre visualizar los datos en diferentes pestañas. Las más útiles para monitorizar la evolución del entrenamiento son <strong>Time Series</strong> (vista moderna recomendada) o <strong>Scalars</strong> (vista clásica):</p>
<ol>
<li><strong>Time Series:</strong> Es la mejor vista para observar cómo evolucionan las métricas a lo largo del tiempo (épocas). Te permite ver claramente la curva de entrenamiento y validación superpuestas.</li>
<li><strong>Scalars:</strong> Muestra exactamente la misma información pero con la interfaz clásica. Es útil si necesitas ajustar el <em>smoothing</em> (suavizado) de las curvas de forma más manual.</li>
</ol>
<p>En cualquiera de las dos pestañas, las gráficas fundamentales a vigilar son:</p>
<ol>
<li><strong><code>epoch_loss</code> / <code>val_loss</code></strong>: Es la gráfica fundamental. Nos dice el error (MSE) en cada época. Es la que usamos para ver si el modelo converge.</li>
<li><strong><code>epoch_mae</code> / <code>val_mae</code></strong>: Es la métrica que nosotros entendemos (error en unidades reales). Es muy útil para comunicar resultados.</li>
</ol>
<p>En estas gráficas, debemos buscar las siguientes señales:</p>
<ul>
<li><strong>Tendencia de las curvas</strong>: Lo ideal es que tanto la curva de <strong>entrenamiento (train)</strong> como la de <strong>validación (val)</strong> bajen de forma suave. Si la curva es muy &quot;dentada&quot; o tiene picos bruscos, puede ser señal de que el <em>learning rate</em> es demasiado alto.</li>
<li><strong>Gap entre curvas</strong>: Es normal que la pérdida de entrenamiento sea un poco menor que la de validación. Sin embargo, si la distancia entre ambas se vuelve cada vez más grande, significa que el modelo está empezando a memorizar (overfitting).</li>
<li><strong>El punto de &quot;despegue&quot;</strong>: Fíjate en el momento exacto en que la curva de validación deja de bajar y empieza a subir lentamente. Ese es el momento óptimo para detener el entrenamiento (y es lo que automatizaremos con el <em>Early Stopping</em>).</li>
<li><strong>Comparación de experimentos</strong>: TensorBoard nos permite marcar varios entrenamientos a la izquierda. Podrás ver, por ejemplo, si la red con 128 neuronas (curva azul) baja más rápido que la de 32 neuronas (curva roja).</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Gráfico EDA" src="/DevTacora/assets/images/tensorboard-loss-68ebcb07e9696bc52f72719b30831139.png" width="1276" height="496" class="img_ev3q"></p>
<p><strong>Conclusiones de esta gráfica:</strong></p>
<p>Al observar una gráfica de <code>epoch_loss</code> como esta, podemos extraer conclusiones clave para mejorar el modelo:</p>
<ol>
<li><strong>Entrenamiento vs. Validación</strong>: La curva naranja representa el <strong>entrenamiento</strong> (va bajando de forma suave hasta el final), mientras que la azul representa la <strong>validación</strong> (se vuelve muy inestable y ruidosa).</li>
<li><strong>Inestabilidad (Ruido)</strong>: Los picos constantes en la curva azul sugieren que el modelo tiene dificultades para generalizar en cada batch o que el conjunto de validación es pequeño/específico, aunque la tendencia general es clara.</li>
<li><strong>Divergencia y Overfitting</strong>: A partir de la época 100, la brecha entre las dos curvas se ensancha drásticamente. Mientras el error de entrenamiento sigue bajando (el modelo memoriza), el error de validación deja de mejorar. Esto es un caso de libro de <strong>Overfitting</strong>.</li>
<li><strong>Punto Óptimo</strong>: El mejor momento para haber detenido este entrenamiento fue alrededor de la <strong>época 40-50</strong>, donde la curva azul alcanzó su punto más bajo antes de volverse errática. Entrenar hasta la época 500 ha sido un desperdicio de tiempo y ha empeorado el modelo final.</li>
</ol>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="demo-práctica-california-housing">Demo práctica: California Housing<a href="#demo-práctica-california-housing" class="hash-link" aria-label="Enlace directo al Demo práctica: California Housing" title="Enlace directo al Demo práctica: California Housing">​</a></h2>
<p>Puedes ver una demostración completa de lo anterior en este <a href="/DevTacora/assets/files/california_housing_redes_densas-545e566ab522fda3f209992c97582599.ipynb" target="_blank">cuaderno de Colab</a> donde entrenamos tres arquitecturas diferentes para el dataset de California Housing y analizamos los resultados en TensorBoard.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="actividad-de-seguimiento">Actividad de seguimiento<a href="#actividad-de-seguimiento" class="hash-link" aria-label="Enlace directo al Actividad de seguimiento" title="Enlace directo al Actividad de seguimiento">​</a></h2>
<p>Para poner en práctica estos conceptos, implementa una red neuronal para predecir la demanda de alquiler de bicicletas utilizando el <strong>Bike Sharing Dataset</strong>.</p>
<p>Reutiliza el Colab que ya realizaste en el tema anterior, donde deberías tener hecho el EDA, preprocesamiento y evaluación de modelos de Machine Learning clásico.</p>
<p><strong>Requisitos de la actividad:</strong></p>
<ol>
<li><strong>Arquitecturas</strong>: Define y entrena al menos <strong>3 configuraciones de red</strong> diferentes (por ejemplo: una baseline, una simple con una capa oculta y una más profunda/ancha).</li>
<li><strong>Monitorización</strong>: Utiliza el callback de <strong>TensorBoard</strong> para registrar el entrenamiento de todos los modelos y describe las gráficas de epoch_loss.</li>
<li><strong>Evaluación</strong>: Compara los modelos utilizando las métricas.</li>
</ol></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Página del documento"><a class="pagination-nav__link pagination-nav__link--prev" href="/DevTacora/docs/category/redes-densas"><div class="pagination-nav__sublabel">Anterior</div><div class="pagination-nav__label">Redes Densas</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#qué-es-una-red-neuronal-densa" class="table-of-contents__link toc-highlight">¿Qué es una Red Neuronal Densa?</a></li><li><a href="#arquitectura-para-regresión" class="table-of-contents__link toc-highlight">Arquitectura para Regresión</a><ul><li><a href="#a-capa-de-entrada-input" class="table-of-contents__link toc-highlight">A. Capa de Entrada (Input)</a></li><li><a href="#b-capas-ocultas-hidden-layers" class="table-of-contents__link toc-highlight">B. Capas Ocultas (Hidden Layers)</a></li><li><a href="#c-capa-de-salida-output" class="table-of-contents__link toc-highlight">C. Capa de Salida (Output)</a></li><li><a href="#implementación-básica-en-keras" class="table-of-contents__link toc-highlight">Implementación básica en Keras</a></li></ul></li><li><a href="#configuración-del-entrenamiento" class="table-of-contents__link toc-highlight">Configuración del Entrenamiento</a><ul><li><a href="#función-de-pérdida-loss-function" class="table-of-contents__link toc-highlight">Función de Pérdida (Loss Function)</a></li><li><a href="#optimizador" class="table-of-contents__link toc-highlight">Optimizador</a></li><li><a href="#métricas" class="table-of-contents__link toc-highlight">Métricas</a></li><li><a href="#implementación-básica-en-keras-1" class="table-of-contents__link toc-highlight">Implementación básica en Keras</a></li></ul></li><li><a href="#el-proceso-de-entrenamiento-batches-y-validación" class="table-of-contents__link toc-highlight">El Proceso de Entrenamiento: Batches y Validación</a><ul><li><a href="#qué-es-el-batch-size" class="table-of-contents__link toc-highlight">¿Qué es el Batch Size?</a></li><li><a href="#el-conjunto-de-validación-validation-split" class="table-of-contents__link toc-highlight">El Conjunto de Validación (Validation Split)</a></li></ul></li><li><a href="#caso-de-estudio-california-housing" class="table-of-contents__link toc-highlight">Caso de Estudio: California Housing</a><ul><li><a href="#el-problema" class="table-of-contents__link toc-highlight">El Problema</a></li><li><a href="#eda-y-preprocesamiento" class="table-of-contents__link toc-highlight">EDA y preprocesamiento</a></li><li><a href="#la-importancia-de-la-estandarización" class="table-of-contents__link toc-highlight">La Importancia de la Estandarización</a></li></ul></li><li><a href="#análisis-de-experimentos-tensorboard" class="table-of-contents__link toc-highlight">Análisis de Experimentos: TensorBoard</a><ul><li><a href="#en-qué-fijarnos-en-tensorboard" class="table-of-contents__link toc-highlight">¿En qué fijarnos en TensorBoard?</a></li></ul></li><li><a href="#demo-práctica-california-housing" class="table-of-contents__link toc-highlight">Demo práctica: California Housing</a></li><li><a href="#actividad-de-seguimiento" class="table-of-contents__link toc-highlight">Actividad de seguimiento</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">
        <section classname="bg-white border-t border-gray-100">
      <div classname="max-w-4xl mx-auto px-6 py-16 text-center">
        <h3 classname="text-2xl font-bold text-gray-900 mb-4">
          Construyendo conocimiento, línea por línea
        </h3>
        <p classname="text-gray-600 leading-relaxed">
          © 2026 Alicia Cámara Casares - Contenido bajo licencia 
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer" classname="text-blue-600 hover:text-blue-700 underline">
                CC BY-NC-SA 4.0
              </a>.
        </p>
      </div>
    </section>
      </div></div></div></footer></div>
</body>
</html>