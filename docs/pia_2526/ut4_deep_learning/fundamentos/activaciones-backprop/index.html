<!doctype html>
<html lang="es" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-pia_2526/ut4_deep_learning/fundamentos/activaciones-backprop" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Funciones de activaci√≥n y Backpropagation | DevTacora</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://acamarac02.github.io/DevTacora/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://acamarac02.github.io/DevTacora/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut4_deep_learning/fundamentos/activaciones-backprop"><meta data-rh="true" property="og:locale" content="es"><meta data-rh="true" name="docusaurus_locale" content="es"><meta data-rh="true" name="docsearch:language" content="es"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Funciones de activaci√≥n y Backpropagation | DevTacora"><meta data-rh="true" name="description" content="Entendiendo el motor de las redes neuronales: c√≥mo la no linealidad y el ajuste de errores permiten que la IA aprenda patrones complejos."><meta data-rh="true" property="og:description" content="Entendiendo el motor de las redes neuronales: c√≥mo la no linealidad y el ajuste de errores permiten que la IA aprenda patrones complejos."><meta data-rh="true" name="keywords" content="funciones de activaci√≥n,relu,sigmoid,softmax,backpropagation,descenso por gradiente,optimizadores,redes neuronales"><link data-rh="true" rel="icon" href="/DevTacora/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut4_deep_learning/fundamentos/activaciones-backprop"><link data-rh="true" rel="alternate" href="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut4_deep_learning/fundamentos/activaciones-backprop" hreflang="es"><link data-rh="true" rel="alternate" href="https://acamarac02.github.io/DevTacora/docs/pia_2526/ut4_deep_learning/fundamentos/activaciones-backprop" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"UT4. Deep Learning","item":"https://acamarac02.github.io/DevTacora/docs/category/ut4-deep-learning"},{"@type":"ListItem","position":2,"name":"Fundamentos","item":"https://acamarac02.github.io/DevTacora/docs/category/fundamentos"},{"@type":"ListItem","position":3,"name":"Funciones de activaci√≥n y Backpropagation","item":"https://acamarac02.github.io/DevTacora/docs/pia_2526/ut4_deep_learning/fundamentos/activaciones-backprop"}]}</script><link rel="alternate" type="application/rss+xml" href="/DevTacora/blog/rss.xml" title="DevTacora RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/DevTacora/blog/atom.xml" title="DevTacora Atom Feed">




<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7WCKN9ZY1F"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-7WCKN9ZY1F",{anonymize_ip:!0})</script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/DevTacora/assets/css/styles.71ba2beb.css">
<script src="/DevTacora/assets/js/runtime~main.9639b348.js" defer="defer"></script>
<script src="/DevTacora/assets/js/main.444011df.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Saltar al contenido principal"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Saltar al contenido principal</a></div><nav aria-label="Principal" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Alternar barra lateral" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/DevTacora/"><div class="navbar__logo"><img src="/DevTacora/img/devtacora_logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/DevTacora/img/devtacora_logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">DevTacora</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/DevTacora/docs/pia_2526/">PIA</a><a class="navbar__item navbar__link" href="/DevTacora/docs/pmdm_2526/">PMDM</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/DevTacora/docs/licencia">Licencia</a><a href="https://www.linkedin.com/in/aliciacamcas" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Cambiar entre modo oscuro y claro (actualmente system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Volver al principio" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Barra lateral de Documentos" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/DevTacora/docs/pia_2526/">Presentaci√≥n</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/DevTacora/docs/category/ut1-introducci√≥n-a-la-ia">UT1. Introducci√≥n a la IA</a><button aria-label="Ampliar la categor√≠a &#x27;UT1. Introducci√≥n a la IA&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/DevTacora/docs/category/ut2-python-para-la-ia">UT2. Python para la IA</a><button aria-label="Ampliar la categor√≠a &#x27;UT2. Python para la IA&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/DevTacora/docs/category/ut3-machine-learning">UT3. Machine Learning</a><button aria-label="Ampliar la categor√≠a &#x27;UT3. Machine Learning&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/DevTacora/docs/category/ut4-deep-learning">UT4. Deep Learning</a><button aria-label="Colapsar categor√≠a &#x27;UT4. Deep Learning&#x27; de la barra lateral" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut4_deep_learning/introduccion">Introducci√≥n</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/DevTacora/docs/category/fundamentos">Fundamentos</a><button aria-label="Colapsar categor√≠a &#x27;Fundamentos&#x27; de la barra lateral" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut4_deep_learning/fundamentos/conceptos-teoricos-primera-red">Conceptos te√≥ricos y primera red neuronal</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/DevTacora/docs/pia_2526/ut4_deep_learning/fundamentos/activaciones-backprop">Funciones de activaci√≥n y Backpropagation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/DevTacora/docs/pia_2526/ut4_deep_learning/fundamentos/exportar-modelo">Exportaci√≥n de modelos</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/DevTacora/docs/category/redes-densas">Redes Densas</a><button aria-label="Ampliar la categor√≠a &#x27;Redes Densas&#x27; de la barra lateral" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Rastro de navegaci√≥n"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="P√°gina de Inicio" class="breadcrumbs__link" href="/DevTacora/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/DevTacora/docs/category/ut4-deep-learning"><span>UT4. Deep Learning</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/DevTacora/docs/category/fundamentos"><span>Fundamentos</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Funciones de activaci√≥n y Backpropagation</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">En esta p√°gina</button></div><div class="theme-doc-markdown markdown"><header><h1>Funciones de activaci√≥n y Backpropagation</h1></header><p>En el apartado anterior vimos c√≥mo una neurona simple puede aprender una relaci√≥n lineal (como Celsius a Fahrenheit). Pero, ¬øqu√© ocurre cuando el problema no es una l√≠nea recta? ¬øC√≥mo hace una red para aprender a reconocer un gato o predecir el precio de una vivienda con cientos de variables?</p>
<p>En esta secci√≥n vamos a descubrir:</p>
<ul>
<li><strong>El &quot;pegamento&quot; de las redes</strong>: Las funciones de activaci√≥n.</li>
<li><strong>El cerebro del entrenamiento</strong>: El algoritmo de Backpropagation.</li>
<li><strong>La br√∫jula</strong>: El descenso por gradiente y los optimizadores.</li>
</ul>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>V√≠deo recomendado</div><div class="admonitionContent_BuS1"><p>Para reforzar visualmente la explicaci√≥n de backpropagation y funciones de activaci√≥n, te recomiendo ver el siguiente v√≠deo:</p><p><a href="https://www.youtube.com/watch?v=_0wdproot34&amp;t=2s" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=_0wdproot34&amp;t=2s</a></p><p>Explica de forma clara c√≥mo se propaga el error en una red neuronal y c√≥mo se aplican las derivadas mediante la regla de la cadena.</p></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="por-qu√©-necesitamos-funciones-de-activaci√≥n">¬øPor qu√© necesitamos funciones de activaci√≥n?<a href="#por-qu√©-necesitamos-funciones-de-activaci√≥n" class="hash-link" aria-label="Enlace directo al ¬øPor qu√© necesitamos funciones de activaci√≥n?" title="Enlace directo al ¬øPor qu√© necesitamos funciones de activaci√≥n?">‚Äã</a></h2>
<p>Si recordamos el perceptr√≥n, su c√°lculo era una suma ponderada: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>a</mi><mi>l</mi><mi>i</mi><mi>d</mi><mi>a</mi><mo>=</mo><mo>‚àë</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">salida = \sum(x_i w_i) + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop op-symbol small-op" style="position:relative;top:0em">‚àë</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span>. Esto es, esencialmente, una operaci√≥n lineal.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="el-problema-de-la-linealidad">El problema de la linealidad<a href="#el-problema-de-la-linealidad" class="hash-link" aria-label="Enlace directo al El problema de la linealidad" title="Enlace directo al El problema de la linealidad">‚Äã</a></h3>
<p>Imagina que construyes una red neuronal con 100 capas de profundidad, pero <strong>no utilizas</strong> funciones de activaci√≥n. Matem√°ticamente, la combinaci√≥n de muchas funciones lineales sigue siendo una funci√≥n lineal.</p>
<blockquote>
<p><strong>Dicho de otro modo:</strong> Sin funciones de activaci√≥n, una red neuronal ultra-compleja de mil capas tiene la misma capacidad de aprendizaje que una simple Regresi√≥n Lineal. No importa cu√°ntas neuronas a√±adas; solo podr√≠as dibujar l√≠neas rectas.</p>
</blockquote>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="introduciendo-la-no-linealidad">Introduciendo la &quot;no linealidad&quot;<a href="#introduciendo-la-no-linealidad" class="hash-link" aria-label="Enlace directo al Introduciendo la &quot;no linealidad&quot;" title="Enlace directo al Introduciendo la &quot;no linealidad&quot;">‚Äã</a></h3>
<p>El mundo real no es lineal. Para que una red neuronal pueda aprender patrones complejos (como curvas, bordes en una imagen o estructuras de lenguaje), necesitamos algo que &quot;rompa&quot; esa linealidad.</p>
<p>Las <strong>funciones de activaci√≥n</strong> se encargan de esto:</p>
<ul>
<li>Deciden si una neurona debe &quot;dispararse&quot; (activarse) o no.</li>
<li>Transforman la suma ponderada en algo m√°s complejo.</li>
<li>Permiten que la red aprenda <strong>formas curvas y patrones intrincados</strong> en los datos.</li>
</ul>
<p>Al aplicar una funci√≥n de activaci√≥n a la salida de cada neurona, permitimos que la red se convierta en un <strong>aproximador universal</strong>, capaz de representar pr√°cticamente cualquier relaci√≥n matem√°tica entre la entrada y la salida.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cat√°logo-de-funciones-de-activaci√≥n-m√°s-comunes">Cat√°logo de funciones de activaci√≥n m√°s comunes<a href="#cat√°logo-de-funciones-de-activaci√≥n-m√°s-comunes" class="hash-link" aria-label="Enlace directo al Cat√°logo de funciones de activaci√≥n m√°s comunes" title="Enlace directo al Cat√°logo de funciones de activaci√≥n m√°s comunes">‚Äã</a></h2>
<p>Para que la red neuronal pueda aprender relaciones complejas, necesitamos aplicar diferentes &quot;filtros&quot; matem√°ticos a la salida de las neuronas. Estas son las funciones de activaci√≥n m√°s utilizadas en la actualidad:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="relu-rectified-linear-unit">ReLU (Rectified Linear Unit)<a href="#relu-rectified-linear-unit" class="hash-link" aria-label="Enlace directo al ReLU (Rectified Linear Unit)" title="Enlace directo al ReLU (Rectified Linear Unit)">‚Äã</a></h3>
<p>Es el est√°ndar de la industria para las <strong>capas ocultas</strong>. Su f√≥rmula es <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>‚Å°</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x) = \max(0, x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>.</p>
<p><img decoding="async" loading="lazy" alt="Gr√°fica" src="/DevTacora/assets/images/fa-relu-7af8b5b878a3e41e52e9f8b315d0d78c.png" width="846" height="554" class="img_ev3q"></p>
<ul>
<li><strong>Funcionamiento</strong>: Si la entrada es positiva, la deja pasar exactamente como est√°; si es negativa, la convierte en cero.</li>
<li><strong>Por qu√© se usa</strong>: Es extremadamente r√°pida de calcular. Adem√°s, ayuda a que los modelos grandes aprendan m√°s r√°pido porque no &quot;aplana&quot; los valores positivos (evita la saturaci√≥n).</li>
<li><strong>Riesgo</strong>: Existe el problema de la &quot;muerte de neuronas&quot; si muchas entradas se vuelven negativas y se quedan bloqueadas en cero.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sigmoide-sigmoid-">Sigmoide (Sigmoid) üîó<a href="#sigmoide-sigmoid-" class="hash-link" aria-label="Enlace directo al Sigmoide (Sigmoid) üîó" title="Enlace directo al Sigmoide (Sigmoid) üîó">‚Äã</a></h3>
<p>Esta funci√≥n toma cualquier n√∫mero y lo &quot;aplasta&quot; para que quepa en el rango entre <strong>0 y 1</strong>.</p>
<p><img decoding="async" loading="lazy" alt="Gr√°fica" src="/DevTacora/assets/images/fa-sigmoid-a7e7b08998b814c8ed5f626638bf05a3.png" width="856" height="554" class="img_ev3q"></p>
<ul>
<li><strong>Interpretaci√≥n</strong>: Ese valor entre 0 y 1 se puede leer directamente como una <strong>probabilidad</strong> (por ejemplo, 0.85 = 85% de probabilidad).</li>
<li><strong>Uso ideal</strong>: Casi exclusivamente en la <strong>capa de salida</strong> de problemas donde la respuesta es &quot;S√≠ o No&quot; (clasificaci√≥n binaria).</li>
<li><strong>Limitaci√≥n</strong>: En capas profundas es problem√°tica porque sus extremos son muy planos, lo que hace que el aprendizaje sea lent√≠simo (problema del gradiente desvaneciente).</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tanh-tangente-hiperb√≥lica">Tanh (Tangente hiperb√≥lica)<a href="#tanh-tangente-hiperb√≥lica" class="hash-link" aria-label="Enlace directo al Tanh (Tangente hiperb√≥lica)" title="Enlace directo al Tanh (Tangente hiperb√≥lica)">‚Äã</a></h3>
<p>Es una versi√≥n &quot;estirada&quot; de la sigmoide que va de <strong>-1 a 1</strong>.</p>
<p><img decoding="async" loading="lazy" alt="Gr√°fica" src="/DevTacora/assets/images/fa-tanh-ad5646855c35f4f3a1851588bd7d8cd2.png" width="976" height="576" class="img_ev3q"></p>
<ul>
<li><strong>Ventaja sobre la sigmoide</strong>: Al estar centrada en el <strong>cero</strong>, los datos que salen de ella tienen una media cercana a cero, lo que suele facilitar que la siguiente capa aprenda mejor.</li>
<li><strong>Uso</strong>: Se usa en capas ocultas cuando queremos que el modelo sea capaz de manejar valores negativos con facilidad.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="softmax">Softmax<a href="#softmax" class="hash-link" aria-label="Enlace directo al Softmax" title="Enlace directo al Softmax">‚Äã</a></h3>
<p>A diferencia de las anteriores, Softmax no mira a una sola neurona, sino a <strong>todo el grupo</strong> de neuronas de la capa de salida.</p>
<p><img decoding="async" loading="lazy" alt="Gr√°fico EDA" src="/DevTacora/assets/images/fa-softmax-0c31c3c637fb0d824cd8883ce8ad90eb.png" width="624" height="477" class="img_ev3q"></p>
<ul>
<li><strong>L√≥gica</strong>: Toma todas las puntuaciones de salida y las convierte en una <strong>distribuci√≥n de probabilidad</strong> que suma 100% (o 1.0).</li>
<li><strong>Uso</strong>: Es obligatoria en la capa de salida para problemas de <strong>clasificaci√≥n multiclase</strong> (por ejemplo, decidir si una imagen es un gato, perro o p√°jaro).</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="comparativa">Comparativa<a href="#comparativa" class="hash-link" aria-label="Enlace directo al Comparativa" title="Enlace directo al Comparativa">‚Äã</a></h3>
<table><thead><tr><th>Funci√≥n</th><th>F√≥rmula simplificada</th><th>Rango</th><th>Aplicaci√≥n T√≠pica</th></tr></thead><tbody><tr><td><strong>ReLU</strong></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>‚Å°</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x) = \max(0, x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mi mathvariant="normal">‚àû</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">[0, \infty)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">‚àû</span><span class="mclose">)</span></span></span></span></td><td>Capas ocultas (General)</td></tr><tr><td><strong>Sigmoide</strong></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>‚àí</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">f(x) = \frac{1}{1 + e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2484em;vertical-align:-0.4033em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7027em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">‚àí</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></td><td>Salida binaria (Probabilidad)</td></tr><tr><td><strong>Tanh</strong></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>‚àí</mo><msup><mi>e</mi><mrow><mo>‚àí</mo><mi>x</mi></mrow></msup></mrow><mrow><msup><mi>e</mi><mi>x</mi></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>‚àí</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">f(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.3907em;vertical-align:-0.4033em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9874em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5935em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7027em"><span style="top:-2.786em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">‚àí</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7385em"><span style="top:-2.931em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span><span class="mbin mtight">‚àí</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8477em"><span style="top:-2.931em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">‚àí</span><span class="mord mathnormal mtight">x</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>‚àí</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(-1, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">‚àí</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></td><td>Capas ocultas espec√≠ficas</td></tr><tr><td><strong>Softmax</strong></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msup><mrow><mo>‚àë</mo><msup><mi>e</mi><msub><mi>x</mi><mi>j</mi></msub></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">f(x_i) = \frac{e^{x_i}}{\sum e^{x_j}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.4413em;vertical-align:-0.5303em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.911em"><span style="top:-2.6447em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">‚àë</span><span class="mspace mtight" style="margin-right:0.1952em"></span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.779em"><span style="top:-2.9714em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em"><span class="pstrut" style="height:2.6595em"></span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.5092em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7385em"><span style="top:-2.931em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:0em;margin-right:0.1em"><span class="pstrut" style="height:2.6595em"></span><span class="mord mathnormal mtight">i</span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.3147em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.5303em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></td><td>Salida multiclase (Excluyente)</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="c√≥mo-aprende-la-red-el-descenso-por-gradiente">¬øC√≥mo aprende la red? El descenso por gradiente<a href="#c√≥mo-aprende-la-red-el-descenso-por-gradiente" class="hash-link" aria-label="Enlace directo al ¬øC√≥mo aprende la red? El descenso por gradiente" title="Enlace directo al ¬øC√≥mo aprende la red? El descenso por gradiente">‚Äã</a></h2>
<p>Una vez que la red ha dado una respuesta (gracias a sus pesos, sesgos y funciones de activaci√≥n), comparamos ese resultado con el valor real usando la <strong>funci√≥n de p√©rdida (Loss Function)</strong>. Si el error es alto, hay que ajustar los pesos. Pero, ¬øhacia d√≥nde los movemos?</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="analog√≠a-del-arquero-qu√©-estamos-corrigiendo">Analog√≠a del arquero: ¬øQu√© estamos corrigiendo?<a href="#analog√≠a-del-arquero-qu√©-estamos-corrigiendo" class="hash-link" aria-label="Enlace directo al Analog√≠a del arquero: ¬øQu√© estamos corrigiendo?" title="Enlace directo al Analog√≠a del arquero: ¬øQu√© estamos corrigiendo?">‚Äã</a></h3>
<p>Imagina que est√°s aprendiendo a disparar con un arco. No eres un experto, as√≠ que la primera vez que disparas, el resultado es un poco ca√≥tico.</p>
<p>El proceso del arquero ser√≠a algo similar a:</p>
<ol>
<li><strong>El Disparo (Forward Propagation):</strong> Te preparas, ajustas la tensi√≥n de la cuerda, inclinas el brazo y sueltas la flecha. La flecha vuela y aterriza en alg√∫n lugar.</li>
<li><strong>La Medida del Error (Loss Function):</strong> Miras d√≥nde cay√≥ la flecha en relaci√≥n con el centro de la diana. Si cay√≥ 20 cm a la derecha y 10 cm arriba, esa distancia es tu &quot;error&quot;.</li>
<li><strong>La Reflexi√≥n (Backpropagation):</strong> Aqu√≠ es donde ocurre la magia. No solo dices &quot;fall√©&quot;, sino que piensas: <em>&quot;Si la flecha se fue a la derecha, ¬øqu√© caus√≥ eso?&quot;</em>. Tal vez fue la presi√≥n de tus dedos o la posici√≥n de tu hombro. Vas &quot;hacia atr√°s&quot;, desde el error hasta tus movimientos iniciales, para entender qu√© corregir.</li>
<li><strong>El Ajuste (Optimizer):</strong> La pr√≥xima vez, decides tensar un poco menos o mover el brazo un mil√≠metro a la izquierda. No cambias todo dr√°sticamente, haces un ajuste peque√±o.</li>
</ol>
<p>El error de nuestra red (la distancia al centro de la diana) se debe a dos factores:</p>
<ul>
<li><strong>El Sesgo (Bias) üéØ</strong>: Es la distancia entre el centro de la diana y el lugar donde suelen caer las flechas. Si el arquero siempre dispara demasiado a la izquierda, tiene un <strong>sesgo alto</strong>. En nuestra red, esto significa que el modelo es demasiado simple (underfitting) y no alcanza a entender la complejidad de los datos.</li>
<li><strong>La Varianza (Variance) üìà</strong>: Es la dispersi√≥n de las flechas. Si el arquero dispara y las flechas quedan muy lejos unas de otras, tiene una <strong>varianza alta</strong>. En la red, esto ocurre cuando el modelo es demasiado sensible a peque√±as variaciones (ruido) del entrenamiento (overfitting).</li>
</ul>
<blockquote>
<p><strong>El objetivo del entrenamiento</strong>: El Descenso por Gradiente es el proceso de ajustar la t√©cnica del arquero tras cada disparo para que sea preciso (bajo sesgo) y constante (baja varianza).</p>
</blockquote>
<p><img decoding="async" loading="lazy" alt="Gr√°fica" src="/DevTacora/assets/images/arquero-e2dbd9e48b0c19125fb0f412ec378981.png" width="890" height="799" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="la-analog√≠a-de-la-monta√±a-con-niebla">La analog√≠a de la monta√±a con niebla<a href="#la-analog√≠a-de-la-monta√±a-con-niebla" class="hash-link" aria-label="Enlace directo al La analog√≠a de la monta√±a con niebla" title="Enlace directo al La analog√≠a de la monta√±a con niebla">‚Äã</a></h3>
<p>¬øC√≥mo sabe el arquero qu√© corregir? Imagina que est√°s en la cima de una monta√±a y hay una niebla tan espesa que no ves nada. Tu objetivo es llegar al <strong>valle</strong> (el punto donde el error es m√≠nimo).</p>
<ol>
<li>Como no ves el camino, tanteas con el pie el terreno a tu alrededor.</li>
<li>Buscas la direcci√≥n en la que el suelo <strong>baja m√°s r√°pido</strong>.</li>
<li>Das un paso peque√±o en esa direcci√≥n (el tama√±o del paso es el <strong>Learning Rate</strong>).</li>
<li>Repites el proceso hasta que sientes que el suelo ya no baja m√°s.</li>
</ol>
<p><img decoding="async" loading="lazy" alt="Gr√°fico EDA" src="/DevTacora/assets/images/descenso-gradiente-90cf211119500dc51cda0dea1dfa29a8.png" width="589" height="479" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="el-gradiente-como-br√∫jula">El Gradiente como br√∫jula<a href="#el-gradiente-como-br√∫jula" class="hash-link" aria-label="Enlace directo al El Gradiente como br√∫jula" title="Enlace directo al El Gradiente como br√∫jula">‚Äã</a></h3>
<p>En matem√°ticas, el <strong>gradiente</strong> es un vector que nos indica la direcci√≥n de m√°xima subida. Como nosotros queremos <strong>bajar</strong> el error, seguimos la direcci√≥n opuesta al gradiente.</p>
<ul>
<li>Si el gradiente es positivo: el peso debe disminuir.</li>
<li>Si el gradiente es negativo: el peso debe aumentar.</li>
</ul>
<p><img decoding="async" loading="lazy" alt="Gr√°fica" src="/DevTacora/assets/images/descenso-gradiente-2-fd7115146b6eb666665ba6b4786fb0a2.png" width="971" height="902" class="img_ev3q"></p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>ACLARACI√ìN DESCENSO DE GRADIENTE</div><div class="admonitionContent_BuS1"><p>El descenso por gradiente no nos dice cu√°nto error hay (eso lo dice la funci√≥n de p√©rdida), nos dice <strong>hacia d√≥nde caminar</strong> para que el error baje en la siguiente iteraci√≥n.</p><p>Para m√°s informaci√≥n puedes leer este art√≠culo de <a href="https://codificandobits.com/blog/el-gradiente-descendente/" target="_blank" rel="noopener noreferrer">codificandobits</a></p></div></div>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="backpropagation-el-arte-de-repartir-culpas">Backpropagation: El arte de repartir culpas<a href="#backpropagation-el-arte-de-repartir-culpas" class="hash-link" aria-label="Enlace directo al Backpropagation: El arte de repartir culpas" title="Enlace directo al Backpropagation: El arte de repartir culpas">‚Äã</a></h2>
<p>El <strong>Backpropagation</strong> (o propagaci√≥n hacia atr√°s) es el coraz√≥n del aprendizaje en las redes neuronales. Es el proceso matem√°tico que permite &quot;repartir las culpas&quot; del error entre todos los pesos y sesgos de la red para que el <strong>descenso por gradiente</strong> sepa exactamente qu√© ajustar.</p>
<p>Si el descenso por gradiente es nuestra br√∫jula para bajar la monta√±a, el <strong>Backpropagation</strong> es el mecanismo que nos dice cu√°nto contribuy√≥ cada parte de nuestra red a que termin√°ramos en el lugar equivocado.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="el-flujo-de-la-informaci√≥n-forward-vs-backward">El flujo de la informaci√≥n: Forward vs. Backward<a href="#el-flujo-de-la-informaci√≥n-forward-vs-backward" class="hash-link" aria-label="Enlace directo al El flujo de la informaci√≥n: Forward vs. Backward" title="Enlace directo al El flujo de la informaci√≥n: Forward vs. Backward">‚Äã</a></h3>
<p>Para entender el Backpropagation, hay que visualizar el viaje de los datos en dos sentidos:</p>
<ol>
<li><strong>Forward Pass (Hacia adelante)</strong>: Los datos entran, se multiplican por los pesos, pasan por las funciones de activaci√≥n y generan una predicci√≥n.</li>
<li><strong>C√°lculo del Error</strong>: Comparamos la predicci√≥n con el valor real usando la funci√≥n de p√©rdida.</li>
<li><strong>Backward Pass (Hacia atr√°s)</strong>: El error viaja en sentido contrario, desde la salida hasta la entrada, calculando la responsabilidad de cada neurona en ese fallo.</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="qui√©n-tiene-m√°s-culpa">¬øQui√©n tiene m√°s culpa?<a href="#qui√©n-tiene-m√°s-culpa" class="hash-link" aria-label="Enlace directo al ¬øQui√©n tiene m√°s culpa?" title="Enlace directo al ¬øQui√©n tiene m√°s culpa?">‚Äã</a></h3>
<p>Imagina que el arquero falla el tiro por 10 cm. El Backpropagation analiza la &quot;cadena de mando&quot; hacia atr√°s:</p>
<ul>
<li>¬øFue culpa de la tensi√≥n del arco (capa de salida)?</li>
<li>¬øFue culpa de la postura del brazo (capa oculta)?</li>
<li>¬øO fue culpa de c√≥mo coloc√≥ los pies al principio (capa de entrada)?</li>
</ul>
<p>Matem√°ticamente, esto se hace mediante la <strong>Regla de la Cadena</strong>. Esta regla permite calcular c√≥mo cambia el error total cuando movemos un peso espec√≠fico en el medio de la red.</p>
<blockquote>
<p><strong>En resumen</strong>: El Backpropagation calcula el <strong>gradiente</strong> (la direcci√≥n del ajuste) para cada peso individual de la red, permitiendo que el optimizador sepa si debe subirlo o bajarlo ligeramente.</p>
</blockquote>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="experimentaci√≥n-pr√°ctica-google-colab">Experimentaci√≥n Pr√°ctica: Google Colab<a href="#experimentaci√≥n-pr√°ctica-google-colab" class="hash-link" aria-label="Enlace directo al Experimentaci√≥n Pr√°ctica: Google Colab" title="Enlace directo al Experimentaci√≥n Pr√°ctica: Google Colab">‚Äã</a></h3>
<p>Para asentar estos conceptos, hemos preparado un cuaderno interactivo donde puedes ver al &quot;arquero&quot; en acci√≥n.</p>
<p>üëâ <strong>Puedes abrir el cuaderno aqu√≠:</strong>
<a href="/DevTacora/assets/files/demo_descenso_gradiente-1c18d1bad7c0f1c22da3c976b2e189c4.ipynb" target="_blank">Demo descenso gradiente</a></p>
<p><strong>¬øPara qu√© sirve este laboratorio?</strong></p>
<ul>
<li><strong>Visualizar la &quot;Monta√±a del Error&quot; üèîÔ∏è</strong>: Ver√°s c√≥mo la funci√≥n de p√©rdida crea una pendiente que la red debe bajar.</li>
<li><strong>Ajustar el paso (Learning Rate) üë£</strong>: Puedes cambiar el <code>lr</code> para ver qu√© pasa si el arquero da pasos muy cortos o demasiado largos.</li>
<li><strong>Entender la ReLU üõ§Ô∏è</strong>: Observar√°s por qu√© la gr√°fica se vuelve plana a la izquierda (el error es constante) y c√≥mo eso afecta al aprendizaje.</li>
</ul>
<p><strong>Anatom√≠a de nuestra mini-red</strong></p>
<ul>
<li><strong>1 Neurona de Entrada ():</strong> Es el punto donde la red recibe el dato inicial (en nuestro caso, el n√∫mero ).</li>
<li><strong>1 Neurona Oculta:</strong> Aqu√≠ es donde ocurre la primera transformaci√≥n. La entrada se multiplica por el <strong>Peso 1 ()</strong> y luego pasa por la funci√≥n de activaci√≥n <strong>ReLU</strong>.</li>
<li><strong>1 Neurona de Salida:</strong> El resultado de la neurona oculta se multiplica por el <strong>Peso 2 ()</strong> para darnos la <strong>Predicci√≥n</strong> final.</li>
</ul>
<p>Trabajar con una sola neurona nos permite ver con total claridad la relaci√≥n matem√°tica entre el <strong>peso</strong> y el <strong>error</strong>. En una red real con millones de neuronas, esta &quot;monta√±a de error&quot; tendr√≠a millones de dimensiones, pero la l√≥gica de bajar hacia el valle sigue siendo la misma.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="optimizadores-el-ritmo-del-aprendizaje">Optimizadores: El ritmo del aprendizaje<a href="#optimizadores-el-ritmo-del-aprendizaje" class="hash-link" aria-label="Enlace directo al Optimizadores: El ritmo del aprendizaje" title="Enlace directo al Optimizadores: El ritmo del aprendizaje">‚Äã</a></h2>
<p>Si el <strong>Backpropagation</strong> nos da la direcci√≥n (el gradiente) y el <strong>Learning Rate</strong> define el tama√±o del paso, los <strong>Optimizadores</strong> son algoritmos que deciden c√≥mo aplicar esos ajustes de forma inteligente para llegar al valle del error lo m√°s r√°pido posible sin &quot;tropezar&quot;.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="por-qu√©-necesitamos-un-optimizador">¬øPor qu√© necesitamos un optimizador?<a href="#por-qu√©-necesitamos-un-optimizador" class="hash-link" aria-label="Enlace directo al ¬øPor qu√© necesitamos un optimizador?" title="Enlace directo al ¬øPor qu√© necesitamos un optimizador?">‚Äã</a></h3>
<p>En el ejemplo del Colab, vimos que si el paso es muy grande, el peso puede rebotar de un lado a otro. Un optimizador ayuda a suavizar ese movimiento. Su funci√≥n principal es gestionar la <strong>velocidad</strong> y la <strong>inercia</strong> del descenso.</p>
<ul>
<li><strong>Inercia (Momentum) ‚öΩ</strong>: Imagina una bola bajando la monta√±a. Si la pendiente es muy pronunciada, la bola gana velocidad. El optimizador usa esto para atravesar zonas planas o peque√±os baches que podr√≠an detener a un arquero que va paso a paso.</li>
<li><strong>Adaptabilidad üß†</strong>: No todos los pesos necesitan cambiar a la misma velocidad. Algunos necesitan pasos grandes al principio y otros pasos min√∫sculos para ajustar la precisi√≥n final.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tipos-comunes-de-optimizadores">Tipos comunes de Optimizadores<a href="#tipos-comunes-de-optimizadores" class="hash-link" aria-label="Enlace directo al Tipos comunes de Optimizadores" title="Enlace directo al Tipos comunes de Optimizadores">‚Äã</a></h3>
<p>Existen varios &quot;estilos&quot; de descenso, pero estos son los m√°s utilizados:</p>
<table><thead><tr><th>Optimizador</th><th>Caracter√≠sticas</th><th>Analog√≠a</th></tr></thead><tbody><tr><td><strong>SGD</strong> (Stochastic Gradient Descent)</td><td>El m√°s b√°sico. Actualiza los pesos con cada grupo de datos.</td><td>Un caminante con br√∫jula que da pasos constantes.</td></tr><tr><td><strong>Adam</strong> (Adaptive Moment Estimation)</td><td>El est√°ndar actual. Combina inercia y pasos adaptables para cada peso.</td><td>Un explorador con GPS que corre en las bajadas y camina con cuidado al llegar al destino.</td></tr><tr><td><strong>RMSprop</strong></td><td>Muy bueno para redes que trabajan con secuencias (como texto).</td><td>Un corredor que ajusta su velocidad seg√∫n lo accidentado que sea el terreno.</td></tr></tbody></table>
<blockquote>
<p><strong>Nota t√©cnica:</strong> En la mayor√≠a de los proyectos modernos, se empieza usando <strong>Adam</strong> por defecto, ya que suele encontrar el valle del error de forma m√°s eficiente que el resto.</p>
</blockquote>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="laboratorio-comparativo-sgd-vs-adam">Laboratorio Comparativo: SGD vs. Adam<a href="#laboratorio-comparativo-sgd-vs-adam" class="hash-link" aria-label="Enlace directo al Laboratorio Comparativo: SGD vs. Adam" title="Enlace directo al Laboratorio Comparativo: SGD vs. Adam">‚Äã</a></h3>
<p>En este experimento, enfrentamos al optimizador m√°s b√°sico contra el est√°ndar de la industria. El objetivo es observar c√≥mo la <strong>inercia</strong> y la <strong>adaptabilidad</strong> cambian la forma en que una red encuentra la soluci√≥n.</p>
<p><strong>¬øQu√© observar en este Colab?</strong></p>
<ul>
<li><strong>La &quot;Memoria&quot; de Adam üß†</strong>: Nota c√≥mo Adam acumula velocidad. Si el error es grande durante varios pasos, Adam &quot;se conf√≠a&quot; y acelera, lo que puede provocar que se pase de largo (overshoot) antes de frenar.</li>
<li><strong>La Constancia de SGD üê¢</strong>: Observa que SGD es mucho m√°s previsible. Sus pasos dependen solo de la pendiente actual, lo que lo hace m√°s lento pero a veces m√°s estable en problemas simples.</li>
<li><strong>El rebasamiento (Overshoot) üé¢</strong>: F√≠jate en los valores negativos de Adam. ¬øPor qu√© sigue avanzando hacia la izquierda si el error ya era cero? Es la inercia de sus pasos anteriores intentando estabilizarse.</li>
</ul>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="problemas-comunes-en-el-entrenamiento">Problemas Comunes en el Entrenamiento<a href="#problemas-comunes-en-el-entrenamiento" class="hash-link" aria-label="Enlace directo al Problemas Comunes en el Entrenamiento" title="Enlace directo al Problemas Comunes en el Entrenamiento">‚Äã</a></h2>
<p>Incluso con el mejor optimizador, el aprendizaje puede fallar por factores matem√°ticos o de configuraci√≥n. Aqu√≠ los tres m√°s importantes:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="gradientes-explosivos-y-desvanecientes">Gradientes Explosivos y Desvanecientes<a href="#gradientes-explosivos-y-desvanecientes" class="hash-link" aria-label="Enlace directo al Gradientes Explosivos y Desvanecientes" title="Enlace directo al Gradientes Explosivos y Desvanecientes">‚Äã</a></h3>
<p>Ocurre cuando el gradiente, al viajar hacia atr√°s por las capas, se vuelve extremadamente grande o casi cero.</p>
<ul>
<li><strong>Explosivos</strong>: El ajuste es tan violento que los pesos &quot;explotan&quot; (se vuelven <code>NaN</code> o infinitos). La red se vuelve inestable.</li>
<li><strong>Desvanecientes (Vanishing)</strong>: El ajuste es tan min√∫sculo que las capas profundas dejan de aprender. Es como intentar mover una monta√±a con un soplido.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sobreajuste-overfitting">Sobreajuste (Overfitting)<a href="#sobreajuste-overfitting" class="hash-link" aria-label="Enlace directo al Sobreajuste (Overfitting)" title="Enlace directo al Sobreajuste (Overfitting)">‚Äã</a></h3>
<p>La red se vuelve tan buena memorizando los datos de entrenamiento que pierde la capacidad de generalizar. Es como un alumno que memoriza las respuestas del examen pero no entiende la materia: si le cambias una coma, suspende.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="m√≠nimos-locales-y-mesetas-plateaus">M√≠nimos Locales y Mesetas (Plateaus)<a href="#m√≠nimos-locales-y-mesetas-plateaus" class="hash-link" aria-label="Enlace directo al M√≠nimos Locales y Mesetas (Plateaus)" title="Enlace directo al M√≠nimos Locales y Mesetas (Plateaus)">‚Äã</a></h3>
<p>A veces el &quot;arquero&quot; se queda atrapado en un peque√±o valle que no es el punto m√°s bajo de la monta√±a (m√≠nimo local) o en una zona tan plana que no sabe hacia d√≥nde seguir bajando. Aqu√≠ es donde <strong>Adam</strong> brilla gracias a su &quot;inercia&quot; para seguir avanzando.</p>
<p><img decoding="async" loading="lazy" alt="Gr√°fica" src="/DevTacora/assets/images/mesetas-e7bb462a4e0e92c8d2757f28838ac1f8.png" width="800" height="600" class="img_ev3q"></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="actividad-de-seguimiento-jugando-en-el-laboratorio-de-neuronas">Actividad de Seguimiento: Jugando en el Laboratorio de Neuronas<a href="#actividad-de-seguimiento-jugando-en-el-laboratorio-de-neuronas" class="hash-link" aria-label="Enlace directo al Actividad de Seguimiento: Jugando en el Laboratorio de Neuronas" title="Enlace directo al Actividad de Seguimiento: Jugando en el Laboratorio de Neuronas">‚Äã</a></h2>
<p>Para entender c√≥mo interact√∫an todas las piezas que hemos estudiado, entra en <a href="https://playground.tensorflow.org/" target="_blank" rel="noopener noreferrer">TensorFlow Playground</a> y realiza el siguiente experimento guiado.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="el-objetivo">El Objetivo<a href="#el-objetivo" class="hash-link" aria-label="Enlace directo al El Objetivo" title="Enlace directo al El Objetivo">‚Äã</a></h3>
<p>Configurar una red neuronal capaz de clasificar el conjunto de datos <strong>&quot;Circular&quot;</strong> (el que tiene un c√≠rculo azul dentro de un anillo naranja) con el menor error posible.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="instrucciones-de-configuraci√≥n">Instrucciones de Configuraci√≥n<a href="#instrucciones-de-configuraci√≥n" class="hash-link" aria-label="Enlace directo al Instrucciones de Configuraci√≥n" title="Enlace directo al Instrucciones de Configuraci√≥n">‚Äã</a></h3>
<ol>
<li><strong>Datos</strong>: Selecciona el dataset circular (arriba a la izquierda).</li>
<li><strong>Arquitectura</strong>: Empieza con una red muy simple: <strong>1 capa oculta con 2 neuronas</strong>. Si no es suficiente, prueba con problemas m√°s complejos.</li>
<li><strong>El &quot;Pegamento&quot; (Activaci√≥n)</strong>: Cambia entre las diferentes.</li>
<li><strong>La Br√∫jula (Learning Rate)</strong>: Config√∫ralo en <strong>0.03</strong>. Ve cambiando el valor hasta conseguir que se separen correctamente los datos.</li>
</ol></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="P√°gina del documento"><a class="pagination-nav__link pagination-nav__link--prev" href="/DevTacora/docs/pia_2526/ut4_deep_learning/fundamentos/conceptos-teoricos-primera-red"><div class="pagination-nav__sublabel">Anterior</div><div class="pagination-nav__label">Conceptos te√≥ricos y primera red neuronal</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/DevTacora/docs/pia_2526/ut4_deep_learning/fundamentos/exportar-modelo"><div class="pagination-nav__sublabel">Siguiente</div><div class="pagination-nav__label">Exportaci√≥n de modelos</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#por-qu√©-necesitamos-funciones-de-activaci√≥n" class="table-of-contents__link toc-highlight">¬øPor qu√© necesitamos funciones de activaci√≥n?</a><ul><li><a href="#el-problema-de-la-linealidad" class="table-of-contents__link toc-highlight">El problema de la linealidad</a></li><li><a href="#introduciendo-la-no-linealidad" class="table-of-contents__link toc-highlight">Introduciendo la &quot;no linealidad&quot;</a></li></ul></li><li><a href="#cat√°logo-de-funciones-de-activaci√≥n-m√°s-comunes" class="table-of-contents__link toc-highlight">Cat√°logo de funciones de activaci√≥n m√°s comunes</a><ul><li><a href="#relu-rectified-linear-unit" class="table-of-contents__link toc-highlight">ReLU (Rectified Linear Unit)</a></li><li><a href="#sigmoide-sigmoid-" class="table-of-contents__link toc-highlight">Sigmoide (Sigmoid) üîó</a></li><li><a href="#tanh-tangente-hiperb√≥lica" class="table-of-contents__link toc-highlight">Tanh (Tangente hiperb√≥lica)</a></li><li><a href="#softmax" class="table-of-contents__link toc-highlight">Softmax</a></li><li><a href="#comparativa" class="table-of-contents__link toc-highlight">Comparativa</a></li></ul></li><li><a href="#c√≥mo-aprende-la-red-el-descenso-por-gradiente" class="table-of-contents__link toc-highlight">¬øC√≥mo aprende la red? El descenso por gradiente</a><ul><li><a href="#analog√≠a-del-arquero-qu√©-estamos-corrigiendo" class="table-of-contents__link toc-highlight">Analog√≠a del arquero: ¬øQu√© estamos corrigiendo?</a></li><li><a href="#la-analog√≠a-de-la-monta√±a-con-niebla" class="table-of-contents__link toc-highlight">La analog√≠a de la monta√±a con niebla</a></li><li><a href="#el-gradiente-como-br√∫jula" class="table-of-contents__link toc-highlight">El Gradiente como br√∫jula</a></li></ul></li><li><a href="#backpropagation-el-arte-de-repartir-culpas" class="table-of-contents__link toc-highlight">Backpropagation: El arte de repartir culpas</a><ul><li><a href="#el-flujo-de-la-informaci√≥n-forward-vs-backward" class="table-of-contents__link toc-highlight">El flujo de la informaci√≥n: Forward vs. Backward</a></li><li><a href="#qui√©n-tiene-m√°s-culpa" class="table-of-contents__link toc-highlight">¬øQui√©n tiene m√°s culpa?</a></li><li><a href="#experimentaci√≥n-pr√°ctica-google-colab" class="table-of-contents__link toc-highlight">Experimentaci√≥n Pr√°ctica: Google Colab</a></li></ul></li><li><a href="#optimizadores-el-ritmo-del-aprendizaje" class="table-of-contents__link toc-highlight">Optimizadores: El ritmo del aprendizaje</a><ul><li><a href="#por-qu√©-necesitamos-un-optimizador" class="table-of-contents__link toc-highlight">¬øPor qu√© necesitamos un optimizador?</a></li><li><a href="#tipos-comunes-de-optimizadores" class="table-of-contents__link toc-highlight">Tipos comunes de Optimizadores</a></li><li><a href="#laboratorio-comparativo-sgd-vs-adam" class="table-of-contents__link toc-highlight">Laboratorio Comparativo: SGD vs. Adam</a></li></ul></li><li><a href="#problemas-comunes-en-el-entrenamiento" class="table-of-contents__link toc-highlight">Problemas Comunes en el Entrenamiento</a><ul><li><a href="#gradientes-explosivos-y-desvanecientes" class="table-of-contents__link toc-highlight">Gradientes Explosivos y Desvanecientes</a></li><li><a href="#sobreajuste-overfitting" class="table-of-contents__link toc-highlight">Sobreajuste (Overfitting)</a></li><li><a href="#m√≠nimos-locales-y-mesetas-plateaus" class="table-of-contents__link toc-highlight">M√≠nimos Locales y Mesetas (Plateaus)</a></li></ul></li><li><a href="#actividad-de-seguimiento-jugando-en-el-laboratorio-de-neuronas" class="table-of-contents__link toc-highlight">Actividad de Seguimiento: Jugando en el Laboratorio de Neuronas</a><ul><li><a href="#el-objetivo" class="table-of-contents__link toc-highlight">El Objetivo</a></li><li><a href="#instrucciones-de-configuraci√≥n" class="table-of-contents__link toc-highlight">Instrucciones de Configuraci√≥n</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">
        <section classname="bg-white border-t border-gray-100">
      <div classname="max-w-4xl mx-auto px-6 py-16 text-center">
        <h3 classname="text-2xl font-bold text-gray-900 mb-4">
          Construyendo conocimiento, l√≠nea por l√≠nea
        </h3>
        <p classname="text-gray-600 leading-relaxed">
          ¬© 2026 Alicia C√°mara Casares - Contenido bajo licencia 
              <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer" classname="text-blue-600 hover:text-blue-700 underline">
                CC BY-NC-SA 4.0
              </a>.
        </p>
      </div>
    </section>
      </div></div></div></footer></div>
</body>
</html>