"use strict";(self.webpackChunkpmdm=self.webpackChunkpmdm||[]).push([[1927],{5821:(e,s,n)=>{n.d(s,{A:()=>r});const r=n.p+"assets/images/random-forest-sabiduria-09abdd3f25876d084e4f470c587ac0f2.png"},28453:(e,s,n)=>{n.d(s,{R:()=>a,x:()=>l});var r=n(96540);const i={},o=r.createContext(i);function a(e){const s=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function l(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(o.Provider,{value:s},e.children)}},44205:(e,s,n)=>{n.d(s,{A:()=>r});const r=n.p+"assets/images/random-forest-example-7b91fb0e2ce6193e556062d09f903c50.png"},78348:(e,s,n)=>{n.d(s,{A:()=>r});const r=n.p+"assets/files/ejemplo_random_forest_iris-b33ac2070353af4236f97c5c937f07a9.ipynb"},78550:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>d,contentTitle:()=>l,default:()=>m,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"pia_2526/ut3_ml/aprendizaje-supervisado/clasificacion/random-forest","title":"Random Forest","description":"Introducci\xf3n a Random Forest aplicado a problemas de clasificaci\xf3n. C\xf3mo funciona un bosque de \xe1rboles, por qu\xe9 mejora a un \xc1rbol de Decisi\xf3n individual, sus hiperpar\xe1metros principales y c\xf3mo entrenarlo y evaluarlo en Python utilizando el dataset Iris.","source":"@site/docs/01_pia_2526/ut3_ml/5-aprendizaje-supervisado/1-clasificacion/3-random-forest.md","sourceDirName":"01_pia_2526/ut3_ml/5-aprendizaje-supervisado/1-clasificacion","slug":"/pia_2526/ut3_ml/aprendizaje-supervisado/clasificacion/random-forest","permalink":"/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/clasificacion/random-forest","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Random Forest","sidebar_position":3,"toc_max_heading_level":5,"description":"Introducci\xf3n a Random Forest aplicado a problemas de clasificaci\xf3n. C\xf3mo funciona un bosque de \xe1rboles, por qu\xe9 mejora a un \xc1rbol de Decisi\xf3n individual, sus hiperpar\xe1metros principales y c\xf3mo entrenarlo y evaluarlo en Python utilizando el dataset Iris.","keywords":["Random Forest","Bagging","Ensamble","Clasificaci\xf3n","Machine Learning","scikit-learn","iris","\xe1rboles","hiperpar\xe1metros"]},"sidebar":"pia_2526_Sidebar","previous":{"title":"Decision Trees","permalink":"/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/clasificacion/arbol-decision"}}');var i=n(74848),o=n(28453);const a={title:"Random Forest",sidebar_position:3,toc_max_heading_level:5,description:"Introducci\xf3n a Random Forest aplicado a problemas de clasificaci\xf3n. C\xf3mo funciona un bosque de \xe1rboles, por qu\xe9 mejora a un \xc1rbol de Decisi\xf3n individual, sus hiperpar\xe1metros principales y c\xf3mo entrenarlo y evaluarlo en Python utilizando el dataset Iris.",keywords:["Random Forest","Bagging","Ensamble","Clasificaci\xf3n","Machine Learning","scikit-learn","iris","\xe1rboles","hiperpar\xe1metros"]},l=void 0,d={},c=[{value:"\xbfPor qu\xe9 surge Random Forest?",id:"por-qu\xe9-surge-random-forest",level:2},{value:"\xbfPor qu\xe9 usar Random Forest vs \xc1rboles de decisi\xf3n?",id:"por-qu\xe9-usar-random-forest-vs-\xe1rboles-de-decisi\xf3n",level:2},{value:"Funcionamiento del modelo",id:"funcionamiento-del-modelo",level:2},{value:"Bagging (Bootstrap Aggregation)",id:"bagging-bootstrap-aggregation",level:3},{value:"Sampling aleatorio de datos",id:"sampling-aleatorio-de-datos",level:3},{value:"Sampling aleatorio de features",id:"sampling-aleatorio-de-features",level:3},{value:"Votaci\xf3n del bosque: predicci\xf3n final",id:"votaci\xf3n-del-bosque-predicci\xf3n-final",level:3},{value:"Importancia del preprocesamiento en Random Forest",id:"importancia-del-preprocesamiento-en-random-forest",level:2},{value:"Ejemplo b\xe1sico en Python",id:"ejemplo-b\xe1sico-en-python",level:2},{value:"Visualizaci\xf3n de los \xe1rboles",id:"visualizaci\xf3n-de-los-\xe1rboles",level:2},{value:"Hiperpar\xe1metros principales",id:"hiperpar\xe1metros-principales",level:2},{value:"<code>n_estimators</code> \u2014 n\xfamero de \xe1rboles del bosque",id:"n_estimators--n\xfamero-de-\xe1rboles-del-bosque",level:3},{value:"<code>max_depth</code> \u2014 profundidad m\xe1xima de cada \xe1rbol",id:"max_depth--profundidad-m\xe1xima-de-cada-\xe1rbol",level:3},{value:"<code>min_samples_leaf</code> \u2014 muestras m\xednimas en cada hoja",id:"min_samples_leaf--muestras-m\xednimas-en-cada-hoja",level:3},{value:"<code>max_features</code> \u2014 n\xfamero de columnas que cada \xe1rbol puede usar",id:"max_features--n\xfamero-de-columnas-que-cada-\xe1rbol-puede-usar",level:3},{value:"\xbfC\xf3mo saber si hay overfitting o underfitting?",id:"c\xf3mo-saber-si-hay-overfitting-o-underfitting",level:3},{value:"Ejemplo con ajuste de hiperpar\xe1metros",id:"ejemplo-con-ajuste-de-hiperpar\xe1metros",level:2},{value:"M\xe9tricas de evaluaci\xf3n",id:"m\xe9tricas-de-evaluaci\xf3n",level:2},{value:"An\xe1lisis de importancia",id:"an\xe1lisis-de-importancia",level:2},{value:"Automatizaci\xf3n b\xfasqueda de hiperpar\xe1metros (GridSearchCV)",id:"automatizaci\xf3n-b\xfasqueda-de-hiperpar\xe1metros-gridsearchcv",level:2},{value:"Ejemplo de diccionario de hiperpar\xe1metros",id:"ejemplo-de-diccionario-de-hiperpar\xe1metros",level:3},{value:"Ejecutar GridSearchCV con Random Forest",id:"ejecutar-gridsearchcv-con-random-forest",level:3},{value:"Actividad de seguimiento: Titanic",id:"actividad-de-seguimiento-titanic",level:2}];function t(e){const s={a:"a",admonition:"admonition",blockquote:"blockquote",br:"br",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)("div",{class:"justify-text",children:[(0,i.jsxs)(s.p,{children:["Los ",(0,i.jsx)(s.strong,{children:"Random Forest"})," (Bosques Aleatorios) son una mejora directa de los \xc1rboles de Decisi\xf3n.\nEn lugar de entrenar ",(0,i.jsx)(s.strong,{children:"un solo \xe1rbol"}),", que puede ser inestable y propenso al sobreajuste, Random Forest crea ",(0,i.jsx)(s.strong,{children:"muchos \xe1rboles diferentes"})," y combina sus predicciones mediante ",(0,i.jsx)(s.strong,{children:"votaci\xf3n"}),"."]}),(0,i.jsx)(s.p,{children:"La idea es sencilla pero muy poderosa:"}),(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Un grupo de modelos simples y diversos suele predecir mejor que un \xfanico modelo complejo."})}),"\n"]}),(0,i.jsxs)(s.p,{children:["Este principio se conoce como ",(0,i.jsx)(s.strong,{children:"sabidur\xeda de la multitud"}),": cuando muchas \u201copiniones\u201d independientes se combinan, los errores individuales se compensan y la predicci\xf3n final es m\xe1s estable."]}),(0,i.jsxs)(s.admonition,{title:"Video recomendado",type:"tip",children:[(0,i.jsx)(s.p,{children:"Si quieres una explicaci\xf3n muy clara e intuitiva de c\xf3mo funciona Random Forest, te recomiendo este v\xeddeo:"}),(0,i.jsxs)(s.p,{children:["\ud83d\udc49 ",(0,i.jsx)(s.a,{href:"https://www.youtube.com/watch?v=v6VJ2RO66Ag",children:"C\xf3mo funciona Random Forest (YouTube)"})]}),(0,i.jsx)(s.p,{children:"En menos de 10 minutos muestra visualmente la idea de los \xe1rboles aleatorios, el bagging y la votaci\xf3n del bosque."})]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"por-qu\xe9-surge-random-forest",children:"\xbfPor qu\xe9 surge Random Forest?"}),(0,i.jsx)(s.p,{children:"Los \xc1rboles de Decisi\xf3n tienen muchas ventajas (interpretabilidad, facilidad de uso\u2026), pero tambi\xe9n un problema importante:"}),(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Si los dejas crecer sin l\xedmites, tienden a sobreajustar los datos."})}),"\n"]}),(0,i.jsx)(s.p,{children:"Un \xfanico \xe1rbol aprende reglas demasiado espec\xedficas, se vuelve muy sensible a peque\xf1as variaciones y generaliza mal. Random Forest aparece como soluci\xf3n:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["crea muchos \xe1rboles ",(0,i.jsx)(s.strong,{children:"distintos"})]}),"\n",(0,i.jsx)(s.li,{children:"cada uno ve una parte diferente de los datos"}),"\n",(0,i.jsx)(s.li,{children:"cada \xe1rbol tambi\xe9n usa un subconjunto aleatorio de caracter\xedsticas"}),"\n",(0,i.jsx)(s.li,{children:"despu\xe9s, todos los \xe1rboles votan la clase final"}),"\n"]}),(0,i.jsxs)(s.p,{children:["El resultado:",(0,i.jsx)(s.br,{}),"\n","\u2714 menos sobreajuste",(0,i.jsx)(s.br,{}),"\n","\u2714 modelo m\xe1s estable",(0,i.jsx)(s.br,{}),"\n","\u2714 mejores predicciones en datos nuevos"]}),(0,i.jsxs)(s.p,{children:["Los Random Forest se basan en el concepto de ",(0,i.jsx)(s.strong,{children:"sabidur\xeda de la multitud"}),":"]}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{alt:"Random Forest",src:n(5821).A+"",width:"3338",height:"1876"})}),(0,i.jsx)(s.p,{children:"Imagina que un \xc1rbol de Decisi\xf3n es una persona haciendo una predicci\xf3n."}),(0,i.jsxs)(s.p,{children:["Si solo preguntas a una persona, puede equivocarse.",(0,i.jsx)(s.br,{}),"\n","Pero si preguntas a ",(0,i.jsx)(s.strong,{children:"100 personas independientes"})," y haces una votaci\xf3n:"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"los errores se compensan"}),"\n",(0,i.jsx)(s.li,{children:"la predicci\xf3n final suele ser muy acertada"}),"\n"]}),(0,i.jsxs)(s.p,{children:["Random Forest funciona igual:\n",(0,i.jsx)(s.strong,{children:"cada \xe1rbol es un \u201cvotante\u201d"}),", y la predicci\xf3n final es la decisi\xf3n mayoritaria."]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"por-qu\xe9-usar-random-forest-vs-\xe1rboles-de-decisi\xf3n",children:"\xbfPor qu\xe9 usar Random Forest vs \xc1rboles de decisi\xf3n?"}),(0,i.jsx)(s.p,{children:"Random Forest supera a un \xc1rbol de Decisi\xf3n individual en casi todos los aspectos importantes:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"M\xe1s robusto"}),(0,i.jsx)(s.br,{}),"\n","Peque\xf1os cambios en los datos no afectan tanto.",(0,i.jsx)(s.br,{}),"\n","Cada \xe1rbol ve una versi\xf3n diferente del dataset, as\xed que el modelo final es estable."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Menos sobreajuste"}),(0,i.jsx)(s.br,{}),"\n","Promediar muchos \xe1rboles reduce la varianza del modelo.",(0,i.jsx)(s.br,{}),"\n","Es decir, ",(0,i.jsx)(s.strong,{children:"memorizan menos y generalizan mejor"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Mejor rendimiento en general"}),(0,i.jsx)(s.br,{}),"\n","En la mayor\xeda de datasets, Random Forest obtiene:"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"mayor accuracy"}),"\n",(0,i.jsx)(s.li,{children:"menor error"}),"\n",(0,i.jsx)(s.li,{children:"mejores predicciones en test"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Combina varios modelos d\xe9biles en un modelo fuerte"}),(0,i.jsx)(s.br,{}),"\n","Cada \xe1rbol es simple y puede cometer errores.",(0,i.jsx)(s.br,{}),"\n","Pero juntos \u2014gracias al m\xe9todo de ",(0,i.jsx)(s.em,{children:"bagging"}),"\u2014 forman un modelo m\xe1s potente y preciso."]}),"\n"]}),"\n"]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"funcionamiento-del-modelo",children:"Funcionamiento del modelo"}),(0,i.jsxs)(s.p,{children:["Random Forest no es un modelo misterioso:\nes simplemente un conjunto de ",(0,i.jsx)(s.strong,{children:"muchos \xc1rboles de Decisi\xf3n"}),", entrenados de manera inteligente para que sean ",(0,i.jsx)(s.strong,{children:"diferentes entre s\xed"})," y, al combinarlos, formen un modelo final m\xe1s robusto."]}),(0,i.jsxs)(s.p,{children:["La clave est\xe1 en dos ideas:\n",(0,i.jsx)(s.strong,{children:"bagging"})," y ",(0,i.jsx)(s.strong,{children:"aleatoriedad"}),"."]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h3,{id:"bagging-bootstrap-aggregation",children:"Bagging (Bootstrap Aggregation)"}),(0,i.jsxs)(s.p,{children:["El primer ingrediente de Random Forest es el ",(0,i.jsx)(s.strong,{children:"bagging"}),", una t\xe9cnica cuyo objetivo es ",(0,i.jsx)(s.strong,{children:"reducir la varianza"})," del modelo."]}),(0,i.jsx)(s.p,{children:"El proceso es:"}),(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["Se crea un ",(0,i.jsx)(s.strong,{children:"subconjunto de datos"})," tomando muestras ",(0,i.jsx)(s.em,{children:"con reemplazo"})," (bootstrap)."]}),"\n",(0,i.jsx)(s.li,{children:"Con ese subconjunto, se entrena un \xe1rbol."}),"\n",(0,i.jsx)(s.li,{children:"Se repite el proceso muchas veces."}),"\n",(0,i.jsx)(s.li,{children:"Cada \xe1rbol aprende cosas ligeramente diferentes."}),"\n",(0,i.jsx)(s.li,{children:"Al final, todas las predicciones se combinan (votaci\xf3n)."}),"\n"]}),(0,i.jsxs)(s.p,{children:["Esto hace que cada \xe1rbol sea imperfecto en una forma distinta, pero ",(0,i.jsx)(s.strong,{children:"la combinaci\xf3n final sea muy estable"}),"."]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h3,{id:"sampling-aleatorio-de-datos",children:"Sampling aleatorio de datos"}),(0,i.jsx)(s.p,{children:"Para cada \xe1rbol del bosque:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"El modelo elige de forma aleatoria un subconjunto de observaciones del dataset original."}),"\n",(0,i.jsxs)(s.li,{children:["Como es sampling ",(0,i.jsx)(s.em,{children:"con reemplazo"}),", algunas observaciones se repiten y otras no aparecen en ese \xe1rbol."]}),"\n"]}),(0,i.jsx)(s.p,{children:"Resultado:"}),(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Cada \xe1rbol ve una versi\xf3n diferente del dataset"}),", lo que introduce diversidad en el bosque."]}),"\n"]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h3,{id:"sampling-aleatorio-de-features",children:"Sampling aleatorio de features"}),(0,i.jsxs)(s.p,{children:["Adem\xe1s de elegir datos distintos, Random Forest tambi\xe9n elige ",(0,i.jsx)(s.strong,{children:"features distintas"})," en cada split de cada \xe1rbol."]}),(0,i.jsx)(s.p,{children:"Por ejemplo:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["Un \xe1rbol puede basarse en ",(0,i.jsx)(s.em,{children:"petal_length"})," y ",(0,i.jsx)(s.em,{children:"sepal_width"})]}),"\n",(0,i.jsxs)(s.li,{children:["Otro puede usar ",(0,i.jsx)(s.em,{children:"petal_width"})," y ",(0,i.jsx)(s.em,{children:"sepal_length"})]}),"\n",(0,i.jsxs)(s.li,{children:["Otro puede ignorar completamente ",(0,i.jsx)(s.em,{children:"sepal_width"})]}),"\n"]}),(0,i.jsx)(s.p,{children:"Esta aleatoriedad adicional es fundamental:"}),(0,i.jsxs)(s.p,{children:["\u2714 evita que todos los \xe1rboles aprendan lo mismo",(0,i.jsx)(s.br,{}),"\n","\u2714 fuerza a que los \xe1rboles busquen caminos alternativos",(0,i.jsx)(s.br,{}),"\n","\u2714 mejora la generalizaci\xf3n del modelo"]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Cada \xe1rbol ve un mundo diferente"}),", combinando:"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"bootstrap (datos diferentes)"}),"\n",(0,i.jsx)(s.li,{children:"selecci\xf3n aleatoria de columnas (features diferentes)"}),"\n"]}),(0,i.jsxs)(s.p,{children:["se consigue que ",(0,i.jsx)(s.strong,{children:"cada \xe1rbol tenga su propia perspectiva"})," sobre el problema."]}),(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:"Ning\xfan \xe1rbol es perfecto, pero sus errores NO son los mismos.\nEsto permite que la votaci\xf3n final sea mucho m\xe1s precisa."}),"\n"]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h3,{id:"votaci\xf3n-del-bosque-predicci\xf3n-final",children:"Votaci\xf3n del bosque: predicci\xf3n final"}),(0,i.jsx)(s.p,{children:"Una vez entrenados todos los \xe1rboles:"}),(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsx)(s.li,{children:"Cada \xe1rbol hace su predicci\xf3n de forma independiente."}),"\n",(0,i.jsxs)(s.li,{children:["En clasificaci\xf3n, se utiliza ",(0,i.jsx)(s.strong,{children:"votaci\xf3n mayoritaria"}),":\n\u2192 la clase m\xe1s votada por todos los \xe1rboles es la predicci\xf3n final."]}),"\n",(0,i.jsxs)(s.li,{children:["En regresi\xf3n, se utiliza la ",(0,i.jsx)(s.strong,{children:"media"})," de las predicciones."]}),"\n"]}),(0,i.jsx)(s.p,{children:"Esta combinaci\xf3n final es el coraz\xf3n del Random Forest:"}),(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"promediar varios modelos d\xe9biles produce un modelo fuerte, estable y dif\xedcil de sobreajustar."})}),"\n"]}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{alt:"Random Forest",src:n(94940).A+"",width:"833",height:"448"})}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"importancia-del-preprocesamiento-en-random-forest",children:"Importancia del preprocesamiento en Random Forest"}),(0,i.jsxs)(s.p,{children:["Aunque Random Forest es uno de los modelos ",(0,i.jsx)(s.strong,{children:"menos exigentes"})," en preprocesamiento, conviene recordar algunas reglas b\xe1sicas para evitar errores y garantizar un buen rendimiento."]}),(0,i.jsx)("div",{class:"texto-sin-justificar",children:(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:"Aspecto"}),(0,i.jsx)(s.th,{children:"\xbfEs necesario?"}),(0,i.jsx)(s.th,{children:"Explicaci\xf3n"})]})}),(0,i.jsxs)(s.tbody,{children:[(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"Escalado (StandardScaler / MinMax)"})}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"\u274c No"})}),(0,i.jsx)(s.td,{children:"Igual que los \xe1rboles individuales, Random Forest solo compara valores del tipo \u201c\xbffeature \u2264 umbral?\u201d, as\xed que las escalas no afectan al modelo."})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"Codificaci\xf3n de categ\xf3ricas"})}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"\u2714 S\xed"})}),(0,i.jsxs)(s.td,{children:["El modelo solo acepta n\xfameros. Puedes usar ",(0,i.jsx)(s.strong,{children:"Label Encoding o One-Hot"}),", ambas funcionan porque el \xe1rbol no interpreta orden."]})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"Tratamiento de outliers"})}),(0,i.jsxs)(s.td,{children:[(0,i.jsx)(s.strong,{children:"\u2714 Opcional"})," (recomendado si son extremos)"]}),(0,i.jsx)(s.td,{children:"Random Forest es robusto a ruido, pero outliers muy extremos pueden influir en splits poco \xf3ptimos en algunos \xe1rboles. No es tan cr\xedtico como en KNN, SVM o regresi\xf3n."})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"Eliminaci\xf3n de nulos"})}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"\u2714 S\xed"})}),(0,i.jsx)(s.td,{children:"Random Forest no admite valores nulos. Deben rellenarse (mean/median/mode) o eliminarse filas."})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"Eliminaci\xf3n de features irrelevantes"})}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"\u2714 Recomendado"})}),(0,i.jsx)(s.td,{children:"Un exceso de features irrelevantes hace que los \xe1rboles prueben divisiones menos \xfatiles. No es grave, pero puede empeorar la precisi\xf3n."})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"One-Hot vs Label Encoding"})}),(0,i.jsx)(s.td,{children:(0,i.jsx)(s.strong,{children:"\u2714 Cualquiera"})}),(0,i.jsx)(s.td,{children:"A diferencia de KNN, la elecci\xf3n no cambia el significado para el modelo. Label Encoding funciona bien incluso sin orden real."})]})]})]})}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"ejemplo-b\xe1sico-en-python",children:"Ejemplo b\xe1sico en Python"}),(0,i.jsxs)(s.p,{children:["Para ver c\xf3mo funciona un ",(0,i.jsx)(s.strong,{children:"Random Forest"})," en la pr\xe1ctica, puedes ejecutar este ejemplo sencillo utilizando el dataset ",(0,i.jsx)(s.strong,{children:"Iris"}),".\nEntrenaremos un Random Forest ",(0,i.jsx)(s.strong,{children:"sin ajustar hiperpar\xe1metros"}),"."]}),(0,i.jsxs)(s.p,{children:["\ud83d\udc49 ",(0,i.jsx)(s.strong,{children:"Puedes abrir el cuaderno aqu\xed:"}),"\n",(0,i.jsx)(s.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:n(78348).A+"",children:"Colab: Random Forest con Iris"})]}),(0,i.jsxs)(s.p,{children:["\ud83d\udc49 ",(0,i.jsx)(s.strong,{children:"Dataset utilizado:"}),"\n",(0,i.jsx)(s.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:n(97087).A+"",children:"iris.csv"})]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"visualizaci\xf3n-de-los-\xe1rboles",children:"Visualizaci\xf3n de los \xe1rboles"}),(0,i.jsxs)(s.p,{children:["En un Random Forest se entrenan ",(0,i.jsx)(s.strong,{children:"decenas o cientos de \xe1rboles"}),", cada uno ligeramente distinto gracias al ",(0,i.jsx)(s.em,{children:"bootstrap"})," y a la selecci\xf3n aleatoria de features."]}),(0,i.jsx)(s.p,{children:"Por ello:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"No tiene sentido visualizar todo el bosque"})," \u2192 ser\xeda imposible de interpretar."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"S\xed es \xfatil visualizar un par de \xe1rboles individuales"})," para ver c\xf3mo cada uno aprende reglas diferentes."]}),"\n"]}),(0,i.jsx)(s.p,{children:"Esto ayuda a entender que:"}),(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"El bosque no depende de un \xfanico \xe1rbol, sino de la votaci\xf3n de muchos modelos diversos."})}),"\n"]}),(0,i.jsx)(s.p,{children:"Si quieres, puedes mostrar solo los primeros \xe1rboles:"}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-python",children:'# Importamos las librer\xedas necesarias\nimport matplotlib.pyplot as plt\nfrom sklearn import tree\n\n# Creamos una figura con 3 subplots (uno por cada \xe1rbol)\nplt.figure(figsize=(30, 15))\n\n# Recorremos los primeros 3 \xe1rboles del Random Forest\nfor i in range(3):\n    # Seleccionamos el subplot en la posici\xf3n i+1\n    plt.subplot(1, 3, i + 1)\n    \n    # Dibujamos el \xe1rbol n\xfamero i dentro del bosque\n    tree.plot_tree(\n        rf.estimators_[i],      # \xc1rbol individual dentro de Random Forest\n        feature_names=X.columns,  # Nombres de las columnas para legibilidad\n        filled=True,              # Colorear nodos seg\xfan clase predominante\n        max_depth=3               # Limitar profundidad para que el \xe1rbol no sea gigantesco\n    )\n    \n    # T\xedtulo para identificar qu\xe9 \xe1rbol estamos viendo\n    plt.title(f"\xc1rbol {i}")\n\n# Mostramos todos los gr\xe1ficos\nplt.show()\n'})}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{alt:"Random Forest",src:n(44205).A+"",width:"2345",height:"1197"})}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"hiperpar\xe1metros-principales",children:"Hiperpar\xe1metros principales"}),(0,i.jsx)(s.p,{children:"Despu\xe9s de ver el funcionamiento b\xe1sico del Random Forest, es importante entender c\xf3mo podemos controlar su comportamiento para evitar sobreajuste, mejorar la estabilidad del modelo y ajustar su rendimiento."}),(0,i.jsxs)(s.p,{children:["En un Random Forest, los hiperpar\xe1metros ya no controlan ",(0,i.jsx)(s.strong,{children:"un \xfanico \xe1rbol"}),", sino ",(0,i.jsx)(s.strong,{children:"c\xf3mo se comportan todos los \xe1rboles del bosque"}),".\nLos m\xe1s importantes son los que permiten regular:"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"cu\xe1ntos \xe1rboles se entrenan"}),"\n",(0,i.jsx)(s.li,{children:"cu\xe1n complejos pueden ser esos \xe1rboles"}),"\n",(0,i.jsx)(s.li,{children:"cu\xe1nta aleatoriedad a\xf1adimos"}),"\n",(0,i.jsx)(s.li,{children:"cu\xe1n homog\xe9neas deben ser las hojas del bosque"}),"\n"]}),(0,i.jsx)(s.hr,{}),(0,i.jsxs)(s.h3,{id:"n_estimators--n\xfamero-de-\xe1rboles-del-bosque",children:[(0,i.jsx)(s.code,{children:"n_estimators"})," \u2014 n\xfamero de \xe1rboles del bosque"]}),(0,i.jsx)(s.p,{children:"Es uno de los hiperpar\xe1metros clave del modelo."}),(0,i.jsxs)(s.p,{children:["Indica ",(0,i.jsx)(s.strong,{children:"cu\xe1ntos \xe1rboles individuales"})," va a entrenar el Random Forest."]}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Idea intuitiva:"})}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"M\xe1s \xe1rboles \u2192 modelo m\xe1s estable"}),"\n",(0,i.jsx)(s.li,{children:"Menos \xe1rboles \u2192 modelo m\xe1s r\xe1pido, pero menos robusto"}),"\n",(0,i.jsx)(s.li,{children:"No existe riesgo real de sobreajuste por poner demasiados \xe1rboles"}),"\n"]}),(0,i.jsx)(s.p,{children:"Ejemplo:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"n_estimators=10"})," \u2192 bosque muy peque\xf1o, poco estable"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"n_estimators=100"})," \u2192 valor t\xedpico"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:"n_estimators=300"})," \u2192 excelente estabilidad en la mayor\xeda de casos"]}),"\n"]}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Regla pr\xe1ctica:"})}),(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:"\u201cPon m\xe1s \xe1rboles si quieres un modelo m\xe1s estable. El \xfanico coste es el tiempo de entrenamiento.\u201d"}),"\n"]}),(0,i.jsx)(s.hr,{}),(0,i.jsxs)(s.h3,{id:"max_depth--profundidad-m\xe1xima-de-cada-\xe1rbol",children:[(0,i.jsx)(s.code,{children:"max_depth"})," \u2014 profundidad m\xe1xima de cada \xe1rbol"]}),(0,i.jsx)(s.p,{children:"Este hiperpar\xe1metro funciona de manera casi id\xe9ntica a como lo viste en \xc1rbol de Decisi\xf3n."}),(0,i.jsxs)(s.p,{children:["Controla ",(0,i.jsx)(s.strong,{children:"cu\xe1n profundos"})," pueden ser los \xe1rboles del bosque."]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\xc1rboles muy profundos \u2192 riesgo de ",(0,i.jsx)(s.em,{children:"overfitting"})," individual"]}),"\n",(0,i.jsxs)(s.li,{children:["\xc1rboles muy poco profundos \u2192 bosque demasiado simple (",(0,i.jsx)(s.em,{children:"underfitting"}),")"]}),"\n",(0,i.jsx)(s.li,{children:"Lo normal es permitir \xe1rboles relativamente profundos, pero no infinitos"}),"\n"]}),(0,i.jsxs)(s.p,{children:["En Random Forest, incluso con \xe1rboles profundos, el modelo ",(0,i.jsx)(s.strong,{children:"no sobreajusta tanto"})," gracias a la aleatoriedad del bosque.\nA\xfan as\xed, limitar la profundidad suele mejorar la generalizaci\xf3n."]}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Regla pr\xe1ctica:"})}),(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:"\u201cPara datasets peque\xf1os como Iris, profundidades entre 4 y 6 funcionan muy bien.\u201d"}),"\n"]}),(0,i.jsx)(s.hr,{}),(0,i.jsxs)(s.h3,{id:"min_samples_leaf--muestras-m\xednimas-en-cada-hoja",children:[(0,i.jsx)(s.code,{children:"min_samples_leaf"})," \u2014 muestras m\xednimas en cada hoja"]}),(0,i.jsxs)(s.p,{children:["Indica el ",(0,i.jsx)(s.strong,{children:"n\xfamero m\xednimo de observaciones"})," que debe contener una hoja del \xe1rbol."]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Valores muy peque\xf1os (1\u20132) \u2192 \xe1rboles muy espec\xedficos"}),"\n",(0,i.jsx)(s.li,{children:"Valores m\xe1s altos \u2192 reglas m\xe1s estables y menos sensibles al ruido"}),"\n"]}),(0,i.jsxs)(s.p,{children:["Es uno de los hiperpar\xe1metros m\xe1s importantes para ",(0,i.jsx)(s.strong,{children:"suavizar"})," un Random Forest."]}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Regla pr\xe1ctica:"})}),(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsx)(s.p,{children:"\u201cValores 1\u20132 funcionan bien para datasets peque\xf1os. Para datasets ruidosos, usa 3\u20135.\u201d"}),"\n"]}),(0,i.jsx)(s.hr,{}),(0,i.jsxs)(s.h3,{id:"max_features--n\xfamero-de-columnas-que-cada-\xe1rbol-puede-usar",children:[(0,i.jsx)(s.code,{children:"max_features"})," \u2014 n\xfamero de columnas que cada \xe1rbol puede usar"]}),(0,i.jsxs)(s.p,{children:["Este hiperpar\xe1metro es ",(0,i.jsx)(s.strong,{children:"la clave que diferencia un Bagging normal de un Random Forest"}),"."]}),(0,i.jsxs)(s.p,{children:["Determina cu\xe1ntas ",(0,i.jsx)(s.strong,{children:"features"})," puede usar cada \xe1rbol en ",(0,i.jsx)(s.strong,{children:"cada divisi\xf3n del \xe1rbol"}),":"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["Valores bajos \u2192 \xe1rboles m\xe1s distintos entre s\xed \u2192 m\xe1s diversidad \u2192 ",(0,i.jsx)(s.strong,{children:"menos sobreajuste"})]}),"\n",(0,i.jsxs)(s.li,{children:["Valores altos \u2192 \xe1rboles m\xe1s parecidos \u2192 ",(0,i.jsx)(s.strong,{children:"m\xe1s riesgo de sobreajuste"})]}),"\n"]}),(0,i.jsx)(s.p,{children:"Valores t\xedpicos:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:'"sqrt"'})," \u2192 usa la ra\xedz cuadrada del n\xfamero de features"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.code,{children:'"log2"'})," \u2192 usa el logaritmo"]}),"\n",(0,i.jsxs)(s.li,{children:["o elegir un n\xfamero fijo (",(0,i.jsx)(s.code,{children:"1"}),", ",(0,i.jsx)(s.code,{children:"2"}),", ",(0,i.jsx)(s.code,{children:"3"}),")"]}),"\n"]}),(0,i.jsxs)(s.p,{children:["Para Iris (4 features), ",(0,i.jsx)(s.code,{children:'"sqrt"'})," equivale a 2 columnas por split \u2192 suele ir muy bien."]}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Regla pr\xe1ctica:"})}),(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsxs)(s.p,{children:["\u201c",(0,i.jsx)(s.code,{children:'max_features="sqrt"'})," es el valor est\xe1ndar y suele funcionar de maravilla.\u201d"]}),"\n"]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h3,{id:"c\xf3mo-saber-si-hay-overfitting-o-underfitting",children:"\xbfC\xf3mo saber si hay overfitting o underfitting?"}),(0,i.jsxs)(s.p,{children:["Al igual que en \xc1rbol de Decisi\xf3n, la forma m\xe1s sencilla de detectar si un Random Forest est\xe1 sobreajustando o infraajustando es comparar la ",(0,i.jsx)(s.strong,{children:"accuracy en train"})," con la ",(0,i.jsx)(s.strong,{children:"accuracy en test"}),"."]}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"OVERFITTING (sobreajuste)"})}),(0,i.jsx)(s.p,{children:"El modelo aprende demasiado bien el entrenamiento y generaliza peor."}),(0,i.jsx)(s.p,{children:"Se\xf1ales:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["Accuracy ",(0,i.jsx)(s.strong,{children:"muy alta en train"})," (a veces 1.00)"]}),"\n",(0,i.jsxs)(s.li,{children:["Accuracy ",(0,i.jsx)(s.strong,{children:"claramente m\xe1s baja en test"})]}),"\n"]}),(0,i.jsx)(s.p,{children:"Ejemplo t\xedpico:"}),(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:"Conjunto"}),(0,i.jsx)(s.th,{children:"Accuracy"})]})}),(0,i.jsxs)(s.tbody,{children:[(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Train"}),(0,i.jsx)(s.td,{children:"1.00"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Test"}),(0,i.jsx)(s.td,{children:"0.90"})]})]})]}),(0,i.jsx)(s.p,{children:"Interpretaci\xf3n:\nLos \xe1rboles del bosque son demasiado complejos. Aunque el Random Forest reduce el sobreajuste respecto a un solo \xe1rbol, todav\xeda puede memorizar parte de los datos."}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"UNDERFITTING (subajuste)"})}),(0,i.jsx)(s.p,{children:"El modelo es demasiado simple."}),(0,i.jsx)(s.p,{children:"Se\xf1ales:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["Accuracy ",(0,i.jsx)(s.strong,{children:"baja en train"})]}),"\n",(0,i.jsxs)(s.li,{children:["Accuracy ",(0,i.jsx)(s.strong,{children:"similarmente baja en test"})]}),"\n"]}),(0,i.jsx)(s.p,{children:"Ejemplo:"}),(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:"Conjunto"}),(0,i.jsx)(s.th,{children:"Accuracy"})]})}),(0,i.jsxs)(s.tbody,{children:[(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Train"}),(0,i.jsx)(s.td,{children:"0.80"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Test"}),(0,i.jsx)(s.td,{children:"0.78"})]})]})]}),(0,i.jsxs)(s.p,{children:["Interpretaci\xf3n:\nEl bosque es peque\xf1o (",(0,i.jsx)(s.code,{children:"n_estimators"})," muy bajo) o los \xe1rboles son demasiado poco profundos."]}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Buen ajuste"})}),(0,i.jsx)(s.p,{children:"Lo ideal:"}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["train y test ",(0,i.jsx)(s.strong,{children:"parecidos"})]}),"\n",(0,i.jsxs)(s.li,{children:["ambos valores ",(0,i.jsx)(s.strong,{children:"altos"})]}),"\n"]}),(0,i.jsx)(s.p,{children:"Ejemplo:"}),(0,i.jsxs)(s.table,{children:[(0,i.jsx)(s.thead,{children:(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.th,{children:"Conjunto"}),(0,i.jsx)(s.th,{children:"Accuracy"})]})}),(0,i.jsxs)(s.tbody,{children:[(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Train"}),(0,i.jsx)(s.td,{children:"0.97"})]}),(0,i.jsxs)(s.tr,{children:[(0,i.jsx)(s.td,{children:"Test"}),(0,i.jsx)(s.td,{children:"0.95"})]})]})]}),(0,i.jsx)(s.p,{children:"Interpretaci\xf3n:\nEl modelo es estable, generaliza bien y no memoriza en exceso.\nEsto es lo habitual en Random Forest bien configurado."}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"C\xf3digo para comprobarlo"})}),(0,i.jsx)(s.p,{children:"Exactamente lo mismo que estudiamos para los \xe1rboles de decisi\xf3n:"}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-python",children:'# Accuracy en entrenamiento y en test\nprint("Accuracy TRAIN:", rf.score(X_train, y_train))\nprint("Accuracy TEST :", rf.score(X_test, y_test))\n'})}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"ejemplo-con-ajuste-de-hiperpar\xe1metros",children:"Ejemplo con ajuste de hiperpar\xe1metros"}),(0,i.jsxs)(s.p,{children:["En este segundo ejemplo trabajaremos con el mismo ",(0,i.jsx)(s.strong,{children:"Google Colab"})," y el mismo ",(0,i.jsx)(s.strong,{children:"dataset Iris"})," utilizados en el ejemplo b\xe1sico.\nEl objetivo ahora es observar c\xf3mo los hiperpar\xe1metros m\xe1s importantes de un Random Forest (",(0,i.jsx)(s.code,{children:"n_estimators"}),", ",(0,i.jsx)(s.code,{children:"max_depth"}),", ",(0,i.jsx)(s.code,{children:"min_samples_leaf"}),", ",(0,i.jsx)(s.code,{children:"max_features"}),") influyen en el rendimiento del modelo."]}),(0,i.jsxs)(s.p,{children:["En el Colab encontrar\xe1s un apartado espec\xedfico llamado ",(0,i.jsx)(s.strong,{children:"\u201cAjuste de hiperpar\xe1metros\u201d"}),"."]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"m\xe9tricas-de-evaluaci\xf3n",children:"M\xe9tricas de evaluaci\xf3n"}),(0,i.jsxs)(s.p,{children:["Las m\xe9tricas que utilizamos para evaluar un Random Forest son ",(0,i.jsx)(s.strong,{children:"exactamente las mismas"})," que ya estudiamos en \xc1rbol de Decisi\xf3n y en KNN:"]}),(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.strong,{children:"Accuracy"})}),"\n",(0,i.jsx)(s.li,{children:(0,i.jsx)(s.strong,{children:"Matriz de confusi\xf3n"})}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Precision, Recall y F1-score"})," (classification_report)"]}),"\n"]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"an\xe1lisis-de-importancia",children:"An\xe1lisis de importancia"}),(0,i.jsxs)(s.p,{children:["Igual que con los \xc1rboles de Decisi\xf3n, un Random Forest permite obtener la ",(0,i.jsx)(s.strong,{children:"importancia de cada variable"})," mediante el atributo:"]}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-python",children:"rf_tuned.feature_importances_\n"})}),(0,i.jsx)(s.p,{children:"La idea y la interpretaci\xf3n son exactamente las mismas que ya estudiamos."}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"automatizaci\xf3n-b\xfasqueda-de-hiperpar\xe1metros-gridsearchcv",children:"Automatizaci\xf3n b\xfasqueda de hiperpar\xe1metros (GridSearchCV)"}),(0,i.jsxs)(s.p,{children:["Igual que en el \xc1rbol de Decisi\xf3n, podemos utilizar ",(0,i.jsx)(s.strong,{children:"GridSearchCV"})," para encontrar la mejor combinaci\xf3n de hiperpar\xe1metros de un ",(0,i.jsx)(s.strong,{children:"Random Forest"}),".\nEl funcionamiento es el mismo: GridSearchCV prueba todas las combinaciones posibles del diccionario de par\xe1metros y selecciona la que obtiene mejor rendimiento mediante validaci\xf3n cruzada."]}),(0,i.jsxs)(s.p,{children:["La \xfanica diferencia es que en Random Forest los hiperpar\xe1metros que ajustamos suelen ser otros (como ",(0,i.jsx)(s.code,{children:"n_estimators"}),", ",(0,i.jsx)(s.code,{children:"max_depth"}),", ",(0,i.jsx)(s.code,{children:"max_features"})," o ",(0,i.jsx)(s.code,{children:"min_samples_leaf"}),")."]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h3,{id:"ejemplo-de-diccionario-de-hiperpar\xe1metros",children:"Ejemplo de diccionario de hiperpar\xe1metros"}),(0,i.jsx)(s.p,{children:"Ajustamos solo los hiperpar\xe1metros m\xe1s importantes:"}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-python",children:'param_grid = {\n    "n_estimators": [100, 200, 300],   # n\xba de \xe1rboles\n    "max_depth": [3, 4, 5, None],      # profundidad m\xe1xima\n    "min_samples_leaf": [1, 2, 3],     # hojas m\xednimas\n    "max_features": [1, 2, "sqrt"]     # n\xba de columnas usadas en cada split\n}\n'})}),(0,i.jsxs)(s.p,{children:["\u26a0\ufe0f Igual que antes, ",(0,i.jsx)(s.strong,{children:"no pongas listas enormes"}),":\ncada valor extra multiplica el n\xfamero de modelos que se entrenan."]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h3,{id:"ejecutar-gridsearchcv-con-random-forest",children:"Ejecutar GridSearchCV con Random Forest"}),(0,i.jsx)(s.pre,{children:(0,i.jsx)(s.code,{className:"language-python",children:'from sklearn.model_selection import GridSearchCV\n\n# Modelo base\nrf = RandomForestClassifier(random_state=42)\n\n# Configuramos GridSearchCV\ngrid = GridSearchCV(\n    estimator=rf,\n    param_grid=param_grid,\n    cv=5,                  # Validaci\xf3n cruzada 5-fold\n    scoring="accuracy",    # M\xe9trica a optimizar\n    n_jobs=-1              # Usa todos los n\xfacleos disponibles (opcional)\n)\n\n# Entrenamos la b\xfasqueda de hiperpar\xe1metros\ngrid.fit(X_train, y_train)\n\n# Mostramos la mejor combinaci\xf3n encontrada\nprint("Mejores hiperpar\xe1metros:", grid.best_params_)\n\n# Obtenemos directamente el Random Forest \xf3ptimo\nbest_rf = grid.best_estimator_\n'})}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.code,{children:"best_rf"})," es el modelo \xf3ptimo ya entrenado, listo para evaluar en test o para analizar importancias de variables."]}),(0,i.jsx)(s.hr,{}),(0,i.jsx)(s.h2,{id:"actividad-de-seguimiento-titanic",children:"Actividad de seguimiento: Titanic"}),(0,i.jsxs)(s.p,{children:["Realiza un proyecto completo con el dataset ",(0,i.jsx)(s.strong,{children:"Titanic"})," siguiendo los pasos vistos en clase."]}),(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"EDA b\xe1sico"})," (ya realizado en entregas anteriores)"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Preprocesamiento"})," (ya realizado en entregas anteriores)"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Modelado:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["Entrena un ",(0,i.jsx)(s.strong,{children:"\xc1rbol de Decisi\xf3n"})]}),"\n",(0,i.jsxs)(s.li,{children:["Entrena un ",(0,i.jsx)(s.strong,{children:"Random Forest"})]}),"\n",(0,i.jsx)(s.li,{children:"Busca los mejores par\xe1metros, muestras los \xe1rboles generados, etc."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Evaluaci\xf3n:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Accuracy"}),"\n",(0,i.jsx)(s.li,{children:"Matriz de confusi\xf3n"}),"\n",(0,i.jsx)(s.li,{children:"Comparaci\xf3n entre ambos modelos"}),"\n"]}),"\n"]}),"\n"]}),(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Entrega:"})," Notebook (Colab) con todos los pasos y conclusiones."]})]})}function m(e={}){const{wrapper:s}={...(0,o.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(t,{...e})}):t(e)}},94940:(e,s,n)=>{n.d(s,{A:()=>r});const r=n.p+"assets/images/rf-votacion-final-a732cdb0a069a8424e76ff56c6b41ee1.png"},97087:(e,s,n)=>{n.d(s,{A:()=>r});const r=n.p+"assets/files/iris-11586a493a1db7736fce5ba6dc154074.csv"}}]);