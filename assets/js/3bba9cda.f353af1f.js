"use strict";(self.webpackChunkpmdm=self.webpackChunkpmdm||[]).push([[3714],{14546:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/files/ejemplo_svr-07a57d9cf2cba612ed2aa7fe2f85b477.ipynb"},18614:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/kernel-svr-54e1eac62321d5e802be82d0aa60faf2.png"},28453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var s=r(96540);const i={},l=s.createContext(i);function o(e){const n=s.useContext(l);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(l.Provider,{value:n},e.children)}},47042:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"pia_2526/ut3_ml/aprendizaje-supervisado/regresion/svr","title":"Support Vector Regression (SVR)","description":"Introducci\xf3n a Support Vector Regression (SVR) en Machine Learning. Idea del margen epsilon, vectores soporte, kernels, hiperpar\xe1metros principales y comparaci\xf3n con otros modelos de regresi\xf3n.","source":"@site/docs/01_pia_2526/ut3_ml/5-aprendizaje-supervisado/2-regresion/08_svr.md","sourceDirName":"01_pia_2526/ut3_ml/5-aprendizaje-supervisado/2-regresion","slug":"/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/svr","permalink":"/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/svr","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"title":"Support Vector Regression (SVR)","sidebar_position":8,"toc_max_heading_level":5,"description":"Introducci\xf3n a Support Vector Regression (SVR) en Machine Learning. Idea del margen epsilon, vectores soporte, kernels, hiperpar\xe1metros principales y comparaci\xf3n con otros modelos de regresi\xf3n.","keywords":["SVR","Support Vector Regression","SVM","Regresi\xf3n","Machine Learning","scikit-learn","kernel","epsilon"]},"sidebar":"pia_2526_Sidebar","previous":{"title":"Gradient Boosting Regresi\xf3n","permalink":"/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/gradient_boosting"}}');var i=r(74848),l=r(28453);const o={title:"Support Vector Regression (SVR)",sidebar_position:8,toc_max_heading_level:5,description:"Introducci\xf3n a Support Vector Regression (SVR) en Machine Learning. Idea del margen epsilon, vectores soporte, kernels, hiperpar\xe1metros principales y comparaci\xf3n con otros modelos de regresi\xf3n.",keywords:["SVR","Support Vector Regression","SVM","Regresi\xf3n","Machine Learning","scikit-learn","kernel","epsilon"]},a=void 0,d={},c=[{value:"Idea principal del algoritmo",id:"idea-principal-del-algoritmo",level:2},{value:"SVR como modelo basado en m\xe1rgenes",id:"svr-como-modelo-basado-en-m\xe1rgenes",level:2},{value:"Funcionamiento interno del modelo",id:"funcionamiento-interno-del-modelo",level:2},{value:"Margen epsilon (\u03b5)",id:"margen-epsilon-\u03b5",level:3},{value:"Vectores soporte",id:"vectores-soporte",level:3},{value:"Regularizaci\xf3n (C)",id:"regularizaci\xf3n-c",level:3},{value:"Entrenamiento vs predicci\xf3n",id:"entrenamiento-vs-predicci\xf3n",level:2},{value:"Entrenamiento",id:"entrenamiento",level:3},{value:"Predicci\xf3n",id:"predicci\xf3n",level:3},{value:"Uso de SVR en regresi\xf3n",id:"uso-de-svr-en-regresi\xf3n",level:2},{value:"Cu\xe1ndo S\xcd usarlo",id:"cu\xe1ndo-s\xed-usarlo",level:3},{value:"Cu\xe1ndo NO es la mejor opci\xf3n",id:"cu\xe1ndo-no-es-la-mejor-opci\xf3n",level:3},{value:"Importancia del preprocesamiento",id:"importancia-del-preprocesamiento",level:2},{value:"Principales hiperpar\xe1metros",id:"principales-hiperpar\xe1metros",level:2},{value:"Par\xe1metro C",id:"par\xe1metro-c",level:3},{value:"Margen epsilon (<code>epsilon</code>)",id:"margen-epsilon-epsilon",level:3},{value:"Kernel",id:"kernel",level:3},{value:"Par\xe1metro gamma (en kernels no lineales)",id:"par\xe1metro-gamma-en-kernels-no-lineales",level:3},{value:"Ajuste de hiperpar\xe1metros",id:"ajuste-de-hiperpar\xe1metros",level:2},{value:"Interpretabilidad del modelo",id:"interpretabilidad-del-modelo",level:2},{value:"M\xe9tricas de evaluaci\xf3n",id:"m\xe9tricas-de-evaluaci\xf3n",level:2},{value:"Flujo recomendado en un problema de SVR (Regresi\xf3n)",id:"flujo-recomendado-en-un-problema-de-svr-regresi\xf3n",level:2},{value:"Ejemplo: SVR para Regresi\xf3n",id:"ejemplo-svr-para-regresi\xf3n",level:2},{value:"Actividad de seguimiento: Bike Sharing Dataset",id:"actividad-de-seguimiento-bike-sharing-dataset",level:2}];function t(e){const n={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["La ",(0,i.jsx)(n.strong,{children:"Support Vector Regression (SVR)"})," es un algoritmo de Machine Learning utilizado para ",(0,i.jsx)(n.strong,{children:"predecir valores num\xe9ricos"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"A diferencia de otros modelos de regresi\xf3n, SVR no intenta minimizar directamente el error total, sino que busca:"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Encontrar una funci\xf3n lo m\xe1s simple posible que se ajuste a los datos, permitiendo peque\xf1os errores controlados."})}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["SVR es un modelo ",(0,i.jsx)(n.strong,{children:"potente"}),", especialmente en datasets peque\xf1os o medianos, pero tambi\xe9n ",(0,i.jsx)(n.strong,{children:"sensible al preprocesamiento y a los hiperpar\xe1metros"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"idea-principal-del-algoritmo",children:"Idea principal del algoritmo"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Gr\xe1fico EDA",src:r(72070).A+"",width:"250",height:"202"})}),"\n",(0,i.jsx)(n.p,{children:"La idea central de SVR es la siguiente:"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"\u201cAjustar una funci\xf3n que prediga bien, manteni\xe9ndose lo m\xe1s plana posible, y tolerando errores peque\xf1os.\u201d"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Para ello, SVR introduce el concepto de ",(0,i.jsx)(n.strong,{children:"margen epsilon (\u03b5)"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Se define un ",(0,i.jsx)(n.strong,{children:"tubo alrededor de la funci\xf3n"})]}),"\n",(0,i.jsxs)(n.li,{children:["Los errores ",(0,i.jsx)(n.strong,{children:"dentro del tubo no se penalizan"})]}),"\n",(0,i.jsxs)(n.li,{children:["Solo se penalizan los puntos que quedan ",(0,i.jsx)(n.strong,{children:"fuera del margen"})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Estos puntos se denominan ",(0,i.jsx)(n.strong,{children:"vectores soporte"})," y son los que realmente determinan el modelo."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"svr-como-modelo-basado-en-m\xe1rgenes",children:"SVR como modelo basado en m\xe1rgenes"}),"\n",(0,i.jsxs)(n.p,{children:["SVR pertenece a la familia de modelos ",(0,i.jsx)(n.strong,{children:"basados en m\xe1rgenes"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"No intenta pasar exactamente por todos los puntos"}),"\n",(0,i.jsxs)(n.li,{children:["Busca un compromiso entre:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"buen ajuste"}),"\n",(0,i.jsx)(n.li,{children:"simplicidad del modelo"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Solo algunos puntos influyen en la soluci\xf3n final"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Esto hace que SVR sea:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"robusto frente a cierto ruido"}),"\n",(0,i.jsx)(n.li,{children:"sensible a outliers si no se regula bien"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"funcionamiento-interno-del-modelo",children:"Funcionamiento interno del modelo"}),"\n",(0,i.jsx)(n.p,{children:"El entrenamiento de SVR se basa en los siguientes conceptos:"}),"\n",(0,i.jsx)(n.h3,{id:"margen-epsilon-\u03b5",children:"Margen epsilon (\u03b5)"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Define una zona de tolerancia alrededor de la funci\xf3n"}),"\n",(0,i.jsxs)(n.li,{children:["Errores menores que \u03b5 ",(0,i.jsx)(n.strong,{children:"no se penalizan"})]}),"\n",(0,i.jsxs)(n.li,{children:["Cuanto mayor es \u03b5:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"m\xe1s tolerancia al error"}),"\n",(0,i.jsx)(n.li,{children:"modelo m\xe1s simple"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"vectores-soporte",children:"Vectores soporte"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Son los puntos que quedan:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"fuera del margen \u03b5"}),"\n",(0,i.jsx)(n.li,{children:"o justo en el borde"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:"Solo estos puntos influyen en la funci\xf3n final"}),"\n",(0,i.jsxs)(n.li,{children:["El resto de observaciones ",(0,i.jsx)(n.strong,{children:"no afectan al modelo"})]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"regularizaci\xf3n-c",children:"Regularizaci\xf3n (C)"}),"\n",(0,i.jsxs)(n.p,{children:["SVR introduce el par\xe1metro ",(0,i.jsx)(n.strong,{children:"C"}),", que controla cu\xe1nto se penalizan los errores grandes:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"C grande \u2192 el modelo intenta ajustarse mucho a los datos"}),"\n",(0,i.jsx)(n.li,{children:"C peque\xf1o \u2192 se permite m\xe1s error para ganar generalizaci\xf3n"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"entrenamiento-vs-predicci\xf3n",children:"Entrenamiento vs predicci\xf3n"}),"\n",(0,i.jsx)(n.h3,{id:"entrenamiento",children:"Entrenamiento"}),"\n",(0,i.jsx)(n.p,{children:"Durante el entrenamiento, SVR:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Define un margen \u03b5 alrededor de la funci\xf3n"}),"\n",(0,i.jsx)(n.li,{children:"Busca una funci\xf3n lo m\xe1s plana posible"}),"\n",(0,i.jsx)(n.li,{children:"Penaliza solo los errores que superan \u03b5"}),"\n",(0,i.jsx)(n.li,{children:"Ajusta la funci\xf3n usando los vectores soporte"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["El proceso se basa en una ",(0,i.jsx)(n.strong,{children:"optimizaci\xf3n matem\xe1tica"}),", no en reglas ni \xe1rboles."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"predicci\xf3n",children:"Predicci\xf3n"}),"\n",(0,i.jsx)(n.p,{children:"Para predecir un nuevo dato se eval\xfaa la funci\xf3n aprendida"}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"uso-de-svr-en-regresi\xf3n",children:"Uso de SVR en regresi\xf3n"}),"\n",(0,i.jsx)(n.h3,{id:"cu\xe1ndo-s\xed-usarlo",children:"Cu\xe1ndo S\xcd usarlo"}),"\n",(0,i.jsx)(n.p,{children:"SVR puede ser una buena opci\xf3n cuando:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"El dataset es peque\xf1o o mediano"}),"\n",(0,i.jsx)(n.li,{children:"Hay relaciones no lineales"}),"\n",(0,i.jsx)(n.li,{children:"Se dispone de buen preprocesamiento"}),"\n",(0,i.jsx)(n.li,{children:"Se busca un modelo potente sin usar ensembles"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"cu\xe1ndo-no-es-la-mejor-opci\xf3n",children:"Cu\xe1ndo NO es la mejor opci\xf3n"}),"\n",(0,i.jsx)(n.p,{children:"SVR puede no ser ideal cuando:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"El dataset es muy grande (entrenamiento lento)"}),"\n",(0,i.jsx)(n.li,{children:"Hay muchas variables sin escalar"}),"\n",(0,i.jsx)(n.li,{children:"Se requiere interpretabilidad"}),"\n",(0,i.jsx)(n.li,{children:"Hay muchos outliers no tratados"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"importancia-del-preprocesamiento",children:"Importancia del preprocesamiento"}),"\n",(0,i.jsxs)(n.p,{children:["En SVR, el preprocesamiento es ",(0,i.jsx)(n.strong,{children:"cr\xedtico"}),":"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspecto"}),(0,i.jsx)(n.th,{children:"\xbfEs necesario?"}),(0,i.jsx)(n.th,{children:"Explicaci\xf3n"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Tratamiento de nulos"}),(0,i.jsx)(n.td,{children:"\u2714 S\xed"}),(0,i.jsx)(n.td,{children:"No admite valores nulos"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Escalado"}),(0,i.jsxs)(n.td,{children:["\u2714 ",(0,i.jsx)(n.strong,{children:"Obligatorio"})]}),(0,i.jsx)(n.td,{children:"Usa distancias y productos escalares"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Variables categ\xf3ricas"}),(0,i.jsx)(n.td,{children:"\u2714 S\xed"}),(0,i.jsx)(n.td,{children:"Deben codificarse"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Outliers"}),(0,i.jsx)(n.td,{children:"\u26a0\ufe0f Muy importante"}),(0,i.jsx)(n.td,{children:"Afectan directamente al margen"})]})]})]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["En la pr\xe1ctica, SVR ",(0,i.jsx)(n.strong,{children:"siempre debe combinarse con escalado"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"principales-hiperpar\xe1metros",children:"Principales hiperpar\xe1metros"}),"\n",(0,i.jsxs)(n.p,{children:["SVR es ",(0,i.jsx)(n.strong,{children:"muy sensible a los hiperpar\xe1metros"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"Los m\xe1s importantes son:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"C"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"epsilon"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"kernel"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"gamma"})," (seg\xfan el kernel)"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"par\xe1metro-c",children:"Par\xe1metro C"}),"\n",(0,i.jsx)(n.p,{children:"Controla el equilibrio entre:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"ajuste a los datos"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"simplicidad del modelo"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"C grande \u2192 riesgo de overfitting"}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"C peque\xf1o \u2192 posible underfitting"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.h3,{id:"margen-epsilon-epsilon",children:["Margen epsilon (",(0,i.jsx)(n.code,{children:"epsilon"}),")"]}),"\n",(0,i.jsx)(n.p,{children:"Define cu\xe1nto error se tolera sin penalizar:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u03b5 peque\xf1o \u2192 ajuste m\xe1s estricto"}),"\n",(0,i.jsx)(n.li,{children:"\u03b5 grande \u2192 modelo m\xe1s suave"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"kernel",children:"Kernel"}),"\n",(0,i.jsx)(n.p,{children:"El kernel define la forma de la funci\xf3n aprendida."}),"\n",(0,i.jsx)(n.p,{children:"Los m\xe1s comunes son:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"linear"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"rbf"})," (el m\xe1s utilizado)"]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"poly"})}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["El kernel permite a SVR modelar ",(0,i.jsx)(n.strong,{children:"relaciones no lineales"}),"."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Gr\xe1fico EDA",src:r(18614).A+"",width:"635",height:"444"})}),"\n",(0,i.jsx)(n.p,{children:"En el gr\xe1fico anterior:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"(a) Linear"}),"\n",(0,i.jsx)(n.li,{children:"(b) Polynomial"}),"\n",(0,i.jsx)(n.li,{children:"(c) Gaussian RBF"}),"\n",(0,i.jsx)(n.li,{children:"(d) Exponential RBF"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["La imagen muestra c\xf3mo ",(0,i.jsx)(n.strong,{children:"SVR cambia la forma de la funci\xf3n aprendida seg\xfan el kernel utilizado"}),". Con el ",(0,i.jsx)(n.strong,{children:"kernel lineal"})," (a), el modelo ajusta una recta con margen, por lo que solo puede capturar relaciones lineales. Con el ",(0,i.jsx)(n.strong,{children:"kernel polin\xf3mico"})," (b), la funci\xf3n se curva suavemente y permite modelar relaciones no lineales simples. El ",(0,i.jsx)(n.strong,{children:"kernel Gaussiano RBF"})," (c) ofrece mayor flexibilidad, adapt\xe1ndose mejor a patrones no lineales complejos manteniendo una curva suave. Por \xfaltimo, el ",(0,i.jsx)(n.strong,{children:"kernel RBF exponencial"})," (d) genera un ajuste muy flexible y local, capaz de seguir variaciones muy finas de los datos, con mayor riesgo de sobreajuste si no se regulan bien los hiperpar\xe1metros."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"par\xe1metro-gamma-en-kernels-no-lineales",children:"Par\xe1metro gamma (en kernels no lineales)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"gamma"})," indica ",(0,i.jsx)(n.strong,{children:"hasta qu\xe9 distancia \u201cse nota\u201d la influencia de cada punto de entrenamiento"})," en los kernels no lineales (como RBF o polin\xf3mico)."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"gamma grande"})," \u2192 cada punto solo influye en una zona muy cercana. El modelo se vuelve muy sensible a cambios locales y puede generar curvas muy onduladas, con ",(0,i.jsx)(n.strong,{children:"riesgo de sobreajuste"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"gamma peque\xf1o"})," \u2192 cada punto influye en una regi\xf3n amplia. El modelo es m\xe1s suave y generaliza mejor, pero puede ",(0,i.jsx)(n.strong,{children:"no capturar detalles importantes"})," y subajustar."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["En la pr\xe1ctica, ",(0,i.jsx)(n.code,{children:"gamma"})," controla la ",(0,i.jsx)(n.strong,{children:"flexibilidad del modelo"}),": valores altos hacen el modelo m\xe1s complejo y valores bajos lo hacen m\xe1s simple."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"ajuste-de-hiperpar\xe1metros",children:"Ajuste de hiperpar\xe1metros"}),"\n",(0,i.jsx)(n.p,{children:"Es habitual usar:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"validaci\xf3n cruzada"}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"GridSearchCV"})," o ",(0,i.jsx)(n.code,{children:"RandomizedSearchCV"})]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Tabla orientativa:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Dataset"}),(0,i.jsx)(n.th,{children:"C"}),(0,i.jsx)(n.th,{children:"epsilon"}),(0,i.jsx)(n.th,{children:"kernel"}),(0,i.jsx)(n.th,{children:"Comentario"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Peque\xf1o"}),(0,i.jsx)(n.td,{children:"1 \u2013 10"}),(0,i.jsx)(n.td,{children:"0.05\u20130.2"}),(0,i.jsx)(n.td,{children:"rbf"}),(0,i.jsx)(n.td,{children:"Buen equilibrio"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Mediano"}),(0,i.jsx)(n.td,{children:"1 \u2013 100"}),(0,i.jsx)(n.td,{children:"0.05\u20130.1"}),(0,i.jsx)(n.td,{children:"rbf"}),(0,i.jsx)(n.td,{children:"Ajustar gamma con cuidado"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Grande"}),(0,i.jsx)(n.td,{children:"\u274c"}),(0,i.jsx)(n.td,{children:"\u274c"}),(0,i.jsx)(n.td,{children:"\u274c"}),(0,i.jsx)(n.td,{children:"SVR suele ser poco eficiente"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"interpretabilidad-del-modelo",children:"Interpretabilidad del modelo"}),"\n",(0,i.jsxs)(n.p,{children:["SVR ",(0,i.jsx)(n.strong,{children:"no es f\xe1cilmente interpretable"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"No tiene coeficientes claros (salvo kernel lineal)"}),"\n",(0,i.jsx)(n.li,{children:"No hay reglas ni \xe1rboles"}),"\n",(0,i.jsx)(n.li,{children:"No ofrece importancia de variables"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Su interpretaci\xf3n es principalmente ",(0,i.jsx)(n.strong,{children:"geom\xe9trica"})," (m\xe1rgenes)."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"m\xe9tricas-de-evaluaci\xf3n",children:"M\xe9tricas de evaluaci\xf3n"}),"\n",(0,i.jsx)(n.p,{children:"Se usan las m\xe9tricas habituales de regresi\xf3n:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"MAE"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"MSE"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"R\xb2"})}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Es importante evaluar el modelo en ",(0,i.jsx)(n.strong,{children:"train y test"})," para detectar:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"overfitting (C o gamma demasiado altos)"}),"\n",(0,i.jsx)(n.li,{children:"underfitting (C o epsilon demasiado bajos)"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"flujo-recomendado-en-un-problema-de-svr-regresi\xf3n",children:"Flujo recomendado en un problema de SVR (Regresi\xf3n)"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Paso"}),(0,i.jsx)(n.th,{children:"Qu\xe9 se hace"}),(0,i.jsx)(n.th,{children:"Por qu\xe9"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"1. EDA"}),(0,i.jsx)(n.td,{children:"Nulos, outliers, escalas"}),(0,i.jsx)(n.td,{children:"SVR es sensible a la escala"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"2. Preprocesamiento"}),(0,i.jsx)(n.td,{children:"Escalado + encoding"}),(0,i.jsx)(n.td,{children:"Requisito fundamental"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"3. Entrenamiento"}),(0,i.jsx)(n.td,{children:"Ajuste de C, epsilon y kernel"}),(0,i.jsx)(n.td,{children:"Modelo sensible"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"4. Evaluaci\xf3n"}),(0,i.jsx)(n.td,{children:"MAE, MSE, R\xb2 + gr\xe1ficos"}),(0,i.jsx)(n.td,{children:"Detectar overfitting"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"5. Comparaci\xf3n"}),(0,i.jsx)(n.td,{children:"Comparar con otros modelos"}),(0,i.jsx)(n.td,{children:"Elegir mejor modelo"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"ejemplo-svr-para-regresi\xf3n",children:"Ejemplo: SVR para Regresi\xf3n"}),"\n",(0,i.jsxs)(n.p,{children:["Para ver c\xf3mo funciona un ",(0,i.jsx)(n.strong,{children:"Support Vector Regressor"})," en la pr\xe1ctica, puedes ejecutar un ejemplo utilizando el dataset ",(0,i.jsx)(n.strong,{children:"California Housing"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\udc49 ",(0,i.jsx)(n.strong,{children:"Puedes abrir el cuaderno aqu\xed:"}),"\n",(0,i.jsx)(n.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:r(14546).A+"",children:"Colab: Support Vector Regression"})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"actividad-de-seguimiento-bike-sharing-dataset",children:"Actividad de seguimiento: Bike Sharing Dataset"}),"\n",(0,i.jsxs)(n.p,{children:["Utiliza el ",(0,i.jsx)(n.strong,{children:"Bike Sharing Dataset"})," y compara:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Regresi\xf3n Lineal"}),"\n",(0,i.jsx)(n.li,{children:"KNN Regresi\xf3n"}),"\n",(0,i.jsx)(n.li,{children:"\xc1rbol de Decisi\xf3n (Regresi\xf3n)"}),"\n",(0,i.jsx)(n.li,{children:"Random Forest (Regresi\xf3n)"}),"\n",(0,i.jsx)(n.li,{children:"Gradient Boosting"}),"\n",(0,i.jsx)(n.li,{children:"SVR"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Incluye:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Ajuste de hiperpar\xe1metros"}),"\n",(0,i.jsx)(n.li,{children:"M\xe9tricas de evaluaci\xf3n"}),"\n",(0,i.jsx)(n.li,{children:"An\xe1lisis de overfitting"}),"\n",(0,i.jsx)(n.li,{children:"Conclusiones razonadas"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Entrega:"})," Notebook (Colab) con conclusiones claras y justificadas."]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(t,{...e})}):t(e)}},72070:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/svr-41e94c58724b793cc22279ba46cd54ad.png"}}]);