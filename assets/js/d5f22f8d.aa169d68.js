"use strict";(self.webpackChunkpmdm=self.webpackChunkpmdm||[]).push([[2786],{28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>l});var r=s(96540);const i={},o=r.createContext(i);function a(e){const n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(o.Provider,{value:n},e.children)}},36965:(e,n,s)=>{s.d(n,{A:()=>r});const r=s.p+"assets/images/resumen-rfr-cd1a684c24fd86b0040fa97375d70e4a.png"},41869:(e,n,s)=>{s.d(n,{A:()=>r});const r=s.p+"assets/files/ejemplo_random_forest_regresion-e01cd51d2cf389acf84830ce5b5ef844.ipynb"},46642:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"pia_2526/ut3_ml/aprendizaje-supervisado/regresion/random_forest_regresion","title":"Random Forest Regresi\xf3n","description":"Introducci\xf3n a Random Forest Regression en Machine Learning. Funcionamiento del algoritmo (bootstrap y submuestreo de variables), diferencias con \xe1rboles de clasificaci\xf3n, hiperpar\xe1metros principales, importancia de variables y m\xe9tricas de evaluaci\xf3n.","source":"@site/docs/01_pia_2526/ut3_ml/5-aprendizaje-supervisado/2-regresion/05_random_forest_regresion.md","sourceDirName":"01_pia_2526/ut3_ml/5-aprendizaje-supervisado/2-regresion","slug":"/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/random_forest_regresion","permalink":"/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/random_forest_regresion","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Random Forest Regresi\xf3n","sidebar_position":5,"toc_max_heading_level":5,"description":"Introducci\xf3n a Random Forest Regression en Machine Learning. Funcionamiento del algoritmo (bootstrap y submuestreo de variables), diferencias con \xe1rboles de clasificaci\xf3n, hiperpar\xe1metros principales, importancia de variables y m\xe9tricas de evaluaci\xf3n.","keywords":["Random Forest","Bosques Aleatorios","Regresi\xf3n","Random Forest Regression","Machine Learning","scikit-learn","bootstrap","bagging"]},"sidebar":"pia_2526_Sidebar","previous":{"title":"Decision Trees Regresi\xf3n","permalink":"/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/arbol_decision_regresion"},"next":{"title":"Ridge y Lasso Regression","permalink":"/DevTacora/docs/pia_2526/ut3_ml/aprendizaje-supervisado/regresion/regresion_ridge_lasso"}}');var i=s(74848),o=s(28453);const a={title:"Random Forest Regresi\xf3n",sidebar_position:5,toc_max_heading_level:5,description:"Introducci\xf3n a Random Forest Regression en Machine Learning. Funcionamiento del algoritmo (bootstrap y submuestreo de variables), diferencias con \xe1rboles de clasificaci\xf3n, hiperpar\xe1metros principales, importancia de variables y m\xe9tricas de evaluaci\xf3n.",keywords:["Random Forest","Bosques Aleatorios","Regresi\xf3n","Random Forest Regression","Machine Learning","scikit-learn","bootstrap","bagging"]},l=void 0,d={},c=[{value:"Idea principal del algoritmo",id:"idea-principal-del-algoritmo",level:2},{value:"Funcionamiento interno del modelo",id:"funcionamiento-interno-del-modelo",level:2},{value:"Paso 1: Bootstrap (muestreo con reemplazo)",id:"paso-1-bootstrap-muestreo-con-reemplazo",level:3},{value:"Paso 2: Entrenar un \xe1rbol con submuestreo de variables",id:"paso-2-entrenar-un-\xe1rbol-con-submuestreo-de-variables",level:3},{value:"Paso 3: Repetir para crear muchos \xe1rboles",id:"paso-3-repetir-para-crear-muchos-\xe1rboles",level:3},{value:"Entrenamiento vs predicci\xf3n",id:"entrenamiento-vs-predicci\xf3n",level:2},{value:"Entrenamiento",id:"entrenamiento",level:3},{value:"Predicci\xf3n",id:"predicci\xf3n",level:3},{value:"Random Forest en regresi\xf3n vs clasificaci\xf3n",id:"random-forest-en-regresi\xf3n-vs-clasificaci\xf3n",level:2},{value:"Uso de Random Forest en Regresi\xf3n",id:"uso-de-random-forest-en-regresi\xf3n",level:2},{value:"Cu\xe1ndo S\xcd usarlos",id:"cu\xe1ndo-s\xed-usarlos",level:3},{value:"Cu\xe1ndo NO funcionan bien",id:"cu\xe1ndo-no-funcionan-bien",level:3},{value:"Importancia del preprocesamiento",id:"importancia-del-preprocesamiento",level:2},{value:"Principales hiperpar\xe1metros",id:"principales-hiperpar\xe1metros",level:2},{value:"N\xfamero de \xe1rboles (<code>n_estimators</code>)",id:"n\xfamero-de-\xe1rboles-n_estimators",level:3},{value:"Profundidad m\xe1xima (<code>max_depth</code>)",id:"profundidad-m\xe1xima-max_depth",level:3},{value:"Muestras m\xednimas (<code>min_samples_split</code>, <code>min_samples_leaf</code>)",id:"muestras-m\xednimas-min_samples_split-min_samples_leaf",level:3},{value:"N\xfamero de variables por split (<code>max_features</code>)",id:"n\xfamero-de-variables-por-split-max_features",level:3},{value:"Ajuste de hiperpar\xe1metros",id:"ajuste-de-hiperpar\xe1metros",level:3},{value:"Importancia de variables",id:"importancia-de-variables",level:2},{value:"M\xe9tricas de evaluaci\xf3n",id:"m\xe9tricas-de-evaluaci\xf3n",level:2},{value:"Flujo recomendado en un problema de Random Forest (Regresi\xf3n)",id:"flujo-recomendado-en-un-problema-de-random-forest-regresi\xf3n",level:2},{value:"Ejemplo: Random Forest para Regresi\xf3n",id:"ejemplo-random-forest-para-regresi\xf3n",level:2},{value:"Actividad de seguimiento: Bike Sharing Dataset",id:"actividad-de-seguimiento-bike-sharing-dataset",level:2}];function t(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["Los ",(0,i.jsx)(n.strong,{children:"Random Forest para Regresi\xf3n (Random Forest Regression)"})," son algoritmos de Machine Learning utilizados para ",(0,i.jsx)(n.strong,{children:"predecir valores num\xe9ricos"})," combinando las predicciones de ",(0,i.jsx)(n.strong,{children:"muchos \xe1rboles de decisi\xf3n"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["Un Random Forest es, literalmente, un ",(0,i.jsx)(n.em,{children:"\u201cbosque\u201d"})," de \xe1rboles:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Cada \xe1rbol aprende reglas ",(0,i.jsx)(n.em,{children:"if\u2013else"})," como un Decision Tree"]}),"\n",(0,i.jsxs)(n.li,{children:["Pero se entrena con ",(0,i.jsx)(n.strong,{children:"variaci\xf3n"})," (datos y variables diferentes)"]}),"\n",(0,i.jsxs)(n.li,{children:["La predicci\xf3n final se obtiene ",(0,i.jsx)(n.strong,{children:"promediando"})," las predicciones de todos los \xe1rboles"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["En la pr\xe1ctica, Random Forest suele ser m\xe1s ",(0,i.jsx)(n.strong,{children:"robusto"})," y generaliza mejor que un \xfanico \xe1rbol, porque reduce el ",(0,i.jsx)(n.strong,{children:"overfitting"})," t\xedpico de los Decision Trees."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Gr\xe1fico EDA",src:s(36965).A+"",width:"1400",height:"1000"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"idea-principal-del-algoritmo",children:"Idea principal del algoritmo"}),"\n",(0,i.jsx)(n.p,{children:"La idea es sencilla:"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"\u201cEn vez de confiar en un solo \xe1rbol (que puede sobreajustar), entrenamos muchos \xe1rboles diferentes y combinamos sus predicciones.\u201d"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Para conseguir \xe1rboles ",(0,i.jsx)(n.strong,{children:"diferentes"}),", Random Forest introduce dos fuentes de aleatoriedad:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Bootstrap de filas (bagging)"}),": cada \xe1rbol se entrena con una muestra aleatoria de los datos"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Submuestreo de variables"}),": en cada split, el \xe1rbol solo puede probar un subconjunto aleatorio de features"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Esta combinaci\xf3n hace que los \xe1rboles no sean copias unos de otros, y por tanto el promedio final sea m\xe1s estable."}),"\n",(0,i.jsxs)(n.admonition,{title:"Random Forest es un ensemble",type:"info",children:[(0,i.jsxs)(n.p,{children:["Random Forest es un modelo ",(0,i.jsx)(n.strong,{children:"ensemble"}),", es decir, un modelo formado por la combinaci\xf3n de muchos modelos simples (en este caso, \xe1rboles)."]}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Un \xe1rbol individual puede ser inestable y sobreajustar"}),"\n",(0,i.jsx)(n.li,{children:"Un conjunto de \xe1rboles tiende a ser m\xe1s robusto"}),"\n",(0,i.jsx)(n.li,{children:"La combinaci\xf3n (media) reduce errores por \u201ccasualidades\u201d del entrenamiento"}),"\n"]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"funcionamiento-interno-del-modelo",children:"Funcionamiento interno del modelo"}),"\n",(0,i.jsxs)(n.p,{children:["Un Random Forest se entrena generando muchos \xe1rboles de decisi\xf3n, pero ",(0,i.jsx)(n.strong,{children:"no todos ven exactamente los mismos datos ni las mismas variables"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"paso-1-bootstrap-muestreo-con-reemplazo",children:"Paso 1: Bootstrap (muestreo con reemplazo)"}),"\n",(0,i.jsx)(n.p,{children:"Para entrenar cada \xe1rbol:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Se crea una muestra aleatoria del dataset ",(0,i.jsx)(n.strong,{children:"con reemplazo"})]}),"\n",(0,i.jsxs)(n.li,{children:["Esto significa que:","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"algunas filas aparecen repetidas"}),"\n",(0,i.jsx)(n.li,{children:"algunas filas no aparecen en ese \xe1rbol"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Ejemplo: si el dataset tiene 1.000 filas, cada \xe1rbol suele entrenarse con 1.000 filas muestreadas con reemplazo (por defecto), pero no ser\xe1n las mismas que en otro \xe1rbol."}),"\n",(0,i.jsxs)(n.p,{children:["Esto se conoce como ",(0,i.jsx)(n.strong,{children:"bagging"})," (",(0,i.jsx)(n.em,{children:"bootstrap aggregating"}),")."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"paso-2-entrenar-un-\xe1rbol-con-submuestreo-de-variables",children:"Paso 2: Entrenar un \xe1rbol con submuestreo de variables"}),"\n",(0,i.jsx)(n.p,{children:"Mientras el \xe1rbol se construye:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["En cada nodo, el algoritmo ",(0,i.jsx)(n.strong,{children:"no prueba todas las variables"})]}),"\n",(0,i.jsxs)(n.li,{children:["En su lugar, selecciona un subconjunto aleatorio de features (por ejemplo, ",(0,i.jsx)(n.code,{children:"sqrt(n_features)"}),")"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Luego:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Eval\xfaa posibles splits usando solo esas variables disponibles"}),"\n",(0,i.jsx)(n.li,{children:"Elige el split que mejor reduce el error"}),"\n"]}),"\n",(0,i.jsxs)(n.admonition,{title:"\xbfC\xf3mo se elige la \u201cmejor divisi\xf3n\u201d en regresi\xf3n?",type:"info",children:[(0,i.jsxs)(n.p,{children:["En Random Forest para ",(0,i.jsx)(n.strong,{children:"regresi\xf3n"}),", cada \xe1rbol usa el mismo criterio que un \xe1rbol de decisi\xf3n de regresi\xf3n:"]}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["La divisi\xf3n se elige buscando ",(0,i.jsx)(n.strong,{children:"minimizar el error"})]}),"\n",(0,i.jsxs)(n.li,{children:["Habitualmente se usa ",(0,i.jsx)(n.strong,{children:"MSE (Mean Squared Error)"})," como medida del error"]}),"\n"]}),(0,i.jsx)(n.p,{children:"El objetivo de cada split es que, dentro de cada grupo, los valores del target sean lo m\xe1s parecidos posible."})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"paso-3-repetir-para-crear-muchos-\xe1rboles",children:"Paso 3: Repetir para crear muchos \xe1rboles"}),"\n",(0,i.jsxs)(n.p,{children:["El proceso se repite tantas veces como indique el hiperpar\xe1metro ",(0,i.jsx)(n.code,{children:"n_estimators"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"100 \xe1rboles"}),"\n",(0,i.jsx)(n.li,{children:"200 \xe1rboles"}),"\n",(0,i.jsx)(n.li,{children:"500 \xe1rboles\u2026"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Cada \xe1rbol ser\xe1 distinto porque:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"ha visto un bootstrap distinto"}),"\n",(0,i.jsx)(n.li,{children:"y ha tomado decisiones basadas en subconjuntos aleatorios de variables"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"entrenamiento-vs-predicci\xf3n",children:"Entrenamiento vs predicci\xf3n"}),"\n",(0,i.jsx)(n.h3,{id:"entrenamiento",children:"Entrenamiento"}),"\n",(0,i.jsx)(n.p,{children:"Durante el entrenamiento, el Random Forest:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Genera muchos conjuntos bootstrap"}),"\n",(0,i.jsx)(n.li,{children:"Entrena un \xe1rbol por cada bootstrap"}),"\n",(0,i.jsx)(n.li,{children:"Introduce aleatoriedad en las features de cada split"}),"\n",(0,i.jsx)(n.li,{children:"Guarda todos los \xe1rboles"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Este proceso puede ser ",(0,i.jsx)(n.strong,{children:"costoso computacionalmente"}),", porque no entrenamos un modelo, sino muchos."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"predicci\xf3n",children:"Predicci\xf3n"}),"\n",(0,i.jsx)(n.p,{children:"Para predecir un nuevo dato:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["El dato se pasa por ",(0,i.jsx)(n.strong,{children:"cada \xe1rbol"})]}),"\n",(0,i.jsx)(n.li,{children:"Cada \xe1rbol devuelve un valor num\xe9rico (su predicci\xf3n)"}),"\n",(0,i.jsxs)(n.li,{children:["El Random Forest devuelve la ",(0,i.jsx)(n.strong,{children:"media"})," de todas las predicciones"]}),"\n"]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"En regresi\xf3n, Random Forest predice promediando."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Esto suele dar resultados m\xe1s estables que un \xe1rbol individual, especialmente si los datos tienen ruido."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"random-forest-en-regresi\xf3n-vs-clasificaci\xf3n",children:"Random Forest en regresi\xf3n vs clasificaci\xf3n"}),"\n",(0,i.jsx)(n.p,{children:"El funcionamiento general es el mismo en ambos casos:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"muchos \xe1rboles"}),"\n",(0,i.jsx)(n.li,{children:"bootstrap"}),"\n",(0,i.jsx)(n.li,{children:"submuestreo de variables"}),"\n",(0,i.jsx)(n.li,{children:"agregaci\xf3n final"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["La diferencia est\xe1 en ",(0,i.jsx)(n.strong,{children:"c\xf3mo se combinan las predicciones"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Clasificaci\xf3n"})," \u2192 votaci\xf3n mayoritaria"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Regresi\xf3n"})," \u2192 media (promedio)"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"uso-de-random-forest-en-regresi\xf3n",children:"Uso de Random Forest en Regresi\xf3n"}),"\n",(0,i.jsx)(n.h3,{id:"cu\xe1ndo-s\xed-usarlos",children:"Cu\xe1ndo S\xcd usarlos"}),"\n",(0,i.jsx)(n.p,{children:"Random Forest suele funcionar muy bien cuando:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Hay relaciones no lineales"}),"\n",(0,i.jsx)(n.li,{children:"El dataset tiene ruido moderado"}),"\n",(0,i.jsx)(n.li,{children:"Se busca buen rendimiento con poco ajuste"}),"\n",(0,i.jsx)(n.li,{children:"Se quiere un modelo robusto sin demasiada feature engineering"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"En muchos problemas tabulares, Random Forest es un modelo \u201ctodoterreno\u201d."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"cu\xe1ndo-no-funcionan-bien",children:"Cu\xe1ndo NO funcionan bien"}),"\n",(0,i.jsx)(n.p,{children:"Puede no ser la mejor opci\xf3n cuando:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Hay much\xedsimas variables (muy alta dimensionalidad)"}),"\n",(0,i.jsx)(n.li,{children:"Se necesita interpretabilidad total (un bosque es menos interpretable que un \xe1rbol)"}),"\n",(0,i.jsx)(n.li,{children:"El dataset es enorme y el entrenamiento se vuelve lento"}),"\n",(0,i.jsx)(n.li,{children:"Se requiere extrapolar fuera del rango observado (no es su punto fuerte)"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"importancia-del-preprocesamiento",children:"Importancia del preprocesamiento"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspecto"}),(0,i.jsx)(n.th,{children:"\xbfEs necesario?"}),(0,i.jsx)(n.th,{children:"Explicaci\xf3n"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Tratamiento de nulos"}),(0,i.jsx)(n.td,{children:"\u2714 S\xed"}),(0,i.jsx)(n.td,{children:"No admite valores nulos"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Escalado"}),(0,i.jsx)(n.td,{children:"\u274c No"}),(0,i.jsx)(n.td,{children:"No usa distancias"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Variables categ\xf3ricas"}),(0,i.jsx)(n.td,{children:"\u26a0\ufe0f Depende"}),(0,i.jsx)(n.td,{children:"Hay que codificarlas (one-hot, ordinal, etc.)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Outliers"}),(0,i.jsx)(n.td,{children:"\u26a0\ufe0f Importante"}),(0,i.jsx)(n.td,{children:"Un bosque es m\xe1s robusto que un \xe1rbol, pero outliers extremos a\xfan pueden afectar"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"principales-hiperpar\xe1metros",children:"Principales hiperpar\xe1metros"}),"\n",(0,i.jsx)(n.p,{children:"Random Forest suele rendir muy bien \u201cpor defecto\u201d, pero estos hiperpar\xe1metros son clave para controlar rendimiento, overfitting y coste:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"n_estimators"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"max_depth"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"min_samples_split"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"min_samples_leaf"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"max_features"})}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"n\xfamero-de-\xe1rboles-n_estimators",children:["N\xfamero de \xe1rboles (",(0,i.jsx)(n.code,{children:"n_estimators"}),")"]}),"\n",(0,i.jsx)(n.p,{children:"Controla cu\xe1ntos \xe1rboles se entrenan. Por lo general, m\xe1s \xe1rboles dan predicciones m\xe1s estables (hasta cierto punto) pero con un mayor coste de entrenamiento"}),"\n",(0,i.jsx)(n.p,{children:"En general:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"100 suele ser un buen punto de partida"}),"\n",(0,i.jsx)(n.li,{children:"200\u2013500 puede mejorar en datasets complejos"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.h3,{id:"profundidad-m\xe1xima-max_depth",children:["Profundidad m\xe1xima (",(0,i.jsx)(n.code,{children:"max_depth"}),")"]}),"\n",(0,i.jsx)(n.p,{children:"Controla cu\xe1n complejos pueden ser los \xe1rboles. \xc1rboles muy profundos tiene m\xe1s riesgo de overfitting en cada \xe1rbol\npero el promedio del bosque suele reducirlo"}),"\n",(0,i.jsxs)(n.p,{children:["Aun as\xed, limitar ",(0,i.jsx)(n.code,{children:"max_depth"})," puede:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"acelerar entrenamiento"}),"\n",(0,i.jsx)(n.li,{children:"mejorar generalizaci\xf3n en datasets peque\xf1os/ruidosos"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.h3,{id:"muestras-m\xednimas-min_samples_split-min_samples_leaf",children:["Muestras m\xednimas (",(0,i.jsx)(n.code,{children:"min_samples_split"}),", ",(0,i.jsx)(n.code,{children:"min_samples_leaf"}),")"]}),"\n",(0,i.jsx)(n.p,{children:"Igual que en un \xe1rbol:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"min_samples_split"}),": m\xednimo para dividir un nodo"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"min_samples_leaf"}),": m\xednimo para que una hoja sea v\xe1lida"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Subir estos valores suele:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"suavizar las predicciones"}),"\n",(0,i.jsx)(n.li,{children:"reducir overfitting"}),"\n",(0,i.jsx)(n.li,{children:"hacer el modelo m\xe1s estable"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.h3,{id:"n\xfamero-de-variables-por-split-max_features",children:["N\xfamero de variables por split (",(0,i.jsx)(n.code,{children:"max_features"}),")"]}),"\n",(0,i.jsx)(n.p,{children:"Este es uno de los hiperpar\xe1metros m\xe1s caracter\xedsticos del Random Forest."}),"\n",(0,i.jsxs)(n.p,{children:["Indica cu\xe1ntas variables se consideran ",(0,i.jsx)(n.strong,{children:"en cada split"}),"."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Menos variables \u2192 \xe1rboles m\xe1s diferentes \u2192 mejor \u201cdiversidad\u201d"}),"\n",(0,i.jsx)(n.li,{children:"Demasiadas variables \u2192 \xe1rboles m\xe1s parecidos \u2192 menos beneficio del ensemble"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Valores t\xedpicos:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"sqrt"})," (muy com\xfan)"]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"log2"})}),"\n",(0,i.jsxs)(n.li,{children:["un porcentaje (ej. ",(0,i.jsx)(n.code,{children:"0.7"}),")"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"ajuste-de-hiperpar\xe1metros",children:"Ajuste de hiperpar\xe1metros"}),"\n",(0,i.jsx)(n.p,{children:"Como en otros algoritmos:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Se puede usar validaci\xf3n cruzada"}),"\n",(0,i.jsxs)(n.li,{children:["Es habitual usar ",(0,i.jsx)(n.code,{children:"GridSearchCV"})]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Tabla orientativa de rangos para empezar:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Tama\xf1o del dataset"}),(0,i.jsx)(n.th,{children:"N\xba de registros"}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.code,{children:"n_estimators"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.code,{children:"max_depth"})}),(0,i.jsx)(n.th,{children:(0,i.jsx)(n.code,{children:"min_samples_leaf"})}),(0,i.jsx)(n.th,{children:"Comentario"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Peque\xf1o"}),(0,i.jsx)(n.td,{children:"< 1.000"}),(0,i.jsx)(n.td,{children:"100 \u2013 300"}),(0,i.jsx)(n.td,{children:"3 \u2013 10"}),(0,i.jsx)(n.td,{children:"2 \u2013 20"}),(0,i.jsx)(n.td,{children:"Limitar complejidad para evitar overfitting"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Mediano"}),(0,i.jsx)(n.td,{children:"1.000 \u2013 10.000"}),(0,i.jsx)(n.td,{children:"200 \u2013 500"}),(0,i.jsx)(n.td,{children:"5 \u2013 20"}),(0,i.jsx)(n.td,{children:"1 \u2013 10"}),(0,i.jsx)(n.td,{children:"Buen equilibrio rendimiento/tiempo"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Grande"}),(0,i.jsx)(n.td,{children:"> 10.000"}),(0,i.jsx)(n.td,{children:"300 \u2013 800"}),(0,i.jsx)(n.td,{children:"10 \u2013 None"}),(0,i.jsx)(n.td,{children:"1 \u2013 5"}),(0,i.jsx)(n.td,{children:"M\xe1s \xe1rboles y profundidad pueden ayudar"})]})]})]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"Estos rangos sirven como punto de partida. Los mejores hiperpar\xe1metros dependen del dataset y deben ajustarse con validaci\xf3n cruzada."}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"importancia-de-variables",children:"Importancia de variables"}),"\n",(0,i.jsxs)(n.p,{children:["Random Forest permite calcular ",(0,i.jsx)(n.strong,{children:"importancia de variables"}),", normalmente basada en:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"cu\xe1nto reduce el error cuando se usa una feature en los splits"}),"\n",(0,i.jsx)(n.li,{children:"promediado a lo largo de todos los \xe1rboles"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Esto es \xfatil para:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"interpretaci\xf3n parcial del modelo"}),"\n",(0,i.jsx)(n.li,{children:"selecci\xf3n de variables"}),"\n",(0,i.jsx)(n.li,{children:"entender qu\xe9 features aportan m\xe1s informaci\xf3n"}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{title:"Importancia \u2260 causalidad",type:"info",children:(0,i.jsx)(n.p,{children:"Que una variable sea importante no significa que sea la causa del fen\xf3meno.\nIndica que el modelo la usa mucho para reducir el error, pero puede haber correlaciones o variables redundantes."})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"m\xe9tricas-de-evaluaci\xf3n",children:"M\xe9tricas de evaluaci\xf3n"}),"\n",(0,i.jsx)(n.p,{children:"En Random Forest Regression se usan las mismas m\xe9tricas que en otros modelos de regresi\xf3n:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MAE"})," (Mean Absolute Error)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MSE"})," (Mean Squared Error)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"R\xb2"})," (Coeficiente de determinaci\xf3n)"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"flujo-recomendado-en-un-problema-de-random-forest-regresi\xf3n",children:"Flujo recomendado en un problema de Random Forest (Regresi\xf3n)"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Paso"}),(0,i.jsx)(n.th,{children:"Qu\xe9 se hace"}),(0,i.jsx)(n.th,{children:"Por qu\xe9 es importante"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"1. EDA"}),(0,i.jsx)(n.td,{children:"Distribuciones, outliers, nulos"}),(0,i.jsx)(n.td,{children:"Asegura calidad de datos"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"2. Preprocesamiento"}),(0,i.jsx)(n.td,{children:"Limpieza + encoding categ\xf3ricas"}),(0,i.jsx)(n.td,{children:"No admite nulos, necesita num\xe9ricos"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"3. Entrenamiento"}),(0,i.jsx)(n.td,{children:"Ajustar hiperpar\xe1metros"}),(0,i.jsx)(n.td,{children:"Controla rendimiento y coste"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"4. Evaluaci\xf3n"}),(0,i.jsx)(n.td,{children:"MAE, MSE, R\xb2 + gr\xe1ficos"}),(0,i.jsx)(n.td,{children:"Medir generalizaci\xf3n"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"5. Interpretaci\xf3n"}),(0,i.jsx)(n.td,{children:"Importancia de variables"}),(0,i.jsx)(n.td,{children:"Entender el modelo"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"6. Comparaci\xf3n"}),(0,i.jsx)(n.td,{children:"Comparar con otros modelos"}),(0,i.jsx)(n.td,{children:"Elegir el mejor para el dataset"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"ejemplo-random-forest-para-regresi\xf3n",children:"Ejemplo: Random Forest para Regresi\xf3n"}),"\n",(0,i.jsxs)(n.p,{children:["Para ver c\xf3mo funciona un ",(0,i.jsx)(n.strong,{children:"Random Forest Regressor"})," en la pr\xe1ctica, puedes ejecutar este ejemplo utilizando el dataset ",(0,i.jsx)(n.strong,{children:"California Housing"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\udc49 ",(0,i.jsx)(n.strong,{children:"Puedes abrir el cuaderno aqu\xed:"}),"\n",(0,i.jsx)(n.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:s(41869).A+"",children:"Colab: Random Forest Regression"})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"actividad-de-seguimiento-bike-sharing-dataset",children:"Actividad de seguimiento: Bike Sharing Dataset"}),"\n",(0,i.jsxs)(n.p,{children:["Utiliza el ",(0,i.jsx)(n.strong,{children:"Bike Sharing Dataset"})," y compara:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Regresi\xf3n Lineal"}),"\n",(0,i.jsx)(n.li,{children:"KNN Regresi\xf3n"}),"\n",(0,i.jsx)(n.li,{children:"\xc1rbol de Decisi\xf3n (Regresi\xf3n)"}),"\n",(0,i.jsx)(n.li,{children:"Random Forest (Regresi\xf3n)"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Incluye:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Ajuste de hiperpar\xe1metros (",(0,i.jsx)(n.code,{children:"n_estimators"}),", ",(0,i.jsx)(n.code,{children:"max_depth"}),", ",(0,i.jsx)(n.code,{children:"max_features"}),", etc.)"]}),"\n",(0,i.jsx)(n.li,{children:"M\xe9tricas de evaluaci\xf3n"}),"\n",(0,i.jsx)(n.li,{children:"Importancia de variables"}),"\n",(0,i.jsx)(n.li,{children:"Conclusiones razonadas"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Entrega:"})," Notebook (Colab) con conclusiones claras y justificadas."]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(t,{...e})}):t(e)}}}]);