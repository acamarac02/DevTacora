"use strict";(self.webpackChunkpmdm=self.webpackChunkpmdm||[]).push([[8506],{9170:(e,s,a)=>{a.d(s,{A:()=>n});const n=a.p+"assets/images/boxplot-fare-ca9672fa663c0764e001425dacc088aa.png"},28453:(e,s,a)=>{a.d(s,{R:()=>l,x:()=>o});var n=a(96540);const r={},i=n.createContext(r);function l(e){const s=n.useContext(i);return n.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),n.createElement(i.Provider,{value:s},e.children)}},31129:(e,s,a)=>{a.r(s),a.d(s,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"pia_2526/ut3_ml/preprocesamiento","title":"Preprocesamiento de Datos","description":"Introducci\xf3n al Preprocesamiento de Datos en Machine Learning. Qu\xe9 es, por qu\xe9 se realiza despu\xe9s del EDA, principales pasos para limpiar, transformar y preparar los datos antes del modelado utilizando pandas y scikit-learn.","source":"@site/docs/01_pia_2526/ut3_ml/4-preprocesamiento.md","sourceDirName":"01_pia_2526/ut3_ml","slug":"/pia_2526/ut3_ml/preprocesamiento","permalink":"/DevTacora/docs/pia_2526/ut3_ml/preprocesamiento","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Preprocesamiento de Datos","sidebar_position":4,"toc_max_heading_level":4,"description":"Introducci\xf3n al Preprocesamiento de Datos en Machine Learning. Qu\xe9 es, por qu\xe9 se realiza despu\xe9s del EDA, principales pasos para limpiar, transformar y preparar los datos antes del modelado utilizando pandas y scikit-learn.","keywords":["Preprocesamiento","Machine Learning","pandas","scikit-learn","limpieza de datos","escalado","codificaci\xf3n","preparaci\xf3n de datos"]},"sidebar":"pia_2526_Sidebar","previous":{"title":"Exploratory Data Analysis (EDA)","permalink":"/DevTacora/docs/pia_2526/ut3_ml/eda"}}');var r=a(74848),i=a(28453);const l={title:"Preprocesamiento de Datos",sidebar_position:4,toc_max_heading_level:4,description:"Introducci\xf3n al Preprocesamiento de Datos en Machine Learning. Qu\xe9 es, por qu\xe9 se realiza despu\xe9s del EDA, principales pasos para limpiar, transformar y preparar los datos antes del modelado utilizando pandas y scikit-learn.",keywords:["Preprocesamiento","Machine Learning","pandas","scikit-learn","limpieza de datos","escalado","codificaci\xf3n","preparaci\xf3n de datos"]},o=void 0,d={},c=[{value:"Introducci\xf3n",id:"introducci\xf3n",level:2},{value:"\xbfPor qu\xe9 es esencial tras el EDA?",id:"por-qu\xe9-es-esencial-tras-el-eda",level:3},{value:"Objetivos del preprocesamiento",id:"objetivos-del-preprocesamiento",level:3},{value:"Herramientas que usaremos",id:"herramientas-que-usaremos",level:3},{value:"Paso 1. Operaciones antes de la divisi\xf3n",id:"paso-1-operaciones-antes-de-la-divisi\xf3n",level:2},{value:"Paso 1.1 Limpieza estructural",id:"paso-11-limpieza-estructural",level:3},{value:"Correcci\xf3n de tipos de datos",id:"correcci\xf3n-de-tipos-de-datos",level:4},{value:"Normalizaci\xf3n de formatos y categor\xedas",id:"normalizaci\xf3n-de-formatos-y-categor\xedas",level:4},{value:"Paso 1.2 Duplicados",id:"paso-12-duplicados",level:3},{value:"Paso 1.3 Outliers y errores evidentes",id:"paso-13-outliers-y-errores-evidentes",level:3},{value:"Paso 2. Divisi\xf3n en <em>train/test</em>",id:"paso-2-divisi\xf3n-en-traintest",level:2},{value:"Paso 2.1. Separar las features y target",id:"paso-21-separar-las-features-y-target",level:3},{value:"Paso 2.2. Divisi\xf3n del dataset",id:"paso-22-divisi\xf3n-del-dataset",level:3},{value:"Paso 3. Operaciones despu\xe9s de la divisi\xf3n",id:"paso-3-operaciones-despu\xe9s-de-la-divisi\xf3n",level:2},{value:"Paso 3.1 Tratamiento de valores nulos (post-split)",id:"paso-31-tratamiento-de-valores-nulos-post-split",level:3},{value:"Imputaci\xf3n para variables num\xe9ricas",id:"imputaci\xf3n-para-variables-num\xe9ricas",level:4},{value:"Imputaci\xf3n para variables categ\xf3ricas",id:"imputaci\xf3n-para-variables-categ\xf3ricas",level:4},{value:"Paso 3.2 Codificaci\xf3n de variables categ\xf3ricas",id:"paso-32-codificaci\xf3n-de-variables-categ\xf3ricas",level:3},{value:"\xbfC\xf3mo elegir entre Label y One-Hot?",id:"c\xf3mo-elegir-entre-label-y-one-hot",level:4},{value:"Label Encoding (para variables <em>ordinales</em>)",id:"label-encoding-para-variables-ordinales",level:4},{value:"One-Hot Encoding (para variables <em>nominales</em>)",id:"one-hot-encoding-para-variables-nominales",level:4},{value:"Paso 3.3. Feature Engineering b\xe1sico",id:"paso-33-feature-engineering-b\xe1sico",level:3},{value:"Creaci\xf3n de variables intuitivas",id:"creaci\xf3n-de-variables-intuitivas",level:4},{value:"Eliminaci\xf3n de variables redundantes",id:"eliminaci\xf3n-de-variables-redundantes",level:4},{value:"Paso 3.4. Escalado y normalizaci\xf3n de variables num\xe9ricas",id:"paso-34-escalado-y-normalizaci\xf3n-de-variables-num\xe9ricas",level:3},{value:"M\xe9todos m\xe1s utilizados",id:"m\xe9todos-m\xe1s-utilizados",level:4},{value:"StandardScaler (escalado est\xe1ndar)",id:"standardscaler-escalado-est\xe1ndar",level:4},{value:"MinMaxScaler (normalizaci\xf3n 0\u20131)",id:"minmaxscaler-normalizaci\xf3n-01",level:4},{value:"Resumen StandardScaler vs MinMaxScaler",id:"resumen-standardscaler-vs-minmaxscaler",level:4},{value:"\xbfDebo escalar todas las columnas num\xe9ricas?",id:"debo-escalar-todas-las-columnas-num\xe9ricas",level:4},{value:"Paso 4. Preparaci\xf3n final del dataset",id:"paso-4-preparaci\xf3n-final-del-dataset",level:2},{value:"Paso 4.1 Revisi\xf3n r\xe1pida de coherencia",id:"paso-41-revisi\xf3n-r\xe1pida-de-coherencia",level:3},{value:"Paso 4.2 Dataset final listo para el modelado",id:"paso-42-dataset-final-listo-para-el-modelado",level:3},{value:"Paso 4.3 Guardar los datasets transformados (opcional, pero recomendable)",id:"paso-43-guardar-los-datasets-transformados-opcional-pero-recomendable",level:3},{value:"Ejercicio de Titanic",id:"ejercicio-de-titanic",level:2}];function t(e){const s={a:"a",admonition:"admonition",blockquote:"blockquote",br:"br",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)("div",{class:"justify-text",children:[(0,r.jsxs)(s.p,{children:["El ",(0,r.jsx)(s.strong,{children:"Preprocesamiento de Datos"})," es la ",(0,r.jsx)(s.strong,{children:"segunda etapa del proceso de Machine Learning"}),", y comienza justo despu\xe9s de haber realizado el ",(0,r.jsx)(s.strong,{children:"An\xe1lisis Exploratorio de Datos (EDA)"}),".",(0,r.jsx)(s.br,{}),"\n","Si en el EDA analizamos y comprendemos los datos, en el preprocesamiento el objetivo es ",(0,r.jsx)(s.strong,{children:"prepararlos adecuadamente"})," para que los algoritmos de aprendizaje autom\xe1tico puedan trabajar con ellos de forma correcta y eficiente."]}),(0,r.jsxs)(s.p,{children:["Durante esta fase, se realizan todas las tareas necesarias para ",(0,r.jsx)(s.strong,{children:"limpiar, transformar y estandarizar"})," los datos.",(0,r.jsx)(s.br,{}),"\n","Esto incluye, por ejemplo, rellenar valores nulos, eliminar duplicados, codificar variables categ\xf3ricas o escalar las num\xe9ricas."]}),(0,r.jsx)("div",{class:"hidden-summary",children:(0,r.jsx)(s.h2,{id:"introducci\xf3n",children:"Introducci\xf3n"})}),(0,r.jsx)(s.h3,{id:"por-qu\xe9-es-esencial-tras-el-eda",children:"\xbfPor qu\xe9 es esencial tras el EDA?"}),(0,r.jsxs)(s.p,{children:["El EDA nos permite descubrir ",(0,r.jsx)(s.strong,{children:"problemas o irregularidades"})," en el dataset: valores perdidos, outliers, tipos de datos incorrectos o variables irrelevantes.",(0,r.jsx)(s.br,{}),"\n","El preprocesamiento es la fase donde ",(0,r.jsx)(s.strong,{children:"se corrigen esos problemas"})," y se dejan los datos listos para el modelado."]}),(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Etapa"}),(0,r.jsx)(s.th,{children:"Objetivo principal"}),(0,r.jsx)(s.th,{children:"Tipo de tareas"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.strong,{children:"EDA"})}),(0,r.jsx)(s.td,{children:"Comprender los datos y detectar patrones o errores."}),(0,r.jsx)(s.td,{children:"An\xe1lisis descriptivo, visualizaci\xf3n, detecci\xf3n de nulos y outliers."})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.strong,{children:"Preprocesamiento"})}),(0,r.jsx)(s.td,{children:"Corregir, transformar y preparar los datos para el modelo."}),(0,r.jsx)(s.td,{children:"Limpieza, imputaci\xf3n, codificaci\xf3n, escalado, selecci\xf3n de variables."})]})]})]}),(0,r.jsxs)(s.p,{children:["\ud83d\udcac ",(0,r.jsx)(s.strong,{children:"Ejemplo:"}),"\nEn el Titanic, durante el EDA descubrimos que hay valores nulos en ",(0,r.jsx)(s.code,{children:"Age"})," y ",(0,r.jsx)(s.code,{children:"Cabin"}),", y que ",(0,r.jsx)(s.code,{children:"Fare"})," tiene outliers.",(0,r.jsx)(s.br,{}),"\n","En el preprocesamiento, decidiremos ",(0,r.jsx)(s.strong,{children:"c\xf3mo rellenar esos nulos"}),", ",(0,r.jsx)(s.strong,{children:"si eliminar o ajustar los outliers"}),", y ",(0,r.jsx)(s.strong,{children:"c\xf3mo convertir las variables categ\xf3ricas"})," (como ",(0,r.jsx)(s.code,{children:"Sex"})," o ",(0,r.jsx)(s.code,{children:"Embarked"}),") a formato num\xe9rico."]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"objetivos-del-preprocesamiento",children:"Objetivos del preprocesamiento"}),(0,r.jsx)(s.p,{children:"El objetivo final es dejar el dataset:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Limpio:"})," sin errores, duplicados ni valores faltantes."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Coherente:"})," con tipos de datos correctos y valores representativos."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Preparado:"})," con todas las variables transformadas en un formato num\xe9rico adecuado para los modelos de Machine Learning."]}),"\n"]}),(0,r.jsxs)(s.p,{children:["En otras palabras, buscamos que los datos sean ",(0,r.jsx)(s.strong,{children:"de calidad y comparables entre s\xed"}),", para que el modelo aprenda de forma fiable."]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"herramientas-que-usaremos",children:"Herramientas que usaremos"}),(0,r.jsx)(s.p,{children:"En Python, las principales herramientas para el preprocesamiento son:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:(0,r.jsx)(s.code,{children:"pandas"})})," \u2192 para limpiar, transformar y manipular los datos."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:(0,r.jsx)(s.code,{children:"scikit-learn (sklearn.preprocessing)"})})," \u2192 para aplicar transformaciones autom\xe1ticas como imputaci\xf3n, codificaci\xf3n y escalado."]}),"\n"]}),(0,r.jsx)(s.p,{children:"Estas librer\xedas se complementan y permiten llevar a cabo todo el flujo de preparaci\xf3n de datos antes de entrenar el modelo."}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h2,{id:"paso-1-operaciones-antes-de-la-divisi\xf3n",children:"Paso 1. Operaciones antes de la divisi\xf3n"}),(0,r.jsxs)(s.p,{children:["Antes de separar el dataset en conjuntos de entrenamiento (",(0,r.jsx)(s.em,{children:"train"}),") y prueba (",(0,r.jsx)(s.em,{children:"test"}),"), debemos realizar una ",(0,r.jsx)(s.strong,{children:"limpieza estructural b\xe1sica"}),".",(0,r.jsx)(s.br,{}),"\n","Este paso no modifica el contenido estad\xedstico de los datos, sino que se asegura de que el dataset sea ",(0,r.jsx)(s.strong,{children:"coherente, entendible y correctamente tipado"}),"."]}),(0,r.jsxs)(s.p,{children:["Estas operaciones se hacen ",(0,r.jsx)(s.strong,{children:"antes de dividir"})," porque afectan por igual a todos los registros y no implican ning\xfan tipo de aprendizaje sobre los valores de los datos (no calculan medias, ni modas, ni escalados)."]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-11-limpieza-estructural",children:"Paso 1.1 Limpieza estructural"}),(0,r.jsxs)(s.p,{children:["El objetivo de la limpieza estructural es ",(0,r.jsx)(s.strong,{children:"asegurar que el dataset est\xe9 bien formado"}),":"]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Comprobar que los tipos de datos son correctos."}),"\n",(0,r.jsx)(s.li,{children:"Corregir formatos o errores de escritura en las variables."}),"\n"]}),(0,r.jsxs)(s.p,{children:["A continuaci\xf3n veremos cada una de estas operaciones aplicadas al dataset ",(0,r.jsx)(s.strong,{children:"Titanic"}),"."]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"correcci\xf3n-de-tipos-de-datos",children:"Correcci\xf3n de tipos de datos"}),(0,r.jsxs)(s.p,{children:["Los tipos de datos son fundamentales.\nPandas puede leer columnas con el tipo incorrecto (por ejemplo, n\xfameros como texto o fechas como ",(0,r.jsx)(s.code,{children:"object"}),"), lo que puede generar errores en el an\xe1lisis y el modelado."]}),(0,r.jsx)(s.p,{children:"Podemos revisar los tipos con:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"df.info()\n"})}),(0,r.jsxs)(s.p,{children:["Si detectamos alguna columna con tipo err\xf3neo, podemos convertirla usando ",(0,r.jsx)(s.code,{children:"astype()"}),"."]}),(0,r.jsxs)(s.p,{children:["Ejemplo: supongamos que una columna num\xe9rica ha sido le\xedda como texto (",(0,r.jsx)(s.code,{children:"object"}),"):"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'# Convertir una columna a tipo num\xe9rico\ndf["Fare"] = df["Fare"].astype(float)\n'})}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Explicaci\xf3n te\xf3rica:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["Los modelos de Machine Learning requieren que ",(0,r.jsx)(s.strong,{children:"las variables num\xe9ricas sean realmente num\xe9ricas"}),", no cadenas de texto."]}),"\n",(0,r.jsx)(s.li,{children:"Asegurar los tipos correctos evita errores posteriores en imputaci\xf3n, escalado o codificaci\xf3n."}),"\n"]}),(0,r.jsxs)(s.p,{children:["\ud83d\udcac ",(0,r.jsx)(s.strong,{children:"Conclusi\xf3n:"})]}),(0,r.jsxs)(s.blockquote,{children:["\n",(0,r.jsx)(s.p,{children:"Revisar y corregir los tipos de datos garantiza que todas las columnas se comporten como se espera en las transformaciones posteriores."}),"\n"]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"normalizaci\xf3n-de-formatos-y-categor\xedas",children:"Normalizaci\xf3n de formatos y categor\xedas"}),(0,r.jsxs)(s.p,{children:["En las variables categ\xf3ricas o de texto, a veces encontramos ",(0,r.jsx)(s.strong,{children:"errores de formato"}),":"]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["Espacios en blanco (",(0,r.jsx)(s.code,{children:'" S "'})," en lugar de ",(0,r.jsx)(s.code,{children:'"S"'}),")."]}),"\n",(0,r.jsxs)(s.li,{children:["May\xfasculas/min\xfasculas mezcladas (",(0,r.jsx)(s.code,{children:'"Male"'})," vs ",(0,r.jsx)(s.code,{children:'"male"'}),")."]}),"\n",(0,r.jsxs)(s.li,{children:["Valores mal escritos (",(0,r.jsx)(s.code,{children:'"Southampton"'})," vs ",(0,r.jsx)(s.code,{children:'"southampton"'}),")."]}),"\n"]}),(0,r.jsxs)(s.p,{children:["Estos errores de formato los veriamos al ejecutar ",(0,r.jsx)(s.code,{children:"unique()"})," sobre una variable categ\xf3rica o al generar gr\xe1ficos sobre ellas. A continuaci\xf3n se muestra un ejemplo donde metemos una dato err\xf3neo en Titanic para estudiar c\xf3mo solucionarlo:"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'# Crear una nueva fila con "Male" como sexo para que podamos ver el error\nnueva_fila = {\n    "PassengerId": 9999,\n    "Survived": 0,\n    "Pclass": 3,\n    "Name": "Smith, Mr. John",\n    "Sex": "Male",\n    "Age": 32,\n    "SibSp": 0,\n    "Parch": 0,\n    "Ticket": "A/5 9999",\n    "Fare": 7.25,\n    "Cabin": "",\n    "Embarked": "S"\n}\n\n# A\xf1adir la fila al DataFrame\ndf = pd.concat([df, pd.DataFrame([nueva_fila])], ignore_index=True)\n\n# Mostrar los valores \xfanicos de la columna \'Sex\'\nprint(df["Sex"].unique())\n'})}),(0,r.jsx)(s.p,{children:"La salida obtenida en este caso ser\xeda:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"array(['male', 'female', 'Male'], dtype=object)\n"})}),(0,r.jsxs)(s.p,{children:["Estos detalles pueden hacer que el modelo interprete ",(0,r.jsx)(s.strong,{children:"dos valores iguales como distintos"}),", lo que distorsiona la codificaci\xf3n posterior."]}),(0,r.jsx)(s.p,{children:"Ese problema anterior se solucionar\xeda pasando a min\xfasculas todos los valores:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'# Normalizar los valores de la columna \'Sex\'\n# Pasamos a min\xfasculas y, de paso, eliminamos posibles espacios\ndf["Sex"] = df["Sex"].str.lower().str.strip()\n\n# Verificar que se ha corregido\nprint(df["Sex"].unique())\n'})}),(0,r.jsx)(s.p,{children:"Salida esperada:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"array(['male', 'female'], dtype=object)\n"})}),(0,r.jsx)(s.p,{children:"Si aparecieran errores tipogr\xe1ficos, se pueden reemplazar manualmente:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'# Ejemplo: sustituir valores incorrectos (si los hubiera)\ndf["Embarked"].replace({"SOUTHAMPTON": "S", "CHERBOURG": "C", "QUEENSTOWN": "Q"}, inplace=True)\n'})}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Explicaci\xf3n te\xf3rica:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["La ",(0,r.jsx)(s.strong,{children:"homogeneizaci\xf3n de categor\xedas"})," es clave para que el modelo reconozca correctamente las clases."]}),"\n",(0,r.jsx)(s.li,{children:"Si dos valores equivalentes se escriben distinto, el modelo los tratar\xe1 como categor\xedas diferentes."}),"\n"]}),(0,r.jsxs)(s.p,{children:["\ud83d\udcac ",(0,r.jsx)(s.strong,{children:"Conclusi\xf3n:"})]}),(0,r.jsxs)(s.blockquote,{children:["\n",(0,r.jsx)(s.p,{children:"Antes de codificar las variables categ\xf3ricas, debemos garantizar que todas las categor\xedas est\xe9n escritas de forma uniforme."}),"\n"]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-12-duplicados",children:"Paso 1.2 Duplicados"}),(0,r.jsxs)(s.p,{children:["En muchos datasets reales, especialmente cuando los datos provienen de distintas fuentes o se han unido varios ficheros, es frecuente encontrar ",(0,r.jsx)(s.strong,{children:"filas duplicadas"}),".",(0,r.jsx)(s.br,{}),"\n","Estas duplicidades pueden provocar que el modelo ",(0,r.jsx)(s.strong,{children:"aprenda varias veces la misma informaci\xf3n"}),", generando sesgos o influyendo en las estad\xedsticas de forma incorrecta."]}),(0,r.jsxs)(s.p,{children:["Por eso, un paso b\xe1sico de la limpieza estructural consiste en ",(0,r.jsx)(s.strong,{children:"detectar y eliminar los registros duplicados"})," antes de seguir con el preprocesamiento."]}),(0,r.jsx)(s.p,{children:"En el An\xe1lisis Exploratorio de Datos ya estudiamos c\xf3mo consultar los duplicados:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"# Comprobar si hay filas duplicadas en el dataset\ndf.duplicated().sum()\n"})}),(0,r.jsx)(s.p,{children:"Salida esperada (en el Titanic original):"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"0\n"})}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Explicaci\xf3n te\xf3rica:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["Si el resultado es ",(0,r.jsx)(s.code,{children:"0"}),", significa que ",(0,r.jsx)(s.strong,{children:"no hay filas duplicadas exactas"}),"."]}),"\n",(0,r.jsxs)(s.li,{children:["Si devuelve un n\xfamero mayor que ",(0,r.jsx)(s.code,{children:"0"}),", indica cu\xe1ntos registros est\xe1n repetidos completamente."]}),"\n"]}),(0,r.jsx)(s.p,{children:"Podemos ver cu\xe1les son esas filas duplicadas con:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"# Mostrar las filas duplicadas (si las hubiera)\ndf[df.duplicated()]\n"})}),(0,r.jsxs)(s.p,{children:["Si detectamos registros repetidos, se eliminan f\xe1cilmente con ",(0,r.jsx)(s.code,{children:"drop_duplicates()"}),":"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"# Eliminar filas duplicadas\ndf = df.drop_duplicates()\n"})}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Explicaci\xf3n te\xf3rica:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["Por defecto, ",(0,r.jsx)(s.code,{children:"drop_duplicates()"})," elimina las filas repetidas ",(0,r.jsx)(s.strong,{children:"manteniendo la primera aparici\xf3n"}),"."]}),"\n",(0,r.jsxs)(s.li,{children:["Este m\xe9todo elimina duplicados considerando ",(0,r.jsx)(s.strong,{children:"todas las columnas"}),"."]}),"\n"]}),(0,r.jsxs)(s.admonition,{title:"Nota importante sobre el orden EDA \u2192 Preprocesamiento",type:"danger",children:[(0,r.jsxs)(s.p,{children:["Los pasos ",(0,r.jsx)(s.strong,{children:"1.1 (Correcci\xf3n de tipos y normalizaci\xf3n de categor\xedas)"})," y ",(0,r.jsx)(s.strong,{children:"1.2 (Eliminaci\xf3n de columnas irrelevantes o duplicadas)"})," pueden realizarse ",(0,r.jsx)(s.strong,{children:"durante el EDA"}),", antes de generar gr\xe1ficos univariantes y bivariantes.\nEsto permite obtener ",(0,r.jsx)(s.strong,{children:"gr\xe1ficos limpios y coherentes"}),", evitando categor\xedas duplicadas (\u201cmale\u201d, \u201cMale\u201d, \u201c male \u201d), tipos incorrectos o columnas que no aportan valor visual."]}),(0,r.jsxs)(s.p,{children:["Sin embargo, ",(0,r.jsx)(s.strong,{children:"todos los pasos restantes del preprocesamiento"})," (tratamiento de valores imposibles, imputaci\xf3n, codificaci\xf3n, escalado, feature engineering\u2026) ",(0,r.jsx)(s.strong,{children:"deben realizarse \xfanicamente despu\xe9s de completar el EDA"}),", cuando ya se ha comprendido la estructura y los problemas del dataset."]})]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-13-outliers-y-errores-evidentes",children:"Paso 1.3 Outliers y errores evidentes"}),(0,r.jsxs)(s.p,{children:["Los ",(0,r.jsx)(s.strong,{children:"outliers"})," (valores at\xedpicos) son datos que se alejan mucho del resto de observaciones. A veces son simplemente ",(0,r.jsx)(s.strong,{children:"casos reales extremos"})," (por ejemplo, una tarifa muy alta en primera clase), pero otras veces se deben a ",(0,r.jsx)(s.strong,{children:"errores de registro o introducci\xf3n de datos"})," (por ejemplo, una edad de 250 a\xf1os)."]}),(0,r.jsxs)(s.p,{children:["En esta fase inicial del preprocesamiento, ",(0,r.jsx)(s.strong,{children:"no buscamos eliminar todos los valores extremos"}),", sino ",(0,r.jsx)(s.strong,{children:"detectar y corregir solo los claramente imposibles o err\xf3neos"}),"."]}),(0,r.jsxs)(s.p,{children:["Una forma sencilla de detectar outliers es mediante un ",(0,r.jsx)(s.strong,{children:"boxplot (diagrama de caja)"}),". Por ejemplo, si introducimos un registro nuevo con una edad de 250 a\xf1os, podr\xedamos ver lo siguiente:"]}),(0,r.jsx)(s.p,{children:(0,r.jsx)(s.img,{alt:"Gr\xe1fico EDA",src:a(49771).A+"",width:"489",height:"240"})}),(0,r.jsxs)(s.p,{children:["No todos los outliers deben eliminarse. Algunos son ",(0,r.jsx)(s.strong,{children:"casos reales v\xe1lidos"}),", y eliminarlos podr\xeda distorsionar el modelo.\nPor eso, antes de borrar nada, conviene preguntarse:"]}),(0,r.jsxs)(s.blockquote,{children:["\n",(0,r.jsx)(s.p,{children:"\xbfEste valor es posible en el contexto del dataset?"}),"\n"]}),(0,r.jsx)(s.p,{children:"Veamos ejemplos:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'# Revisar valores m\xe1ximos en columnas num\xe9ricas\ndf[["Age", "Fare"]].max()\n'})}),(0,r.jsx)(s.p,{children:"Posible salida:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"Age     80.0\nFare    512.3292\ndtype: float64\n"})}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Interpretaci\xf3n:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Una edad de 80 a\xf1os es realista (no hay problema)."}),"\n",(0,r.jsx)(s.li,{children:"Una tarifa de m\xe1s de 500 tambi\xe9n puede ser v\xe1lida para pasajeros de primera clase."}),"\n",(0,r.jsxs)(s.li,{children:["Pero si encontr\xe1ramos una edad de ",(0,r.jsx)(s.strong,{children:"250 a\xf1os"})," o un valor negativo en la tarifa (",(0,r.jsx)(s.code,{children:"Fare = -10"}),"), ser\xedan claramente errores de registro."]}),"\n"]}),(0,r.jsxs)(s.p,{children:["Podemos usar condiciones simples para ",(0,r.jsx)(s.strong,{children:"detectar valores imposibles"})," y corregirlos o eliminarlos."]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'# Ejemplo: eliminar edades imposibles\ndf = df[df["Age"] <= 100]\n\n# Ejemplo: corregir tarifas negativas (si existieran)\n# Esto aprende de datos, se deber\xeda hacer despu\xe9s de dividir en train y test\ndf.loc[df["Fare"] < 0, "Fare"] = df["Fare"].median()\n'})}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Explicaci\xf3n te\xf3rica:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["Usamos ",(0,r.jsx)(s.strong,{children:"filtros l\xf3gicos"})," (",(0,r.jsx)(s.code,{children:'df["Age"] <= 100'}),") para quedarnos solo con valores v\xe1lidos."]}),"\n",(0,r.jsxs)(s.li,{children:["Si un valor err\xf3neo es aislado y no queremos eliminar la fila completa, podemos ",(0,r.jsx)(s.strong,{children:"reemplazarlo"})," por un valor representativo (por ejemplo, la mediana)."]}),"\n"]}),(0,r.jsx)(s.admonition,{title:"CUIDADO CON EL TRATAMIENTO DE LOS OUTLIERS",type:"warning",children:(0,r.jsxs)(s.p,{children:["Si lo que queremos es ",(0,r.jsx)(s.strong,{children:"corregir datos"}),", como el caso de la tarifa que se explicaba antes, habr\xeda que hacerlo ",(0,r.jsx)(s.strong,{children:"despu\xe9s de dividir en train y test"}),"."]})}),(0,r.jsx)(s.hr,{}),(0,r.jsxs)(s.h2,{id:"paso-2-divisi\xf3n-en-traintest",children:["Paso 2. Divisi\xf3n en ",(0,r.jsx)(s.em,{children:"train/test"})]}),(0,r.jsxs)(s.p,{children:["Una vez que el dataset est\xe1 limpio a nivel ",(0,r.jsx)(s.strong,{children:"estructural"})," (sin duplicados, sin columnas irrelevantes, sin tipos incorrectos y sin errores evidentes), estamos listos para el paso m\xe1s importante del flujo de Machine Learning: la ",(0,r.jsx)(s.strong,{children:"divisi\xf3n en conjuntos de entrenamiento y prueba"}),"."]}),(0,r.jsx)(s.p,{children:"Este paso es fundamental para construir modelos fiables y evaluar su rendimiento de forma justa."}),(0,r.jsxs)(s.admonition,{title:"\xbfPor qu\xe9 dividir antes de \u201caprender\u201d par\xe1metros?",type:"info",children:[(0,r.jsxs)(s.p,{children:["Cada vez que aplicamos una t\xe9cnica de preprocesamiento que ",(0,r.jsx)(s.strong,{children:"aprende algo de los datos"}),", como calcular la ",(0,r.jsx)(s.strong,{children:"mediana"})," para imputar nulos, determinar las ",(0,r.jsx)(s.strong,{children:"categor\xedas"})," para One-Hot Encoding, calcular la ",(0,r.jsx)(s.strong,{children:"media y desviaci\xf3n"})," para escalar, estamos extrayendo ",(0,r.jsx)(s.strong,{children:"informaci\xf3n estad\xedstica"})," del dataset."]}),(0,r.jsxs)(s.p,{children:["Si hacemos esta extracci\xf3n ",(0,r.jsx)(s.strong,{children:"antes"})," de dividir, estar\xedamos utilizando ",(0,r.jsx)(s.strong,{children:"informaci\xf3n del futuro"})," (del conjunto de test) para preparar nuestros datos. Esto se llama ",(0,r.jsx)(s.strong,{children:"data leakage"})," (",(0,r.jsx)(s.em,{children:"filtraci\xf3n de datos"}),"), y provoca:"]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"modelos que parecen m\xe1s precisos de lo que realmente son,"}),"\n",(0,r.jsx)(s.li,{children:"una evaluaci\xf3n injusta,"}),"\n",(0,r.jsx)(s.li,{children:"generalizaci\xf3n mucho peor en datos nuevos."}),"\n"]}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Regla de oro del preprocesamiento:"})]}),(0,r.jsxs)(s.blockquote,{children:["\n",(0,r.jsxs)(s.p,{children:["Todo lo que ",(0,r.jsx)(s.strong,{children:"aprende par\xe1metros"})," debe ajustarse ",(0,r.jsx)(s.strong,{children:"solo con los datos de entrenamiento"}),", y luego aplicarse a los datos de prueba sin volver a aprender nada."]}),"\n"]})]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-21-separar-las-features-y-target",children:"Paso 2.1. Separar las features y target"}),(0,r.jsx)(s.p,{children:"Antes de dividir, debemos indicar:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["qu\xe9 columnas vamos a usar para predecir \u2192 ",(0,r.jsx)(s.strong,{children:"X"})," (features)"]}),"\n",(0,r.jsxs)(s.li,{children:["qu\xe9 columna queremos predecir \u2192 ",(0,r.jsx)(s.strong,{children:"y"})," (target)"]}),"\n"]}),(0,r.jsx)(s.p,{children:"Ejemplo con Titanic:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"# Seleccionamos las columnas relevantes (features) y la variable objetivo (target)\n# En EDA ya dejamos claro que Name, Cabin, etc. no eran \xfatiles\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch', 'Embarked']\ntarget = 'Survived'\n\nX = df[features].copy()\ny = df[target]\n"})}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Explicaci\xf3n te\xf3rica:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"X"})," contiene todas las variables que el modelo utilizar\xe1 como entrada."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"y"})," contiene \xfanicamente la variable que queremos predecir."]}),"\n",(0,r.jsxs)(s.li,{children:["Usamos ",(0,r.jsx)(s.code,{children:".copy()"})," para evitar modificar el DataFrame original cuando realicemos transformaciones posteriores."]}),"\n"]}),(0,r.jsxs)(s.p,{children:["Supongamos que nuestro Dataframe (variable ",(0,r.jsx)(s.code,{children:"df"}),") contiene:"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"   Survived  Pclass     Sex   Age   Fare  SibSp  Parch Embarked\n0         0       3    male  22.0   7.25      1      0        S\n1         1       1  female  38.0  71.28      1      0        C\n2         1       3  female  26.0   7.92      0      0        S\n"})}),(0,r.jsxs)(s.p,{children:["Despu\xe9s de aplicar el c\xf3digo anterior, la variable ",(0,r.jsx)(s.code,{children:"X"})," ser\xeda un Dataframe con el contenido:"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"   Pclass     Sex   Age   Fare  SibSp  Parch Embarked\n0       3    male  22.0   7.25      1      0        S\n1       1  female  38.0  71.28      1      0        C\n2       3  female  26.0   7.92      0      0        S\n"})}),(0,r.jsxs)(s.p,{children:["Y la variable ",(0,r.jsx)(s.code,{children:"y"})," ser\xeda una Serie con la variable objetivo correspondiente a cada fila de X."]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"0    0\n1    1\n2    1\nName: Survived, dtype: int64\n"})}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-22-divisi\xf3n-del-dataset",children:"Paso 2.2. Divisi\xf3n del dataset"}),(0,r.jsxs)(s.p,{children:["La funci\xf3n ",(0,r.jsx)(s.code,{children:"train_test_split"})," de scikit-learn permite dividir el dataset de forma aleatoria en:"]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"train"})," \u2192 usado para entrenar (ajustar) el modelo."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"test"})," \u2192 usado para evaluar el rendimiento final del modelo."]}),"\n"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.2,       # el 20% para test, 80% para train\n    random_state=42,     # fija la aleatoriedad para reproducir resultados\n    stratify=y           # mantiene la proporci\xf3n de clases en train y test\n)\n"})}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Explicaci\xf3n de los par\xe1metros:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:(0,r.jsx)(s.code,{children:"test_size=0.2"})}),"\nUsamos un 20% para test. Es est\xe1ndar para muchos problemas y datasets medianos."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:(0,r.jsx)(s.code,{children:"random_state=42"})}),"\nAsegura que todos obtengamos exactamente la misma divisi\xf3n.\nSi no lo pones, cada ejecuci\xf3n divide el dataset de forma distinta."]}),"\n"]}),"\n",(0,r.jsxs)(s.li,{children:["\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:(0,r.jsx)(s.code,{children:"stratify=y"})}),"\nMuy importante cuando el target tiene clases desbalanceadas (por ejemplo, supervivencia en Titanic).\nGenera train y test con la ",(0,r.jsx)(s.strong,{children:"misma proporci\xf3n de clases"})," que el dataset original.\nEjemplo: si el Titanic tiene un 38% de supervivientes y un 62% de fallecidos, ambos conjuntos mantendr\xe1n esa proporci\xf3n."]}),"\n"]}),"\n"]}),(0,r.jsx)(s.h2,{id:"paso-3-operaciones-despu\xe9s-de-la-divisi\xf3n",children:"Paso 3. Operaciones despu\xe9s de la divisi\xf3n"}),(0,r.jsxs)(s.p,{children:["Una vez que ya tenemos nuestros conjuntos ",(0,r.jsx)(s.strong,{children:"X_train, X_test, y_train y y_test"}),", comienza la fase m\xe1s importante del preprocesamiento:   todas las transformaciones que ",(0,r.jsx)(s.strong,{children:"aprenden par\xe1metros"})," deben realizarse ",(0,r.jsx)(s.strong,{children:"ajust\xe1ndose \xfanicamente al train"}),", y luego aplicarse al test."]}),(0,r.jsx)(s.p,{children:"El objetivo principal en esta fase es:"}),(0,r.jsxs)(s.blockquote,{children:["\n",(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Aprender par\xe1metros con train \u2192 aplicar esos mismos par\xe1metros a test."})}),"\n"]}),(0,r.jsxs)(s.p,{children:["Esto evita el ",(0,r.jsx)(s.strong,{children:"data leakage"})," y garantiza que el modelo se eval\xfaa de forma justa."]}),(0,r.jsxs)(s.admonition,{title:"Nota clave: lo que ocurre a partir de aqu\xed",type:"tip",children:[(0,r.jsxs)(s.p,{children:["Una vez dividido el dataset, ",(0,r.jsx)(s.strong,{children:"todas las transformaciones que aprendan informaci\xf3n del conjunto"})," (imputaci\xf3n, codificaci\xf3n, escalado\u2026) deben seguir esta estructura:"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'# EJEMPLO DE FLUJO CORRECTO (imputaci\xf3n como ejemplo)\nimputer = SimpleImputer(strategy="median")\n\nX_train["Age"] = imputer.fit_transform(X_train[["Age"]])  # aprende la mediana solo con train\nX_test["Age"]  = imputer.transform(X_test[["Age"]])        # aplica lo aprendido al test\n'})}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Por qu\xe9 es tan importante:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"fit"})," (entrenar) \u2192 solo en ",(0,r.jsx)(s.strong,{children:"train"})]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"transform"})," (aplicar) \u2192 en ",(0,r.jsx)(s.strong,{children:"train"})," y ",(0,r.jsx)(s.strong,{children:"test"})]}),"\n"]}),(0,r.jsxs)(s.p,{children:["\u26a0\ufe0f Nunca debe llamarse ",(0,r.jsx)(s.code,{children:"fit"})," con los datos de ",(0,r.jsx)(s.strong,{children:"test"}),"."]}),(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Ejemplo visual para entenderlo"})}),(0,r.jsx)(s.p,{children:"Imagina que tenemos esta columna de edades antes de dividir:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"[20, 30, 40, 80]\n"})}),(0,r.jsxs)(s.p,{children:["Despu\xe9s del ",(0,r.jsx)(s.em,{children:"train/test split"}),", queda as\xed:"]}),(0,r.jsx)(s.p,{children:"Train (lo que el modelo puede ver al aprender):"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"[20, 30, 40]\n"})}),(0,r.jsx)(s.p,{children:"Test (datos nuevos que simulan el futuro):"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"[80]\n"})}),(0,r.jsx)(s.p,{children:"Si hacemos:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'imputer.fit(X_train[["Age"]])\n'})}),(0,r.jsxs)(s.p,{children:["El imputador ",(0,r.jsx)(s.strong,{children:"aprende la mediana de train"}),", que es:"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"mediana(train) = 30\n"})}),(0,r.jsx)(s.p,{children:"Y despu\xe9s aplicamos:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'imputer.transform(X_test[["Age"]])\n'})}),(0,r.jsxs)(s.p,{children:["\u2192 El imputador usa ",(0,r.jsx)(s.strong,{children:"solo la mediana aprendida (30)"}),", sin mirar el valor 80 del futuro."]}),(0,r.jsx)(s.p,{children:(0,r.jsxs)(s.strong,{children:["\xbfQu\xe9 pasar\xeda si hici\xe9ramos ",(0,r.jsx)(s.code,{children:"fit"})," tambi\xe9n con test?"]})}),(0,r.jsx)(s.p,{children:"Estar\xedamos calculando la mediana as\xed:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"mediana([20, 30, 40, 80]) = 35\n"})}),(0,r.jsxs)(s.p,{children:["Es decir, el imputador est\xe1 usando informaci\xf3n del test para aprender. Esto es ",(0,r.jsx)(s.strong,{children:"data leakage"})," (filtraci\xf3n de datos). El modelo estar\xeda \u201cviendo el futuro\u201d y la evaluaci\xf3n ya no ser\xeda realista."]})]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-31-tratamiento-de-valores-nulos-post-split",children:"Paso 3.1 Tratamiento de valores nulos (post-split)"}),(0,r.jsx)(s.p,{children:"Ya vimos en EDA que pod\xedamos ver los nulos con la instrucci\xf3n:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"X_train.isnull().sum()\n"})}),(0,r.jsx)(s.p,{children:"Las estrategias de tratamiento m\xe1s comunes son:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Eliminar filas o columnas"})," con demasiados nulos (poco habitual aqu\xed, porque ya hicimos la limpieza estructural antes del split)."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"Imputar valores faltantes"})," usando:","\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Media"}),"\n",(0,r.jsx)(s.li,{children:"Mediana (m\xe1s robusta)"}),"\n",(0,r.jsx)(s.li,{children:"Moda (para categ\xf3ricas)"}),"\n"]}),"\n"]}),"\n"]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"imputaci\xf3n-para-variables-num\xe9ricas",children:"Imputaci\xf3n para variables num\xe9ricas"}),(0,r.jsxs)(s.p,{children:["En Titanic, la columna ",(0,r.jsx)(s.code,{children:"Age"})," tiene valores nulos, as\xed que usaremos ",(0,r.jsx)(s.code,{children:"SimpleImputer"})," con la ",(0,r.jsx)(s.strong,{children:"mediana"}),", que suele funcionar mejor que la media en datos sesgados."]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'from sklearn.impute import SimpleImputer\n\n# Imputador para columnas num\xe9ricas con estrategia de mediana\nimputer_num = SimpleImputer(strategy="median")\n\n# Ajustamos (fit) SOLO con train\nX_train["Age"] = imputer_num.fit_transform(X_train[["Age"]])\n\n# Transformamos test con lo aprendido\nX_test["Age"] = imputer_num.transform(X_test[["Age"]])\n'})}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Explicaci\xf3n:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"fit_transform()"})," aprende la mediana de Age en train \u2192 la aplica al propio train."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"transform()"})," aplica esa misma mediana al test, sin recalcular nada."]}),"\n"]}),(0,r.jsxs)(s.admonition,{title:"\xbfMedia o mediana? Decisi\xf3n seg\xfan la distribuci\xf3n",type:"info",children:[(0,r.jsxs)(s.p,{children:["Para decidir si debemos imputar con ",(0,r.jsx)(s.strong,{children:"media"})," o ",(0,r.jsx)(s.strong,{children:"mediana"}),", es importante observar ",(0,r.jsx)(s.strong,{children:"la forma de la distribuci\xf3n"}),". En el caso de la edad en el Titanic, vemos que ",(0,r.jsx)(s.strong,{children:"no tiene forma de campana sim\xe9trica"})," (no es una distribuci\xf3n normal).",(0,r.jsx)(s.br,{}),"\n","Hay muchos valores concentrados entre 15 y 35 a\xf1os, y luego la cola se alarga hacia la derecha."]}),(0,r.jsxs)(s.p,{children:["Esto significa que la variable est\xe1 ",(0,r.jsx)(s.strong,{children:"sesgada"})," (asim\xe9trica), y por tanto ",(0,r.jsx)(s.strong,{children:"la media estar\xeda demasiado influida por los valores altos"}),". En cambio, la ",(0,r.jsx)(s.strong,{children:"mediana"})," es m\xe1s robusta y representa mejor el valor central real."]}),(0,r.jsxs)(s.p,{children:["Por eso, en este caso, ",(0,r.jsx)(s.strong,{children:"la estrategia recomendada es usar la mediana"})," para imputar los valores nulos de ",(0,r.jsx)(s.code,{children:"Age"}),"."]}),(0,r.jsx)(s.p,{children:(0,r.jsx)(s.img,{alt:"Gr\xe1fico EDA",src:a(73825).A+"",width:"571",height:"455"})})]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"imputaci\xf3n-para-variables-categ\xf3ricas",children:"Imputaci\xf3n para variables categ\xf3ricas"}),(0,r.jsxs)(s.p,{children:["Ejemplo con ",(0,r.jsx)(s.code,{children:"Embarked"}),":"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'# Imputador para columnas categ\xf3ricas, qued\xe1ndose con la categor\xeda m\xe1s frecuente\nimputer_cat = SimpleImputer(strategy="most_frequent")\n\nX_train["Embarked"] = imputer_cat.fit_transform(X_train[["Embarked"]]).ravel()\nX_test["Embarked"]  = imputer_cat.transform(X_test[["Embarked"]]).ravel()\n'})}),(0,r.jsxs)(s.p,{children:["Esto rellena los valores nulos con la ",(0,r.jsx)(s.strong,{children:"categor\xeda m\xe1s frecuente"})," de los pasajeros en ",(0,r.jsx)(s.em,{children:"train"}),"."]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-32-codificaci\xf3n-de-variables-categ\xf3ricas",children:"Paso 3.2 Codificaci\xf3n de variables categ\xf3ricas"}),(0,r.jsxs)(s.p,{children:["Los modelos de Machine Learning ",(0,r.jsx)(s.strong,{children:"no pueden trabajar directamente con texto"}),", por lo que todas las variables categ\xf3ricas deben convertirse a valores num\xe9ricos."]}),(0,r.jsxs)(s.p,{children:["Para ello existen dos t\xe9cnicas principales: ",(0,r.jsx)(s.strong,{children:"Label Encoding"})," y ",(0,r.jsx)(s.strong,{children:"One-Hot Encoding"}),". Cada una se usa en situaciones distintas y genera tipos de columnas diferentes."]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"c\xf3mo-elegir-entre-label-y-one-hot",children:"\xbfC\xf3mo elegir entre Label y One-Hot?"}),(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Tipo de variable"}),(0,r.jsx)(s.th,{children:"Ejemplo"}),(0,r.jsx)(s.th,{children:"Codificaci\xf3n recomendada"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsxs)(s.td,{children:[(0,r.jsx)(s.strong,{children:"Ordinal"})," (tiene orden)"]}),(0,r.jsx)(s.td,{children:"Clase del Titanic"}),(0,r.jsx)(s.td,{children:"Label Encoding"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsxs)(s.td,{children:[(0,r.jsx)(s.strong,{children:"Nominal"})," (sin orden)"]}),(0,r.jsx)(s.td,{children:"Sexo, puerto"}),(0,r.jsx)(s.td,{children:"One-Hot Encoding"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.strong,{children:"Much\xedsimas categor\xedas"})}),(0,r.jsx)(s.td,{children:"C\xf3digos \xfanicos, IDs"}),(0,r.jsx)(s.td,{children:"Ninguna (mejor eliminar o agrupar)"})]})]})]}),(0,r.jsx)(s.hr,{}),(0,r.jsxs)(s.h4,{id:"label-encoding-para-variables-ordinales",children:["Label Encoding (para variables ",(0,r.jsx)(s.em,{children:"ordinales"}),")"]}),(0,r.jsxs)(s.p,{children:["Vamos a suponer que en el Titanic la columna ",(0,r.jsx)(s.strong,{children:"Pclass"})," no viniera como n\xfameros ",(0,r.jsx)(s.code,{children:"1, 2, 3"}),", sino como texto:"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-text",children:'"1st", "2nd", "3rd"\n'})}),(0,r.jsxs)(s.p,{children:["Es una variable ",(0,r.jsx)(s.strong,{children:"categ\xf3rica ordinal"})," (hay un orden claro: 1st < 2nd < 3rd), as\xed que aqu\xed ",(0,r.jsx)(s.strong,{children:"s\xed tiene sentido"})," usar ",(0,r.jsx)(s.strong,{children:"Label Encoding"}),"."]}),(0,r.jsx)(s.p,{children:"La idea es la misma que con los nulos:"}),(0,r.jsxs)(s.p,{children:["\ud83d\udc49 ",(0,r.jsxs)(s.strong,{children:["Ajustamos (fit) solo con ",(0,r.jsx)(s.code,{children:"X_train"})]})," y despu\xe9s ",(0,r.jsxs)(s.strong,{children:["aplicamos (transform) a ",(0,r.jsx)(s.code,{children:"X_train"})," y ",(0,r.jsx)(s.code,{children:"X_test"})]}),"."]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'from sklearn.preprocessing import LabelEncoder\n\nencoder_pclass = LabelEncoder()\n\n# Ajustamos el encoder SOLO con los datos de train\nencoder_pclass.fit(X_train["Pclass"])\n\n# Transformamos train y test con el mismo mapeo aprendido\nX_train["Pclass_encoded"] = encoder_pclass.transform(X_train["Pclass"])\nX_test["Pclass_encoded"]  = encoder_pclass.transform(X_test["Pclass"])\n'})}),(0,r.jsx)(s.p,{children:"Si las clases fueran, por ejemplo:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-text",children:'["1st", "2nd", "3rd"]\n'})}),(0,r.jsx)(s.p,{children:"el encoder podr\xeda aprender algo como:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-text",children:'"1st" -> 0\n"2nd" -> 1\n"3rd" -> 2\n'})}),(0,r.jsx)(s.p,{children:"Y las nuevas columnas quedar\xedan as\xed:"}),(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Pclass"}),(0,r.jsx)(s.th,{children:"Pclass_encoded"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"1st"}),(0,r.jsx)(s.td,{children:"0"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"3rd"}),(0,r.jsx)(s.td,{children:"2"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"2nd"}),(0,r.jsx)(s.td,{children:"1"})]})]})]}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Importante:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"fit"})," aprende qu\xe9 categor\xedas existen y en qu\xe9 orden las codifica \u2192 ",(0,r.jsx)(s.strong,{children:"solo en X_train"}),"."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"transform"})," aplica ese mismo mapeo a ",(0,r.jsx)(s.strong,{children:"X_train y X_test"}),"."]}),"\n",(0,r.jsxs)(s.li,{children:["Genera ",(0,r.jsx)(s.strong,{children:"una \xfanica columna num\xe9rica"}),", que conserva el orden natural de la variable (",(0,r.jsx)(s.code,{children:"1st < 2nd < 3rd"}),")."]}),"\n"]}),(0,r.jsx)(s.hr,{}),(0,r.jsxs)(s.h4,{id:"one-hot-encoding-para-variables-nominales",children:["One-Hot Encoding (para variables ",(0,r.jsx)(s.em,{children:"nominales"}),")"]}),(0,r.jsxs)(s.p,{children:["En el Titanic, columnas como ",(0,r.jsx)(s.strong,{children:"Sex"})," o ",(0,r.jsx)(s.strong,{children:"Embarked"})," contienen categor\xedas que ",(0,r.jsx)(s.strong,{children:"no tienen un orden"}),":"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-text",children:'Sex:       "male", "female"\nEmbarked:  "S", "C", "Q"\n'})}),(0,r.jsxs)(s.p,{children:["Cuando las categor\xedas ",(0,r.jsx)(s.strong,{children:"no tienen jerarqu\xeda"}),", no podemos asignarles n\xfameros como 0, 1, 2 porque el modelo podr\xeda interpretar err\xf3neamente que uno \u201cvale m\xe1s\u201d que otro."]}),(0,r.jsxs)(s.p,{children:["\ud83d\udc49 En estos casos, la t\xe9cnica correcta es ",(0,r.jsx)(s.strong,{children:"One-Hot Encoding"}),"."]}),(0,r.jsxs)(s.p,{children:["Esta t\xe9cnica crea ",(0,r.jsx)(s.strong,{children:"una columna por cada categor\xeda"}),", con valores 0/1 indicando si esa fila pertenece a esa categor\xeda."]}),(0,r.jsx)(s.p,{children:"La idea es la misma que antes:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["Ajustamos (fit) el codificador solo con ",(0,r.jsx)(s.code,{children:"X_train"})]}),"\n",(0,r.jsxs)(s.li,{children:["Transformamos tanto ",(0,r.jsx)(s.code,{children:"X_train"})," como ",(0,r.jsx)(s.code,{children:"X_test"})," con lo aprendido"]}),"\n"]}),(0,r.jsx)(s.p,{children:(0,r.jsxs)(s.strong,{children:["Ejemplo con la columna ",(0,r.jsx)(s.code,{children:"Embarked"})," del Titanic"]})}),(0,r.jsx)(s.p,{children:"Vamos a transformar esta variable nominal en columnas num\xe9ricas:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'from sklearn.preprocessing import OneHotEncoder\n\n# Empezamos por Embarked\nencoder_embarked = OneHotEncoder(handle_unknown="ignore", sparse_output=False)\n\n# Ajustamos SOLO con los datos de train\nencoder_embarked.fit(X_train[["Embarked"]])\n\n# Transformamos train y test usando lo aprendido\n# embarked_train y embarked_test son arrays numpy, hay que procesarlos m\xe1s tarde para obtener un DataFrame\nembarked_train = encoder_embarked.transform(X_train[["Embarked"]])\nembarked_test  = encoder_embarked.transform(X_test[["Embarked"]])\n\n# Convertimos las matrices a DataFrames para verlas mejor y a\xf1adirlas posteriormente a nuestro DataFrame completo\nembarked_train = pd.DataFrame(embarked_train, \n                              columns=encoder_embarked.get_feature_names_out(["Embarked"]),\n                              index=X_train.index)\nembarked_test  = pd.DataFrame(embarked_test,\n                              columns=encoder_embarked.get_feature_names_out(["Embarked"]),\n                              index=X_test.index)\n'})}),(0,r.jsx)(s.p,{children:"Vamos a entender c\xf3mo funciona el c\xf3digo anterior. Supongamos que tenemos este DataFrame:"}),(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsx)(s.tr,{children:(0,r.jsx)(s.th,{children:"Embarked"})})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsx)(s.tr,{children:(0,r.jsx)(s.td,{children:"S"})}),(0,r.jsx)(s.tr,{children:(0,r.jsx)(s.td,{children:"C"})}),(0,r.jsx)(s.tr,{children:(0,r.jsx)(s.td,{children:"Q"})}),(0,r.jsx)(s.tr,{children:(0,r.jsx)(s.td,{children:"S"})}),(0,r.jsx)(s.tr,{children:(0,r.jsx)(s.td,{children:"C"})})]})]}),(0,r.jsxs)(s.p,{children:["Si aplicamos ",(0,r.jsx)(s.strong,{children:"One-Hot Encoding"}),", obtendremos tres nuevas columnas (una por cada categor\xeda):"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"Embarked_C   Embarked_Q   Embarked_S\n"})}),(0,r.jsx)(s.p,{children:"La transformaci\xf3n completa quedar\xeda as\xed:"}),(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Embarked"}),(0,r.jsx)(s.th,{children:"Embarked_C"}),(0,r.jsx)(s.th,{children:"Embarked_Q"}),(0,r.jsx)(s.th,{children:"Embarked_S"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"S"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"1"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"C"}),(0,r.jsx)(s.td,{children:"1"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"0"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Q"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"1"}),(0,r.jsx)(s.td,{children:"0"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"S"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"1"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"C"}),(0,r.jsx)(s.td,{children:"1"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"0"})]})]})]}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Interpretaci\xf3n r\xe1pida:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Cada categor\xeda se convierte en una columna."}),"\n",(0,r.jsx)(s.li,{children:"El valor 1 indica la categor\xeda correspondiente de esa fila."}),"\n",(0,r.jsx)(s.li,{children:"Solo una columna vale 1 porque cada pasajero solo puede embarcar por un puerto."}),"\n"]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.p,{children:"Tras aplicar One-Hot Encoding, en el \xfaltimo paso:"}),(0,r.jsxs)(s.ol,{children:["\n",(0,r.jsxs)(s.li,{children:["Se ",(0,r.jsx)(s.strong,{children:"eliminan las columnas originales"})," (",(0,r.jsx)(s.code,{children:"Embarked"}),", ",(0,r.jsx)(s.code,{children:"Sex"}),", etc.)"]}),"\n",(0,r.jsxs)(s.li,{children:["Se ",(0,r.jsx)(s.strong,{children:"a\xf1aden las columnas generadas"})," al DataFrame"]}),"\n"]}),(0,r.jsx)(s.p,{children:"Ejemplo:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'# Eliminamos columnas categ\xf3ricas originales, sustituy\xe9ndolas por las nuevas generadas\nX_train = pd.concat([X_train.drop(columns=["Embarked"]), embarked_train], axis=1)\nX_test  = pd.concat([X_test.drop(columns=["Embarked"]), embarked_test], axis=1)\n'})}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-33-feature-engineering-b\xe1sico",children:"Paso 3.3. Feature Engineering b\xe1sico"}),(0,r.jsxs)(s.p,{children:["El ",(0,r.jsx)(s.strong,{children:"Feature Engineering"})," consiste en crear nuevas variables (features) que puedan aportar informaci\xf3n adicional al modelo.",(0,r.jsx)(s.br,{}),"\n","En esta fase del curso solo veremos ",(0,r.jsx)(s.strong,{children:"transformaciones sencillas y muy intuitivas"}),", sin t\xe9cnicas avanzadas."]}),(0,r.jsx)(s.p,{children:"El objetivo es mejorar la capacidad predictiva del modelo utilizando informaci\xf3n que ya existe en el dataset, pero combinada de forma m\xe1s \xfatil."}),(0,r.jsx)(s.h4,{id:"creaci\xf3n-de-variables-intuitivas",children:"Creaci\xf3n de variables intuitivas"}),(0,r.jsx)(s.p,{children:"A veces, combinar varias columnas puede generar una nueva variable con m\xe1s significado que las originales por separado."}),(0,r.jsx)(s.p,{children:"En el Titanic, las columnas:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"SibSp"})," \u2192 n\xfamero de hermanos/esposos a bordo"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"Parch"})," \u2192 n\xfamero de padres/hijos a bordo"]}),"\n"]}),(0,r.jsxs)(s.p,{children:["por separado aportan informaci\xf3n, pero ",(0,r.jsx)(s.strong,{children:"juntas pueden representar mejor el tama\xf1o del grupo familiar"}),"."]}),(0,r.jsx)(s.p,{children:"Creamos una nueva columna:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'# Crear tama\xf1o familiar\nX_train["FamilySize"] = X_train["SibSp"] + X_train["Parch"] + 1\nX_test["FamilySize"]  = X_test["SibSp"] + X_test["Parch"] + 1\n'})}),(0,r.jsx)(s.p,{children:"\xbfPor qu\xe9 sumamos 1?"}),(0,r.jsx)(s.p,{children:"\ud83d\udc49 Para incluir al propio pasajero en el tama\xf1o total de la familia."}),(0,r.jsx)(s.p,{children:"Ejemplo:"}),(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"SibSp"}),(0,r.jsx)(s.th,{children:"Parch"}),(0,r.jsx)(s.th,{children:"FamilySize"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"1"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"2"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"1"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"3"}),(0,r.jsx)(s.td,{children:"1"}),(0,r.jsx)(s.td,{children:"5"})]})]})]}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Interpretaci\xf3n:"}),"\nLos grupos m\xe1s grandes ten\xedan, en general, menor probabilidad de sobrevivir, por lo que esta variable puede ayudar al modelo."]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"eliminaci\xf3n-de-variables-redundantes",children:"Eliminaci\xf3n de variables redundantes"}),(0,r.jsxs)(s.p,{children:["Una vez que hemos creado una nueva variable derivada de otras dos, es posible que las variables originales ",(0,r.jsx)(s.strong,{children:"ya no sean necesarias"})," o aporten informaci\xf3n duplicada."]}),(0,r.jsx)(s.p,{children:"En este nivel b\xe1sico, la regla que seguiremos ser\xe1:"}),(0,r.jsxs)(s.p,{children:["\ud83d\udc49 ",(0,r.jsx)(s.strong,{children:"Si la nueva variable resume bien la informaci\xf3n, podemos eliminar las columnas que la generaron."})]}),(0,r.jsxs)(s.p,{children:["Por ejemplo, tras crear ",(0,r.jsx)(s.code,{children:"FamilySize"}),", podr\xedamos eliminar ",(0,r.jsx)(s.code,{children:"SibSp"})," y ",(0,r.jsx)(s.code,{children:"Parch"})," para evitar redundancia:"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'X_train = X_train.drop(columns=["SibSp", "Parch"])\nX_test  = X_test.drop(columns=["SibSp", "Parch"])\n'})}),(0,r.jsx)(s.p,{children:"Esto hace el dataset m\xe1s compacto y claro para el modelo."}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-34-escalado-y-normalizaci\xf3n-de-variables-num\xe9ricas",children:"Paso 3.4. Escalado y normalizaci\xf3n de variables num\xe9ricas"}),(0,r.jsxs)(s.p,{children:["Tras imputar valores nulos y codificar las variables categ\xf3ricas, el siguiente paso es ",(0,r.jsx)(s.strong,{children:"escalar o normalizar las variables num\xe9ricas"}),".",(0,r.jsx)(s.br,{}),"\n","Este proceso es fundamental en muchos modelos de Machine Learning, especialmente aquellos que son sensibles a la magnitud de los valores (por ejemplo, KNN, regresi\xf3n log\xedstica, redes neuronales, SVM\u2026)."]}),(0,r.jsx)(s.p,{children:"En un dataset como el Titanic, algunas columnas num\xe9ricas tienen escalas muy distintas:"}),(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Variable"}),(0,r.jsx)(s.th,{children:"Rango aproximado"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.code,{children:"Age"})}),(0,r.jsx)(s.td,{children:"0 \u2013 80"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.code,{children:"Fare"})}),(0,r.jsx)(s.td,{children:"0 \u2013 512"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:(0,r.jsx)(s.code,{children:"SibSp"})}),(0,r.jsx)(s.td,{children:"0 \u2013 8"})]})]})]}),(0,r.jsx)(s.p,{children:"Si no escalamos estas variables:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["Los modelos podr\xedan ",(0,r.jsx)(s.strong,{children:"dar m\xe1s importancia"})," a las columnas con valores m\xe1s grandes (",(0,r.jsx)(s.code,{children:"Fare"}),")."]}),"\n",(0,r.jsxs)(s.li,{children:["La distancia entre puntos en modelos basados en distancia (como KNN o clustering) estar\xeda ",(0,r.jsx)(s.strong,{children:"sesgada"}),"."]}),"\n",(0,r.jsx)(s.li,{children:"El entrenamiento podr\xeda tardar m\xe1s y converger peor."}),"\n"]}),(0,r.jsxs)(s.p,{children:["\u27a1\ufe0f ",(0,r.jsx)(s.strong,{children:"Escalar no cambia la forma de los datos"}),", pero s\xed su rango, para que todas las variables \u201cjueguen en igualdad de condiciones\u201d."]}),(0,r.jsxs)(s.admonition,{title:"Nota avanzada (Paso previo sobre los outliers)",type:"info",children:[(0,r.jsxs)(s.p,{children:["En algunas variables ",(0,r.jsx)(s.strong,{children:"muy sesgadas"}),", como ",(0,r.jsx)(s.code,{children:"Fare"})," en el Titanic, los valores altos son mucho mayores que los valores t\xedpicos.",(0,r.jsx)(s.br,{}),"\n","Esto produce una distribuci\xf3n con ",(0,r.jsx)(s.strong,{children:"cola larga"}),", que puede afectar a ciertos modelos o a algunos m\xe9todos de escalado (por ejemplo, MinMaxScaler)."]}),(0,r.jsx)(s.p,{children:(0,r.jsx)(s.img,{alt:"Gr\xe1fico EDA",src:a(9170).A+"",width:"520",height:"455"})}),(0,r.jsxs)(s.p,{children:["En an\xe1lisis m\xe1s avanzados existe la posibilidad de aplicar ",(0,r.jsx)(s.strong,{children:"transformaciones matem\xe1ticas"})," como:"]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"log()"})," \u2192 reduce el impacto de los valores muy grandes"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.code,{children:"sqrt()"})," \u2192 suaviza moderadamente la distribuci\xf3n"]}),"\n",(0,r.jsxs)(s.li,{children:["Transformaciones m\xe1s complejas como ",(0,r.jsx)(s.strong,{children:"Box-Cox"})," o ",(0,r.jsx)(s.strong,{children:"Yeo-Johnson"})]}),"\n"]}),(0,r.jsxs)(s.p,{children:["Estas transformaciones no eliminan outliers reales, sino que simplemente ",(0,r.jsx)(s.strong,{children:"reducen su influencia"})," para modelos muy sensibles a distribuciones sesgadas."]}),(0,r.jsxs)(s.p,{children:["Sin embargo, estas t\xe9cnicas pertenecen a un nivel m\xe1s avanzado de ",(0,r.jsx)(s.em,{children:"Feature Engineering"}),".",(0,r.jsx)(s.br,{}),"\n","En este curso inicial ",(0,r.jsx)(s.strong,{children:"no son necesarias"})," y no las aplicaremos, ya que los modelos que veremos funcionan correctamente sin esta complejidad adicional."]})]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"m\xe9todos-m\xe1s-utilizados",children:"M\xe9todos m\xe1s utilizados"}),(0,r.jsx)(s.p,{children:"Aqu\xed veremos los dos escaladores que se usan en la mayor\xeda de proyectos:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"StandardScaler"})," \u2192 distribuye con media = 0 y desviaci\xf3n est\xe1ndar = 1"]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"MinMaxScaler"})," \u2192 lleva todos los valores al rango [0, 1]"]}),"\n"]}),(0,r.jsxs)(s.p,{children:["Ambos se utilizan ",(0,r.jsx)(s.strong,{children:"despu\xe9s"})," del ",(0,r.jsx)(s.em,{children:"train/test split"}),", tras las imputaciones necesarias y antes de entrenar el modelo."]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"standardscaler-escalado-est\xe1ndar",children:"StandardScaler (escalado est\xe1ndar)"}),(0,r.jsxs)(s.p,{children:["El ",(0,r.jsx)(s.code,{children:"StandardScaler"})," transforma cada variable num\xe9rica para que tenga:"]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:(0,r.jsx)(s.strong,{children:"Media = 0"})}),"\n",(0,r.jsx)(s.li,{children:(0,r.jsx)(s.strong,{children:"Desviaci\xf3n est\xe1ndar = 1"})}),"\n"]}),(0,r.jsx)(s.p,{children:"Matem\xe1ticamente:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"valor_escalado = (valor - media) / desviaci\xf3n_est\xe1ndar\n"})}),(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"\xbfCu\xe1ndo usar StandardScaler?"})}),(0,r.jsxs)(s.p,{children:["\u2714 ",(0,r.jsx)(s.strong,{children:"Para casi todos los modelos cl\xe1sicos de Machine Learning."})]}),(0,r.jsx)(s.p,{children:"Porque:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Centra los datos (media=0), lo cual ayuda al entrenamiento."}),"\n",(0,r.jsx)(s.li,{children:"No obliga a tener datos en un rango fijo."}),"\n",(0,r.jsx)(s.li,{children:"Funciona bien incluso si las variables no est\xe1n \u201cperfectamente distribuidas\u201d."}),"\n"]}),(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Ejemplo con Titanic"})}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'from sklearn.preprocessing import StandardScaler\n\n# \xa1IMPORTANTE! Seleccionamos solo las columnas num\xe9ricas que queremos escalar (por ahora seleccionaremos todas)\nnum_cols = ["Pclass", "Age", "Fare", "SibSp", "Parch"]\n\n# Creamos el escalador\nscaler = StandardScaler()\n\n# Ajustamos el escalador SOLO con los datos de train (fit)\nX_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n\n# Aplicamos la transformaci\xf3n a test (transform)\nX_test[num_cols] = scaler.transform(X_test[num_cols])\n'})}),(0,r.jsx)(s.p,{children:"Tras esto, cada columna quedar\xe1 escalada, por ejemplo:"}),(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Variable"}),(0,r.jsx)(s.th,{children:"Antes"}),(0,r.jsx)(s.th,{children:"Despu\xe9s"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Age"}),(0,r.jsx)(s.td,{children:"22"}),(0,r.jsx)(s.td,{children:"-0.73"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Age"}),(0,r.jsx)(s.td,{children:"38"}),(0,r.jsx)(s.td,{children:"1.22"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Fare"}),(0,r.jsx)(s.td,{children:"512"}),(0,r.jsx)(s.td,{children:"4.11"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Parch"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"-0.45"})]})]})]}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Interpretaci\xf3n:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Valores negativos \u2192 menores que la media"}),"\n",(0,r.jsx)(s.li,{children:"Valores positivos \u2192 mayores que la media"}),"\n"]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"minmaxscaler-normalizaci\xf3n-01",children:"MinMaxScaler (normalizaci\xf3n 0\u20131)"}),(0,r.jsxs)(s.p,{children:["El ",(0,r.jsx)(s.code,{children:"MinMaxScaler"})," transforma cada variable num\xe9rica para que todos sus valores queden dentro del rango:"]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:(0,r.jsx)(s.strong,{children:"M\xednimo = 0"})}),"\n",(0,r.jsx)(s.li,{children:(0,r.jsx)(s.strong,{children:"M\xe1ximo = 1"})}),"\n"]}),(0,r.jsx)(s.p,{children:"Matem\xe1ticamente:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{children:"valor_escalado = (valor - min) / (max - min)\n"})}),(0,r.jsx)(s.p,{children:"Es decir, cada valor se reescala proporcionalmente seg\xfan el valor m\xednimo y m\xe1ximo de la columna."}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"\xbfCu\xe1ndo usar MinMaxScaler?"})}),(0,r.jsxs)(s.p,{children:["\u2714 ",(0,r.jsx)(s.strong,{children:"Cuando queremos que todos los valores queden entre 0 y 1."}),(0,r.jsx)(s.br,{}),"\n","\u2714 \xdatil en modelos que funcionan mejor con entradas normalizadas en un rango fijo, como:"]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Redes neuronales"}),"\n",(0,r.jsx)(s.li,{children:"Modelos que trabajan con activaciones entre 0 y 1"}),"\n"]}),(0,r.jsxs)(s.p,{children:["\u274c ",(0,r.jsx)(s.strong,{children:"No es ideal si hay valores extremos muy altos (outliers reales)."})," En esos casos, un \xfanico valor muy grande puede hacer que casi todos los dem\xe1s queden muy cerca de 0 tras escalar."]}),(0,r.jsx)(s.p,{children:(0,r.jsx)(s.strong,{children:"Ejemplo con Titanic"})}),(0,r.jsx)(s.p,{children:"Vamos a escalar las mismas columnas num\xe9ricas que antes:"}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'from sklearn.preprocessing import MinMaxScaler\n\n# Seleccionamos las columnas num\xe9ricas que queremos escalar\nnum_cols = ["Pclass", "Age", "Fare", "SibSp", "Parch"]\n\n# Creamos el escalador\nscaler = MinMaxScaler()\n\n# Ajustamos el escalador SOLO con los datos de train (fit)\nX_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n\n# Aplicamos la transformaci\xf3n a test (transform)\nX_test[num_cols] = scaler.transform(X_test[num_cols])\n'})}),(0,r.jsx)(s.p,{children:"Tras esto, cada columna quedar\xe1 normalizada al rango 0\u20131. Por ejemplo:"}),(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Variable"}),(0,r.jsx)(s.th,{children:"Antes"}),(0,r.jsx)(s.th,{children:"Despu\xe9s"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Age"}),(0,r.jsx)(s.td,{children:"22"}),(0,r.jsx)(s.td,{children:"0.28"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Age"}),(0,r.jsx)(s.td,{children:"38"}),(0,r.jsx)(s.td,{children:"0.54"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Fare"}),(0,r.jsx)(s.td,{children:"512"}),(0,r.jsx)(s.td,{children:"1.00"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Parch"}),(0,r.jsx)(s.td,{children:"0"}),(0,r.jsx)(s.td,{children:"0.00"})]})]})]}),(0,r.jsxs)(s.p,{children:["\ud83d\udca1 ",(0,r.jsx)(s.strong,{children:"Interpretaci\xf3n:"})]}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"0"})," representa el valor m\xednimo visto en ",(0,r.jsx)(s.em,{children:"train"}),"."]}),"\n",(0,r.jsxs)(s.li,{children:[(0,r.jsx)(s.strong,{children:"1"})," representa el valor m\xe1ximo visto en ",(0,r.jsx)(s.em,{children:"train"}),"."]}),"\n",(0,r.jsx)(s.li,{children:"El resto de valores quedan en posiciones proporcionales dentro del intervalo 0\u20131."}),"\n"]}),(0,r.jsx)(s.admonition,{title:"Nota sobre MinMaxScaler",type:"info",children:(0,r.jsx)(s.p,{children:"Aunque MinMaxScaler funciona bien en muchos casos, recuerda que si existe un valor extremadamente alto (como una tarifa de 500), el resto de valores quedar\xe1n muy cerca de 0.\nPor eso, aunque es \xfatil, suele utilizarse menos que StandardScaler en problemas cl\xe1sicos."})}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"resumen-standardscaler-vs-minmaxscaler",children:"Resumen StandardScaler vs MinMaxScaler"}),(0,r.jsxs)(s.table,{children:[(0,r.jsx)(s.thead,{children:(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.th,{children:"Caracter\xedstica"}),(0,r.jsx)(s.th,{children:"StandardScaler"}),(0,r.jsx)(s.th,{children:"MinMaxScaler"})]})}),(0,r.jsxs)(s.tbody,{children:[(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Rango"}),(0,r.jsx)(s.td,{children:"No fijo (puede ser negativo)"}),(0,r.jsx)(s.td,{children:"Entre 0 y 1"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Usa"}),(0,r.jsx)(s.td,{children:"Media y desviaci\xf3n"}),(0,r.jsx)(s.td,{children:"M\xednimo y m\xe1ximo"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Afectado por outliers"}),(0,r.jsx)(s.td,{children:"S\xed (mucho)"}),(0,r.jsx)(s.td,{children:"S\xed (much\xedsimo)"})]}),(0,r.jsxs)(s.tr,{children:[(0,r.jsx)(s.td,{children:"Mejor para"}),(0,r.jsx)(s.td,{children:"Modelos lineales, KNN, SVM"}),(0,r.jsx)(s.td,{children:"Redes neuronales, datos entre 0-1"})]})]})]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h4,{id:"debo-escalar-todas-las-columnas-num\xe9ricas",children:"\xbfDebo escalar todas las columnas num\xe9ricas?"}),(0,r.jsxs)(s.p,{children:["\u2714 ",(0,r.jsx)(s.strong,{children:"S\xed"}),", si usas modelos basados en distancias (KNN, SVM).",(0,r.jsx)(s.br,{}),"\n","\u2714 ",(0,r.jsx)(s.strong,{children:"S\xed"}),", si usas regresi\xf3n log\xedstica o redes neuronales.",(0,r.jsx)(s.br,{}),"\n","\u274c ",(0,r.jsx)(s.strong,{children:"No es necesario"})," para \xe1rboles de decisi\xf3n o Random Forest (no les afecta)."]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h2,{id:"paso-4-preparaci\xf3n-final-del-dataset",children:"Paso 4. Preparaci\xf3n final del dataset"}),(0,r.jsxs)(s.p,{children:["Despu\xe9s de haber realizado todas las tareas de preprocesamiento \u2014limpieza estructural, divisi\xf3n en ",(0,r.jsx)(s.em,{children:"train/test"}),", imputaci\xf3n, codificaci\xf3n, escalado y feature engineering\u2014 ya tenemos nuestros datos pr\xe1cticamente listos para entrenar modelos de Machine Learning."]}),(0,r.jsxs)(s.p,{children:["Antes de continuar, es recomendable hacer una ",(0,r.jsx)(s.strong,{children:"\xfaltima revisi\xf3n r\xe1pida"})," para comprobar que todo ha quedado correctamente transformado."]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-41-revisi\xf3n-r\xe1pida-de-coherencia",children:"Paso 4.1 Revisi\xf3n r\xe1pida de coherencia"}),(0,r.jsx)(s.p,{children:"En este punto debemos asegurarnos de que:"}),(0,r.jsxs)(s.p,{children:["\u2714 ",(0,r.jsx)(s.strong,{children:"No quedan valores nulos"})]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"X_train.isnull().sum()\nX_test.isnull().sum()\n"})}),(0,r.jsx)(s.p,{children:"Si alguna columna sigue teniendo nulos, puede deberse a:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"una codificaci\xf3n incompleta,"}),"\n",(0,r.jsx)(s.li,{children:"un problema en la imputaci\xf3n,"}),"\n",(0,r.jsx)(s.li,{children:"o columnas que no se incluyeron en el proceso."}),"\n"]}),(0,r.jsxs)(s.p,{children:["\u2714 ",(0,r.jsx)(s.strong,{children:"Todas las columnas son num\xe9ricas"})]}),(0,r.jsxs)(s.p,{children:["Los modelos cl\xe1sicos de Machine Learning ",(0,r.jsx)(s.strong,{children:"solo aceptan variables num\xe9ricas"}),". Debemos asegurarnos de que ya no quedan columnas categ\xf3ricas sin transformar:"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"X_train.dtypes\n"})}),(0,r.jsxs)(s.p,{children:["En este punto todo deber\xeda ser ",(0,r.jsx)(s.code,{children:"int"}),", ",(0,r.jsx)(s.code,{children:"float"})," o ",(0,r.jsx)(s.code,{children:"uint8"})," (en caso de One-Hot Encoding)."]}),(0,r.jsxs)(s.p,{children:["\u2714 ",(0,r.jsx)(s.strong,{children:"Las columnas de train y test coinciden"})]}),(0,r.jsxs)(s.p,{children:["Esto es MUY importante. Si el n\xfamero o nombre de columnas no coincide entre ",(0,r.jsx)(s.code,{children:"X_train"})," y ",(0,r.jsx)(s.code,{children:"X_test"}),", el modelo no podr\xe1 predecir correctamente."]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:"print(X_train.shape)\nprint(X_test.shape)\n\nprint(X_train.columns)\nprint(X_test.columns)\n"})}),(0,r.jsx)(s.p,{children:"Si no coinciden, normalmente significa que:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"falt\xf3 eliminar alguna columna original antes de concatenar,"}),"\n",(0,r.jsx)(s.li,{children:"hubo categor\xedas presentes en train que no aparecieron en test,"}),"\n",(0,r.jsx)(s.li,{children:"o se mezclaron escaladores o imputadores incorrectamente."}),"\n"]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-42-dataset-final-listo-para-el-modelado",children:"Paso 4.2 Dataset final listo para el modelado"}),(0,r.jsxs)(s.p,{children:["Cuando se cumple todo los descrito en el paso anterior, ",(0,r.jsx)(s.strong,{children:"nuestro dataset est\xe1 preparado para entrenar un modelo."})]}),(0,r.jsx)(s.p,{children:"A partir de aqu\xed, podemos comenzar con:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"Regresi\xf3n log\xedstica"}),"\n",(0,r.jsx)(s.li,{children:"\xc1rboles"}),"\n",(0,r.jsx)(s.li,{children:"Random Forest"}),"\n",(0,r.jsx)(s.li,{children:"KNN"}),"\n",(0,r.jsx)(s.li,{children:"SVM"}),"\n",(0,r.jsx)(s.li,{children:"etc."}),"\n"]}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h3,{id:"paso-43-guardar-los-datasets-transformados-opcional-pero-recomendable",children:"Paso 4.3 Guardar los datasets transformados (opcional, pero recomendable)"}),(0,r.jsx)(s.p,{children:"Es muy habitual guardar las versiones preprocesadas de los datos, especialmente si queremos:"}),(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsx)(s.li,{children:"reutilizarlos,"}),"\n",(0,r.jsx)(s.li,{children:"compartirlos,"}),"\n",(0,r.jsx)(s.li,{children:"hacer pruebas con diferentes modelos,"}),"\n",(0,r.jsx)(s.li,{children:"o evitar repetir todo el proceso de preprocesamiento."}),"\n"]}),(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-python",children:'X_train.to_csv("titanic_X_train_preprocessed.csv", index=False)\nX_test.to_csv("titanic_X_test_preprocessed.csv", index=False)\ny_train.to_csv("titanic_y_train.csv", index=False)\ny_test.to_csv("titanic_y_test.csv", index=False)\n'})}),(0,r.jsx)(s.hr,{}),(0,r.jsx)(s.h2,{id:"ejercicio-de-titanic",children:"Ejercicio de Titanic"}),(0,r.jsxs)(s.p,{children:["Realiza el preprocesamiento del dataset ",(0,r.jsx)(s.strong,{children:"Titanic"}),", pero esta vez con un fichero \u201censuciado\u201d a prop\xf3sito para poder aplicar la mayor\xeda de las t\xe9cnicas vistas."]}),(0,r.jsx)(s.p,{children:"Puedes partir del cuaderno que ya tienes de EDA (cuidado, tendr\xe1s que volver a ejecutarlo con el nuevo dataset):"}),(0,r.jsxs)(s.p,{children:["\ud83d\udc49 ",(0,r.jsx)(s.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:a(59017).A+"",children:"Cuaderno de EDA \u2014 Titanic"})]}),(0,r.jsxs)(s.p,{children:["\ud83d\udcc2 Dataset para este ejercicio: ",(0,r.jsx)(s.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:a(59326).A+"",children:(0,r.jsx)(s.code,{children:"titanic_sucio.csv"})})]}),(0,r.jsxs)(s.p,{children:["Como opci\xf3n adicional, puedes entrenar un modelo sencillo (por ejemplo, ",(0,r.jsx)(s.strong,{children:"KNN"}),") con el dataset ya preprocesado para comprobar que todo el flujo funciona correctamente y que los resultados mejoran con respecto al preprocesamiento sencillo que hac\xedamos al inicio del tema."]})]})}function h(e={}){const{wrapper:s}={...(0,i.R)(),...e.components};return s?(0,r.jsx)(s,{...e,children:(0,r.jsx)(t,{...e})}):t(e)}},49771:(e,s,a)=>{a.d(s,{A:()=>n});const n=a.p+"assets/images/boxplot-valor-erroneo-1176351e75914a967e0dcbad609d797d.png"},59017:(e,s,a)=>{a.d(s,{A:()=>n});const n=a.p+"assets/files/EDA_Titanic-d3829ade827a195700af8fce3aef1407.ipynb"},59326:(e,s,a)=>{a.d(s,{A:()=>n});const n=a.p+"assets/files/titanic_sucio-488a5c3690f6101661c0c9c3d3266cec.csv"},73825:(e,s,a)=>{a.d(s,{A:()=>n});const n=a.p+"assets/images/histograma-edad-81e806966568c145f13432fee8be42b3.png"}}]);