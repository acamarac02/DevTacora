"use strict";(self.webpackChunkpmdm=self.webpackChunkpmdm||[]).push([[9001],{28453:(e,a,n)=>{n.d(a,{R:()=>l,x:()=>o});var s=n(96540);const r={},i=s.createContext(r);function l(e){const a=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(i.Provider,{value:a},e.children)}},48928:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>d,contentTitle:()=>o,default:()=>m,frontMatter:()=>l,metadata:()=>s,toc:()=>t});const s=JSON.parse('{"id":"pia_2526/ut4_deep_learning/redes-densas/regresion","title":"Redes Densas para Regresi\xf3n","description":"C\xf3mo utilizar redes neuronales densas (MLP) para predecir valores continuos. Arquitectura, funciones de activaci\xf3n y m\xe9tricas clave.","source":"@site/docs/01_pia_2526/ut4_deep_learning/3-redes-densas/1-regresion.md","sourceDirName":"01_pia_2526/ut4_deep_learning/3-redes-densas","slug":"/pia_2526/ut4_deep_learning/redes-densas/regresion","permalink":"/DevTacora/docs/pia_2526/ut4_deep_learning/redes-densas/regresion","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Redes Densas para Regresi\xf3n","sidebar_position":1,"description":"C\xf3mo utilizar redes neuronales densas (MLP) para predecir valores continuos. Arquitectura, funciones de activaci\xf3n y m\xe9tricas clave.","keywords":["regresi\xf3n","redes densas","MLP","California Housing","MSE","MAE","ReLU","TensorBoard"]},"sidebar":"pia_2526_Sidebar","previous":{"title":"Redes Densas","permalink":"/DevTacora/docs/category/redes-densas"}}');var r=n(74848),i=n(28453);const l={title:"Redes Densas para Regresi\xf3n",sidebar_position:1,description:"C\xf3mo utilizar redes neuronales densas (MLP) para predecir valores continuos. Arquitectura, funciones de activaci\xf3n y m\xe9tricas clave.",keywords:["regresi\xf3n","redes densas","MLP","California Housing","MSE","MAE","ReLU","TensorBoard"]},o=void 0,d={},t=[{value:"\xbfQu\xe9 es una Red Neuronal Densa?",id:"qu\xe9-es-una-red-neuronal-densa",level:2},{value:"Arquitectura para Regresi\xf3n",id:"arquitectura-para-regresi\xf3n",level:2},{value:"A. Capa de Entrada (Input)",id:"a-capa-de-entrada-input",level:3},{value:"B. Capas Ocultas (Hidden Layers)",id:"b-capas-ocultas-hidden-layers",level:3},{value:"C. Capa de Salida (Output)",id:"c-capa-de-salida-output",level:3},{value:"Implementaci\xf3n b\xe1sica en Keras",id:"implementaci\xf3n-b\xe1sica-en-keras",level:3},{value:"Configuraci\xf3n del Entrenamiento",id:"configuraci\xf3n-del-entrenamiento",level:2},{value:"Funci\xf3n de P\xe9rdida (Loss Function)",id:"funci\xf3n-de-p\xe9rdida-loss-function",level:3},{value:"Optimizador",id:"optimizador",level:3},{value:"M\xe9tricas",id:"m\xe9tricas",level:3},{value:"Implementaci\xf3n b\xe1sica en Keras",id:"implementaci\xf3n-b\xe1sica-en-keras-1",level:3},{value:"El Proceso de Entrenamiento: Batches y Validaci\xf3n",id:"el-proceso-de-entrenamiento-batches-y-validaci\xf3n",level:2},{value:"\xbfQu\xe9 es el Batch Size?",id:"qu\xe9-es-el-batch-size",level:3},{value:"El Conjunto de Validaci\xf3n (Validation Split)",id:"el-conjunto-de-validaci\xf3n-validation-split",level:3},{value:"Caso de Estudio: California Housing",id:"caso-de-estudio-california-housing",level:2},{value:"El Problema",id:"el-problema",level:3},{value:"EDA y preprocesamiento",id:"eda-y-preprocesamiento",level:3},{value:"La Importancia de la Estandarizaci\xf3n",id:"la-importancia-de-la-estandarizaci\xf3n",level:3},{value:"An\xe1lisis de Experimentos: TensorBoard",id:"an\xe1lisis-de-experimentos-tensorboard",level:2},{value:"\xbfEn qu\xe9 fijarnos en TensorBoard?",id:"en-qu\xe9-fijarnos-en-tensorboard",level:3},{value:"Demo pr\xe1ctica: California Housing",id:"demo-pr\xe1ctica-california-housing",level:2},{value:"Actividad de seguimiento",id:"actividad-de-seguimiento",level:2}];function c(e){const a={a:"a",admonition:"admonition",annotation:"annotation",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",math:"math",mi:"mi",mo:"mo",mrow:"mrow",msub:"msub",ol:"ol",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(a.p,{children:"En los apartados anteriores hemos visto c\xf3mo funciona una neurona individual y c\xf3mo se entrena mediante el descenso de gradiente. Pero una sola neurona (perceptr\xf3n) tiene una limitaci\xf3n fundamental: solo puede aprender relaciones lineales."}),"\n",(0,r.jsxs)(a.p,{children:["Para resolver problemas complejos, necesitamos conectar muchas neuronas en capas, formando lo que se conoce como ",(0,r.jsx)(a.strong,{children:"Red Neuronal Densa"})," o ",(0,r.jsx)(a.strong,{children:"Perceptr\xf3n Multicapa (MLP)"}),"."]}),"\n",(0,r.jsxs)(a.p,{children:["En este apartado vamos a ver c\xf3mo configurar estas redes para resolver problemas de ",(0,r.jsx)(a.strong,{children:"regresi\xf3n"}),", es decir, cuando queremos predecir un valor num\xe9rico continuo (como el precio de una casa, la temperatura de ma\xf1ana o la demanda de electricidad)."]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"qu\xe9-es-una-red-neuronal-densa",children:"\xbfQu\xe9 es una Red Neuronal Densa?"}),"\n",(0,r.jsxs)(a.p,{children:["Una red densa (",(0,r.jsx)(a.em,{children:"Fully Connected Layer"})," o ",(0,r.jsx)(a.em,{children:"Dense Layer"}),") es aquella en la que ",(0,r.jsx)(a.strong,{children:"cada neurona de una capa est\xe1 conectada con todas las neuronas de la capa siguiente"}),"."]}),"\n",(0,r.jsx)(a.p,{children:"Es la arquitectura m\xe1s b\xe1sica y fundamental del Deep Learning. Su potencia reside en que, al apilar varias capas con funciones de activaci\xf3n no lineales (como ReLU), la red puede aprender a aproximar cualquier funci\xf3n matem\xe1tica compleja, no solo l\xedneas rectas."}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.img,{alt:"Gr\xe1fico EDA",src:n(57204).A+"",width:"800",height:"504"})}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"arquitectura-para-regresi\xf3n",children:"Arquitectura para Regresi\xf3n"}),"\n",(0,r.jsx)(a.p,{children:"Cuando dise\xf1amos una red para un problema de regresi\xf3n, la arquitectura suele seguir un patr\xf3n est\xe1ndar:"}),"\n",(0,r.jsx)(a.h3,{id:"a-capa-de-entrada-input",children:"A. Capa de Entrada (Input)"}),"\n",(0,r.jsxs)(a.p,{children:["El n\xfamero de neuronas de entrada debe coincidir con el n\xfamero de ",(0,r.jsx)(a.strong,{children:"caracter\xedsticas (features)"})," de nuestros datos."]}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Si nuestro dataset tiene 8 columnas de datos (como en California Housing), la capa de entrada tendr\xe1 8 neuronas."}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"b-capas-ocultas-hidden-layers",children:"B. Capas Ocultas (Hidden Layers)"}),"\n",(0,r.jsx)(a.p,{children:'Aqu\xed es donde ocurre la "magia".'}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"N\xfamero de capas y neuronas"}),": Depende de la complejidad del problema. Para problemas sencillos, 1 o 2 capas con 32-64 neuronas suelen funcionar bien."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Funci\xf3n de Activaci\xf3n"}),": El est\xe1ndar hoy en d\xeda es ",(0,r.jsx)(a.strong,{children:"ReLU"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(a.admonition,{title:"\xbfCu\xe1l es la mejor arquitectura?",type:"tip",children:[(0,r.jsxs)(a.p,{children:["No existe una f\xf3rmula m\xe1gica. La clave en Deep Learning es la ",(0,r.jsx)(a.strong,{children:"experimentaci\xf3n"}),". Probaremos diferentes combinaciones (m\xe1s capas, menos neuronas, etc.) y nos quedaremos con aquella que:"]}),(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Mejor generalice"}),": La que consiga el menor error en el conjunto de ",(0,r.jsx)(a.strong,{children:"Validaci\xf3n"})," (no en el de entrenamiento)."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Sea m\xe1s simple"}),": Siguiendo el principio de la ",(0,r.jsx)(a.em,{children:"Navaja de Ockham"}),", si dos arquitecturas dan resultados similares, siempre elegiremos la m\xe1s sencilla para evitar el sobreajuste y ahorrar c\xf3mputo."]}),"\n"]})]}),"\n",(0,r.jsx)(a.h3,{id:"c-capa-de-salida-output",children:"C. Capa de Salida (Output)"}),"\n",(0,r.jsx)(a.p,{children:"Esta es la parte cr\xedtica que diferencia a la regresi\xf3n de la clasificaci\xf3n."}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"N\xfamero de neuronas"}),": ",(0,r.jsx)(a.strong,{children:"1"})," (porque queremos predecir un \xfanico valor num\xe9rico)."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Funci\xf3n de Activaci\xf3n"}),": ",(0,r.jsx)(a.strong,{children:"Ninguna (Lineal)"}),".","\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"No usamos Sigmoid o Tanh porque estas comprimen la salida a rangos limitados ([0,1] o [-1,1])."}),"\n",(0,r.jsxs)(a.li,{children:["Queremos que la red pueda predecir cualquier valor real (por ejemplo, un precio de 500.000$ o una temperatura de -15\xbaC), por lo que dejamos que la neurona devuelva el valor tal cual lo calcula la suma ponderada: ",(0,r.jsxs)(a.span,{className:"katex",children:[(0,r.jsx)(a.span,{className:"katex-mathml",children:(0,r.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,r.jsxs)(a.semantics,{children:[(0,r.jsxs)(a.mrow,{children:[(0,r.jsx)(a.mi,{children:"y"}),(0,r.jsx)(a.mo,{children:"="}),(0,r.jsx)(a.mo,{children:"\u2211"}),(0,r.jsx)(a.mo,{stretchy:"false",children:"("}),(0,r.jsxs)(a.msub,{children:[(0,r.jsx)(a.mi,{children:"w"}),(0,r.jsx)(a.mi,{children:"i"})]}),(0,r.jsxs)(a.msub,{children:[(0,r.jsx)(a.mi,{children:"x"}),(0,r.jsx)(a.mi,{children:"i"})]}),(0,r.jsx)(a.mo,{stretchy:"false",children:")"}),(0,r.jsx)(a.mo,{children:"+"}),(0,r.jsx)(a.mi,{children:"b"})]}),(0,r.jsx)(a.annotation,{encoding:"application/x-tex",children:"y = \\sum (w_i x_i) + b"})]})})}),(0,r.jsxs)(a.span,{className:"katex-html","aria-hidden":"true",children:[(0,r.jsxs)(a.span,{className:"base",children:[(0,r.jsx)(a.span,{className:"strut",style:{height:"0.625em",verticalAlign:"-0.1944em"}}),(0,r.jsx)(a.span,{className:"mord mathnormal",style:{marginRight:"0.03588em"},children:"y"}),(0,r.jsx)(a.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,r.jsx)(a.span,{className:"mrel",children:"="}),(0,r.jsx)(a.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,r.jsxs)(a.span,{className:"base",children:[(0,r.jsx)(a.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,r.jsx)(a.span,{className:"mop op-symbol small-op",style:{position:"relative",top:"0em"},children:"\u2211"}),(0,r.jsx)(a.span,{className:"mopen",children:"("}),(0,r.jsxs)(a.span,{className:"mord",children:[(0,r.jsx)(a.span,{className:"mord mathnormal",style:{marginRight:"0.02691em"},children:"w"}),(0,r.jsx)(a.span,{className:"msupsub",children:(0,r.jsxs)(a.span,{className:"vlist-t vlist-t2",children:[(0,r.jsxs)(a.span,{className:"vlist-r",children:[(0,r.jsx)(a.span,{className:"vlist",style:{height:"0.3117em"},children:(0,r.jsxs)(a.span,{style:{top:"-2.55em",marginLeft:"-0.0269em",marginRight:"0.05em"},children:[(0,r.jsx)(a.span,{className:"pstrut",style:{height:"2.7em"}}),(0,r.jsx)(a.span,{className:"sizing reset-size6 size3 mtight",children:(0,r.jsx)(a.span,{className:"mord mathnormal mtight",children:"i"})})]})}),(0,r.jsx)(a.span,{className:"vlist-s",children:"\u200b"})]}),(0,r.jsx)(a.span,{className:"vlist-r",children:(0,r.jsx)(a.span,{className:"vlist",style:{height:"0.15em"},children:(0,r.jsx)(a.span,{})})})]})})]}),(0,r.jsxs)(a.span,{className:"mord",children:[(0,r.jsx)(a.span,{className:"mord mathnormal",children:"x"}),(0,r.jsx)(a.span,{className:"msupsub",children:(0,r.jsxs)(a.span,{className:"vlist-t vlist-t2",children:[(0,r.jsxs)(a.span,{className:"vlist-r",children:[(0,r.jsx)(a.span,{className:"vlist",style:{height:"0.3117em"},children:(0,r.jsxs)(a.span,{style:{top:"-2.55em",marginLeft:"0em",marginRight:"0.05em"},children:[(0,r.jsx)(a.span,{className:"pstrut",style:{height:"2.7em"}}),(0,r.jsx)(a.span,{className:"sizing reset-size6 size3 mtight",children:(0,r.jsx)(a.span,{className:"mord mathnormal mtight",children:"i"})})]})}),(0,r.jsx)(a.span,{className:"vlist-s",children:"\u200b"})]}),(0,r.jsx)(a.span,{className:"vlist-r",children:(0,r.jsx)(a.span,{className:"vlist",style:{height:"0.15em"},children:(0,r.jsx)(a.span,{})})})]})})]}),(0,r.jsx)(a.span,{className:"mclose",children:")"}),(0,r.jsx)(a.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,r.jsx)(a.span,{className:"mbin",children:"+"}),(0,r.jsx)(a.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,r.jsxs)(a.span,{className:"base",children:[(0,r.jsx)(a.span,{className:"strut",style:{height:"0.6944em"}}),(0,r.jsx)(a.span,{className:"mord mathnormal",children:"b"})]})]})]}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"implementaci\xf3n-b\xe1sica-en-keras",children:"Implementaci\xf3n b\xe1sica en Keras"}),"\n",(0,r.jsx)(a.p,{children:"Traducir esta arquitectura a c\xf3digo con TensorFlow y Keras es muy directo. Aqu\xed tienes un ejemplo de c\xf3mo se configurar\xeda la arquitectura:"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"import tensorflow as tf\nfrom tensorflow.keras import layers\n\n# 1. Definir la arquitectura\nmodel = tf.keras.Sequential([\n    # Capa oculta 1: 64 neuronas, activaci\xf3n ReLU\n    layers.Dense(64, activation='relu', input_shape=[n_features]), \n    # Capa oculta 2: 32 neuronas, activaci\xf3n ReLU\n    layers.Dense(32, activation='relu'),\n    # Capa de salida: 1 neurona, sin activaci\xf3n (lineal)\n    layers.Dense(1)\n])\n"})}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"configuraci\xf3n-del-entrenamiento",children:"Configuraci\xf3n del Entrenamiento"}),"\n",(0,r.jsx)(a.p,{children:"Para entrenar una red de regresi\xf3n, necesitamos configurar el compilador del modelo con los siguientes elementos:"}),"\n",(0,r.jsx)(a.h3,{id:"funci\xf3n-de-p\xe9rdida-loss-function",children:"Funci\xf3n de P\xe9rdida (Loss Function)"}),"\n",(0,r.jsx)(a.p,{children:"Es la m\xe9trica que el optimizador intentar\xe1 minimizar. Las m\xe1s comunes en regresi\xf3n son:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"MSE (Mean Squared Error)"}),": Calcula el promedio de los errores al cuadrado. Penaliza mucho los errores grandes (outliers). Es la m\xe1s habitual en regresi\xf3n."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"MAE (Mean Absolute Error)"}),": Calcula el promedio del valor absoluto de los errores. Es menos sensible a outliers que el MSE."]}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"optimizador",children:"Optimizador"}),"\n",(0,r.jsxs)(a.p,{children:["Como vimos en la teor\xeda, el algoritmo que ajusta los pesos. El est\xe1ndar de facto para empezar es ",(0,r.jsx)(a.strong,{children:"Adam"}),", ya que gestiona autom\xe1ticamente el ",(0,r.jsx)(a.em,{children:"learning rate"})," de forma adaptativa."]}),"\n",(0,r.jsx)(a.h3,{id:"m\xe9tricas",children:"M\xe9tricas"}),"\n",(0,r.jsxs)(a.p,{children:["Son valores que ",(0,r.jsx)(a.em,{children:"nosotros"})," leemos para entender qu\xe9 tan bien funciona el modelo (aunque no se usan directamente para optimizar)."]}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"MAE"}),' es muy interpretable: nos dice, de media, cu\xe1nto nos estamos equivocando en las unidades originales (por ejemplo, "nos equivocamos en 20.000$ de media").']}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"RMSE"})," (Ra\xedz del error cuadr\xe1tico medio): Muy usada tambi\xe9n para tener una medida de error en las mismas unidades que la variable objetivo."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"R\xb2 (R-cuadrado)"}),': Indica qu\xe9 porcentaje de la variaci\xf3n de los datos es capaz de explicar nuestro modelo. Un R\xb2 de 0.8 significa que el modelo explica el 80% de la variabilidad. Es la m\xe9trica ideal para saber si el modelo es "bueno" en t\xe9rminos generales.']}),"\n"]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h3,{id:"implementaci\xf3n-b\xe1sica-en-keras-1",children:"Implementaci\xf3n b\xe1sica en Keras"}),"\n",(0,r.jsx)(a.p,{children:"Traducir esta arquitectura a c\xf3digo con TensorFlow y Keras es muy directo. Aqu\xed tienes un ejemplo de c\xf3mo se compila un modelo:"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"# 2. Compilar el modelo\nmodel.compile(\n    optimizer='adam',\n    loss='mse',\n    metrics=['mae']\n)\n"})}),"\n",(0,r.jsx)(a.admonition,{title:"Diferencia entre Loss y Metrics",type:"tip",children:(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Loss (P\xe9rdida)"}),": Es para la ",(0,r.jsx)(a.strong,{children:"Red Neuronal"}),". Es la funci\xf3n que el optimizador intenta minimizar para ajustar los pesos."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Metrics (M\xe9tricas)"}),": Es para el ",(0,r.jsx)(a.strong,{children:"Humano"}),". Son valores que Keras nos muestra durante el entrenamiento para que podamos entender c\xf3mo de bueno es el modelo en unidades comprensibles (como el MAE en d\xf3lares), pero la red no las usa para aprender."]}),"\n"]})}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"el-proceso-de-entrenamiento-batches-y-validaci\xf3n",children:"El Proceso de Entrenamiento: Batches y Validaci\xf3n"}),"\n",(0,r.jsxs)(a.p,{children:["Para que el modelo aprenda correctamente, no basta con pasarle los datos; hay que definir ",(0,r.jsx)(a.em,{children:"c\xf3mo"})," los va a procesar."]}),"\n",(0,r.jsx)(a.h3,{id:"qu\xe9-es-el-batch-size",children:"\xbfQu\xe9 es el Batch Size?"}),"\n",(0,r.jsxs)(a.p,{children:["No le pasamos todos los datos a la red a la vez (ser\xeda demasiado pesado para la memoria), ni tampoco uno por uno (ser\xeda muy lento). Los agrupamos en ",(0,r.jsx)(a.strong,{children:"batches"})," (lotes)."]}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Batch Size"}),": El n\xfamero de ejemplos que procesa la red antes de actualizar los pesos. Un valor com\xfan es 32 o 64."]}),"\n",(0,r.jsx)(a.li,{children:(0,r.jsx)(a.em,{children:'Nota: No confundir con "Batch Normalization", que es una t\xe9cnica de regularizaci\xf3n que veremos m\xe1s adelante.'})}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"el-conjunto-de-validaci\xf3n-validation-split",children:"El Conjunto de Validaci\xf3n (Validation Split)"}),"\n",(0,r.jsxs)(a.p,{children:["Durante el entrenamiento, es vital saber c\xf3mo se comporta el modelo con datos que ",(0,r.jsx)(a.strong,{children:"no est\xe1 usando para aprender"}),".\nReservamos una peque\xf1a parte de los datos (por ejemplo, el 20%) para validaci\xf3n. El modelo:"]}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:["Aprende con el conjunto de ",(0,r.jsx)(a.strong,{children:"Entrenamiento"}),"."]}),"\n",(0,r.jsxs)(a.li,{children:["Al final de cada \xe9poca, se eval\xfaa con el conjunto de ",(0,r.jsx)(a.strong,{children:"Validaci\xf3n"}),"."]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"Esto nos permite detectar el sobreajuste en tiempo real: si el error de entrenamiento baja pero el de validaci\xf3n sube, el modelo est\xe1 empezando a memorizar."}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"# Entrenar usando batches y conjunto de validaci\xf3n\nhistory = model.fit(\n    X_train, y_train,\n    epochs=100,\n    batch_size=32,\n    validation_data=(X_valid, y_valid),\n    verbose=0\n)\n"})}),"\n",(0,r.jsxs)(a.admonition,{title:"Train, Validation y Test",type:"tip",children:[(0,r.jsx)(a.p,{children:"Para entrenar un modelo correctamente, solemos dividir nuestros datos en tres bloques:"}),(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsxs)(a.strong,{children:["Entrenamiento (",(0,r.jsx)(a.code,{children:"X_train"}),", ",(0,r.jsx)(a.code,{children:"y_train"}),")"]}),': Son los "apuntes" que la red estudia para ajustar sus pesos.']}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsxs)(a.strong,{children:["Validaci\xf3n (",(0,r.jsx)(a.code,{children:"X_valid"}),", ",(0,r.jsx)(a.code,{children:"y_valid"}),")"]}),': Es un "simulacro de examen" que se hace al final de cada \xe9poca. Sirve para ver si el modelo est\xe1 aprendiendo a generalizar o solo est\xe1 memorizando. ',(0,r.jsx)(a.strong,{children:"La red no usa estos datos para ajustar pesos."})]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsxs)(a.strong,{children:["Test (",(0,r.jsx)(a.code,{children:"X_test"}),", ",(0,r.jsx)(a.code,{children:"y_test"}),")"]}),': Es el "examen final" que solo se hace una vez hemos terminado de entrenar y ajustar todo, para saber el rendimiento real del modelo con datos que nunca ha visto.']}),"\n"]}),(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:"from sklearn.model_selection import train_test_split\n\n# Dividimos para obtener el conjunto de Test (20%)\nX_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2)\n\n# Del resto (80%), sacamos el conjunto de Validaci\xf3n (ej: 25% de 80% = 20% del total)\nX_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25)\n"})})]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"caso-de-estudio-california-housing",children:"Caso de Estudio: California Housing"}),"\n",(0,r.jsxs)(a.p,{children:["Para poner en pr\xe1ctica estos conceptos, en la siguiente demo utilizaremos el famoso dataset ",(0,r.jsx)(a.strong,{children:"California Housing"}),"."]}),"\n",(0,r.jsx)(a.h3,{id:"el-problema",children:"El Problema"}),"\n",(0,r.jsxs)(a.p,{children:["El objetivo es predecir el ",(0,r.jsx)(a.strong,{children:"precio medio de las viviendas"})," en un distrito de California, bas\xe1ndonos en datos del censo de 1990."]}),"\n",(0,r.jsx)(a.p,{children:"Las caracter\xedsticas (features) incluyen:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"Ingreso medio en el bloque (MedInc)"}),"\n",(0,r.jsx)(a.li,{children:"Antig\xfcedad media de las casas (HouseAge)"}),"\n",(0,r.jsx)(a.li,{children:"N\xfamero medio de habitaciones (AveRooms)"}),"\n",(0,r.jsx)(a.li,{children:"Latitud y Longitud"}),"\n",(0,r.jsx)(a.li,{children:"Poblaci\xf3n, etc."}),"\n"]}),"\n",(0,r.jsx)(a.h3,{id:"eda-y-preprocesamiento",children:"EDA y preprocesamiento"}),"\n",(0,r.jsxs)(a.p,{children:["Antes de pasar los datos a una red neuronal, debemos aplicar todo lo aprendido en las unidades anteriores sobre ",(0,r.jsx)(a.strong,{children:"An\xe1lisis Exploratorio de Datos (EDA)"})," y ",(0,r.jsx)(a.strong,{children:"Preprocesamiento"}),"."]}),"\n",(0,r.jsx)(a.p,{children:'A menudo se piensa que el Deep Learning es "m\xe1gico" y que puede procesar cualquier cosa, pero nada m\xe1s lejos de la realidad:'}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"No admiten valores nulos"}),": Una red neuronal no puede operar con ",(0,r.jsx)(a.code,{children:"NaN"}),". Debemos imputar o eliminar esos valores previamente."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Solo entienden n\xfameros"}),": Todo el texto (variables categ\xf3ricas) debe ser codificado (One-Hot Encoding, Label Encoding, etc.) antes de entrar en la red."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Sensibilidad a Outliers"}),': Al basarse en el descenso de gradiente, los valores extremos pueden desestabilizar el entrenamiento y hacer que los pesos "exploten".']}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"En resumen: una red neuronal solo ser\xe1 tan buena como la calidad de los datos que le entregues."}),"\n",(0,r.jsx)(a.h3,{id:"la-importancia-de-la-estandarizaci\xf3n",children:"La Importancia de la Estandarizaci\xf3n"}),"\n",(0,r.jsxs)(a.p,{children:["A diferencia de los modelos basados en \xe1rboles (como Random Forest o XGBoost), las redes neuronales son ",(0,r.jsx)(a.strong,{children:"muy sensibles a la escala de los datos"}),"."]}),"\n",(0,r.jsx)(a.p,{children:"Si una variable tiene valores entre 0-1 (como una proporci\xf3n) y otra tiene valores entre 1.000-100.000 (como ingresos), la red tendr\xe1 dificultades para converger, ya que los pesos asociados a la variable grande tendr\xe1n que ser muy peque\xf1os y el gradiente ser\xe1 inestable."}),"\n",(0,r.jsxs)(a.admonition,{title:"Regla de Oro",type:"important",children:[(0,r.jsxs)(a.p,{children:["En Deep Learning, ",(0,r.jsx)(a.strong,{children:"siempre"})," debemos estandarizar o normalizar los datos de entrada para que tengan una escala similar (por ejemplo, media 0 y desviaci\xf3n est\xe1ndar 1)."]}),(0,r.jsxs)(a.p,{children:[(0,r.jsx)(a.strong,{children:"\xbfY la variable objetivo (Target)?"}),"\nEn problemas de regresi\xf3n donde el valor a predecir es muy grande (como el precio de una casa: 500.000$), a veces tambi\xe9n es recomendable escalarlo. Si no lo hacemos, el modelo podr\xeda tardar mucho en converger porque los errores iniciales ser\xedan gigantescos."]})]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"an\xe1lisis-de-experimentos-tensorboard",children:"An\xe1lisis de Experimentos: TensorBoard"}),"\n",(0,r.jsx)(a.p,{children:"Cuando entrenamos redes neuronales, a menudo probamos muchas configuraciones distintas:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsx)(a.li,{children:"\xbfMejor con 1 capa oculta o con 3?"}),"\n",(0,r.jsx)(a.li,{children:"\xbfMejor con 32 neuronas o con 128?"}),"\n",(0,r.jsxs)(a.li,{children:["\xbfMejor con ",(0,r.jsx)(a.em,{children:"learning rate"})," 0.01 o 0.001?"]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"Llevar la cuenta de todo esto no es f\xe1cil. Aqu\xed entra en juego TensorBoard."}),"\n",(0,r.jsxs)(a.p,{children:[(0,r.jsx)(a.strong,{children:"TensorBoard"})," es una herramienta de visualizaci\xf3n incliuda en TensorFlow que nos permite monitorizar el entrenamiento en tiempo real."]}),"\n",(0,r.jsx)(a.p,{children:"Nos permite ver:"}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Curvas de P\xe9rdida"}),": Ver si el modelo est\xe1 aprendiendo o si ha dejado de mejorar."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Comparar Modelos"}),": Superponer las gr\xe1ficas de distintos entrenamientos para ver cu\xe1l converge m\xe1s r\xe1pido o consigue menor error."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Detectar Overfitting"}),": Si vemos que la p\xe9rdida en entrenamiento baja pero en validaci\xf3n sube, sabremos exactamente en qu\xe9 \xe9poca empez\xf3 el sobreajuste."]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"En la demo pr\xe1ctica aprenderemos a instrumentar nuestro c\xf3digo para enviar estos datos a TensorBoard y analizarlos visualmente:"}),"\n",(0,r.jsx)(a.pre,{children:(0,r.jsx)(a.code,{className:"language-python",children:'import datetime\n\n# 1. Definir d\xf3nde se guardar\xe1n los logs (historial del entrenamiento)\n# Usamos la fecha y hora para que cada entrenamiento tenga su propia carpeta\nlog_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")\n\n# 2. Crear el callback de TensorBoard\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n# 3. Entrenar el modelo pasando el callback en una lista\nmodel.fit(\n    X_train, y_train, \n    epochs=100, \n    validation_data=(X_valid, y_valid),\n    callbacks=[tensorboard_callback]\n)\n\n# 4. Mostrar el panel de TensorBoard directamente en el cuaderno\n%load_ext tensorboard\n%tensorboard --logdir logs/fit\n'})}),"\n",(0,r.jsx)(a.h3,{id:"en-qu\xe9-fijarnos-en-tensorboard",children:"\xbfEn qu\xe9 fijarnos en TensorBoard?"}),"\n",(0,r.jsxs)(a.p,{children:["Una vez que se abre el panel, puedes elegir entre visualizar los datos en diferentes pesta\xf1as. Las m\xe1s \xfatiles para monitorizar la evoluci\xf3n del entrenamiento son ",(0,r.jsx)(a.strong,{children:"Time Series"})," (vista moderna recomendada) o ",(0,r.jsx)(a.strong,{children:"Scalars"})," (vista cl\xe1sica):"]}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Time Series:"})," Es la mejor vista para observar c\xf3mo evolucionan las m\xe9tricas a lo largo del tiempo (\xe9pocas). Te permite ver claramente la curva de entrenamiento y validaci\xf3n superpuestas."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Scalars:"})," Muestra exactamente la misma informaci\xf3n pero con la interfaz cl\xe1sica. Es \xfatil si necesitas ajustar el ",(0,r.jsx)(a.em,{children:"smoothing"})," (suavizado) de las curvas de forma m\xe1s manual."]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"En cualquiera de las dos pesta\xf1as, las gr\xe1ficas fundamentales a vigilar son:"}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsxs)(a.strong,{children:[(0,r.jsx)(a.code,{children:"epoch_loss"})," / ",(0,r.jsx)(a.code,{children:"val_loss"})]}),": Es la gr\xe1fica fundamental. Nos dice el error (MSE) en cada \xe9poca. Es la que usamos para ver si el modelo converge."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsxs)(a.strong,{children:[(0,r.jsx)(a.code,{children:"epoch_mae"})," / ",(0,r.jsx)(a.code,{children:"val_mae"})]}),": Es la m\xe9trica que nosotros entendemos (error en unidades reales). Es muy \xfatil para comunicar resultados."]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:"En estas gr\xe1ficas, debemos buscar las siguientes se\xf1ales:"}),"\n",(0,r.jsxs)(a.ul,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Tendencia de las curvas"}),": Lo ideal es que tanto la curva de ",(0,r.jsx)(a.strong,{children:"entrenamiento (train)"})," como la de ",(0,r.jsx)(a.strong,{children:"validaci\xf3n (val)"}),' bajen de forma suave. Si la curva es muy "dentada" o tiene picos bruscos, puede ser se\xf1al de que el ',(0,r.jsx)(a.em,{children:"learning rate"})," es demasiado alto."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Gap entre curvas"}),": Es normal que la p\xe9rdida de entrenamiento sea un poco menor que la de validaci\xf3n. Sin embargo, si la distancia entre ambas se vuelve cada vez m\xe1s grande, significa que el modelo est\xe1 empezando a memorizar (overfitting)."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:'El punto de "despegue"'}),": F\xedjate en el momento exacto en que la curva de validaci\xf3n deja de bajar y empieza a subir lentamente. Ese es el momento \xf3ptimo para detener el entrenamiento (y es lo que automatizaremos con el ",(0,r.jsx)(a.em,{children:"Early Stopping"}),")."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Comparaci\xf3n de experimentos"}),": TensorBoard nos permite marcar varios entrenamientos a la izquierda. Podr\xe1s ver, por ejemplo, si la red con 128 neuronas (curva azul) baja m\xe1s r\xe1pido que la de 32 neuronas (curva roja)."]}),"\n"]}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.img,{alt:"Gr\xe1fico EDA",src:n(52845).A+"",width:"1276",height:"496"})}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"Conclusiones de esta gr\xe1fica:"})}),"\n",(0,r.jsxs)(a.p,{children:["Al observar una gr\xe1fica de ",(0,r.jsx)(a.code,{children:"epoch_loss"})," como esta, podemos extraer conclusiones clave para mejorar el modelo:"]}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Entrenamiento vs. Validaci\xf3n"}),": La curva naranja representa el ",(0,r.jsx)(a.strong,{children:"entrenamiento"})," (va bajando de forma suave hasta el final), mientras que la azul representa la ",(0,r.jsx)(a.strong,{children:"validaci\xf3n"})," (se vuelve muy inestable y ruidosa)."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Inestabilidad (Ruido)"}),": Los picos constantes en la curva azul sugieren que el modelo tiene dificultades para generalizar en cada batch o que el conjunto de validaci\xf3n es peque\xf1o/espec\xedfico, aunque la tendencia general es clara."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Divergencia y Overfitting"}),": A partir de la \xe9poca 100, la brecha entre las dos curvas se ensancha dr\xe1sticamente. Mientras el error de entrenamiento sigue bajando (el modelo memoriza), el error de validaci\xf3n deja de mejorar. Esto es un caso de libro de ",(0,r.jsx)(a.strong,{children:"Overfitting"}),"."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Punto \xd3ptimo"}),": El mejor momento para haber detenido este entrenamiento fue alrededor de la ",(0,r.jsx)(a.strong,{children:"\xe9poca 40-50"}),", donde la curva azul alcanz\xf3 su punto m\xe1s bajo antes de volverse err\xe1tica. Entrenar hasta la \xe9poca 500 ha sido un desperdicio de tiempo y ha empeorado el modelo final."]}),"\n"]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"demo-pr\xe1ctica-california-housing",children:"Demo pr\xe1ctica: California Housing"}),"\n",(0,r.jsxs)(a.p,{children:["Puedes ver una demostraci\xf3n completa de lo anterior en este ",(0,r.jsx)(a.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:n(58202).A+"",children:"cuaderno de Colab"})," donde entrenamos tres arquitecturas diferentes para el dataset de California Housing y analizamos los resultados en TensorBoard."]}),"\n",(0,r.jsx)(a.hr,{}),"\n",(0,r.jsx)(a.h2,{id:"actividad-de-seguimiento",children:"Actividad de seguimiento"}),"\n",(0,r.jsxs)(a.p,{children:["Para poner en pr\xe1ctica estos conceptos, implementa una red neuronal para predecir la demanda de alquiler de bicicletas utilizando el ",(0,r.jsx)(a.strong,{children:"Bike Sharing Dataset"}),"."]}),"\n",(0,r.jsx)(a.p,{children:"Reutiliza el Colab que ya realizaste en el tema anterior, donde deber\xedas tener hecho el EDA, preprocesamiento y evaluaci\xf3n de modelos de Machine Learning cl\xe1sico."}),"\n",(0,r.jsx)(a.p,{children:(0,r.jsx)(a.strong,{children:"Requisitos de la actividad:"})}),"\n",(0,r.jsxs)(a.ol,{children:["\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Arquitecturas"}),": Define y entrena al menos ",(0,r.jsx)(a.strong,{children:"3 configuraciones de red"})," diferentes (por ejemplo: una baseline, una simple con una capa oculta y una m\xe1s profunda/ancha)."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Monitorizaci\xf3n"}),": Utiliza el callback de ",(0,r.jsx)(a.strong,{children:"TensorBoard"})," para registrar el entrenamiento de todos los modelos y describe las gr\xe1ficas de epoch_loss."]}),"\n",(0,r.jsxs)(a.li,{children:[(0,r.jsx)(a.strong,{children:"Evaluaci\xf3n"}),": Compara los modelos utilizando las m\xe9tricas."]}),"\n"]})]})}function m(e={}){const{wrapper:a}={...(0,i.R)(),...e.components};return a?(0,r.jsx)(a,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},52845:(e,a,n)=>{n.d(a,{A:()=>s});const s=n.p+"assets/images/tensorboard-loss-68ebcb07e9696bc52f72719b30831139.png"},57204:(e,a,n)=>{n.d(a,{A:()=>s});const s=n.p+"assets/images/nn-architecture-21fb3cf4325a32be9dace5c67fada707.png"},58202:(e,a,n)=>{n.d(a,{A:()=>s});const s=n.p+"assets/files/california_housing_redes_densas-545e566ab522fda3f209992c97582599.ipynb"}}]);